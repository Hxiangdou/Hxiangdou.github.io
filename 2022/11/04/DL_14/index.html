

<!DOCTYPE html>
<html lang="en" color-mode=light>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>动手学习深度学习（14）深度学习硬件：计算性能 - Hexo</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />
  
  <meta name="description" content="很好地理解算法和模型才可以捕获统计方面的问题，构建出具...">
  <meta name="author" content="茴香豆">
  <link rel="icon" href="/images/icons/favicon-16x16.png" type="image/png" sizes="16x16">
  <link rel="icon" href="/images/icons/favicon-32x32.png" type="image/png" sizes="32x32">
  <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180">
  <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon-144x144.png">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
    
<link rel="stylesheet" href="https://at.alicdn.com/t/font_1445822_p6ry5n7lrr.css">

  

  
    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css">

  

  
    
      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/xcode.min.css" name="highlight-style" mode="light">

      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/solarized-dark.min.css" name="highlight-style" mode="dark">

      
  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      isHome: false,
      fancybox: true,
      pjax: false,
      loading: {
        gif: '/images/theme/loading.gif',
        lottie: ''
      },
      lazyload: {
        enable: true,
        only_post: 'false',
        loading: {
          gif: '/images/theme/loading.gif',
          lottie: ''
        }
      },
      donate: {
        enable: true,
        alipay: '/images/支付宝.JPG',
        wechat: '/images/微信.JPG'
      },
      galleries: {
        enable: true
      },
      fab: {
        enable: true,
        always_show: false
      },
      carrier: {
        enable: true
      },
      daovoice: {
        enable: true
      },
      preview: {
        background: {
          default: '',
          api: ''
        },
        motto: {
          default: '我在开了灯的床头下，想问问自己的心啊。',
          typing: true,
          api: 'https://v2.jinrishici.com/one.json',
          data_contents: '["data","content"]'
        },
      },
      qrcode: {
        enable: true,
        type: 'url',
        image: 'https://pic.izhaoo.com/weapp-code.jpg',
      },
      toc: {
        enable: true
      },
      scrollbar: {
        type: 'default'
      },
      notification: {
        enable: false,
        delay: 4500,
        list: '',
        page_white_list: '',
        page_black_list: ''
      },
      search: {
        enable: true,
        path: '/search.xml'
      }
    }
  </script>

  

  

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>

<body class="lock-screen">
  <div class="loading" id="loading"></div>
  
    


  <nav class="navbar">
    <div class="left">
      
        <i class="iconfont iconhome j-navbar-back-home"></i>
      
      
        <i class="iconfont iconqrcode j-navbar-qrcode"></i>
      
      
        <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i>
      
      
        <i class="iconfont iconsearch j-navbar-search"></i>
      
    </div>
    <div class="center">动手学习深度学习（14）深度学习硬件：计算性能</div>
    <div class="right">
      <i class="iconfont iconmenu j-navbar-menu"></i>
    </div>
    
      <div id="qrcode-navbar"></div>
    
  </nav>

  
  

<nav class="menu">
  <div class="menu-container">
    <div class="menu-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <ul class="menu-content"><li class="menu-item">
        <a href="/ " class="underline "> 首页</a>
      </li><li class="menu-item">
        <a href="/galleries/ " class="underline "> 相册</a>
      </li><li class="menu-item">
        <a href="/archives/ " class="underline "> 归档</a>
      </li><li class="menu-item">
        <a href="/tags/ " class="underline "> 标签</a>
      </li><li class="menu-item">
        <a href="/categories/ " class="underline "> 分类</a>
      </li><li class="menu-item">
        <a href="/about/ " class="underline "> 关于</a>
      </li></ul>
    
      <div class="menu-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
    
  </div>
</nav>
  <main id="main">
  <div class="article-wrap">
    <div class="row container">
      <div class="col-xl-3"></div>
      <div class="col-xl-6"><article class="article">
  <div class="wrap">
    <section class="head">
  <img   class="lazyload" data-original="/images/pat/2.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">动手学习深度学习（14）深度学习硬件：计算性能</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>November 04, 2022</span>
      
        <span class="post-info-item">
          <i class="iconfont iconeye"></i><span id="/2022/11/04/DL_14/" class="leancloud-counter" data-flag-title="动手学习深度学习（14）深度学习硬件：计算性能"></span>
        </span>
        <span class="post-info-item">
          <i class="iconfont iconheart"></i><span id="/2022/11/04/DL_14/" class="leancloud-like" data-flag-title="动手学习深度学习（14）深度学习硬件：计算性能"></span>
        </span>
      
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>8311</span>
    </div>
  </div>
</section>
    <section class="main">
      <section class="content">
        
        <p>很好地理解算法和模型才可以捕获统计方面的问题，构建出具有出色性能的系统。同时，至少对底层硬件有一定的了解也是必不可少的。本节的内容可以作为理解某些算法为什么比其他算法更高效以及如何实现良好吞吐量的起点。</p>
<h2 id="数据并行vs模型并行"><a href="#数据并行vs模型并行" class="headerlink" title="数据并行vs模型并行"></a>数据并行vs模型并行</h2><ul>
<li>数据并行：将小批量分成n块，每个GPU拿到完整参数计算一块数据的梯度；通常性能更好</li>
<li>模型并行：将模型分成n块，每个GPU拿到一块模型计算它的前向后后向结果；通常用于模型大到单GPU放不下</li>
</ul>
<h2 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure>

<p>我们使用 <a target="_blank" rel="noopener" href="https://zh.d2l.ai/chapter_convolutional-neural-networks/lenet.html#sec-lenet">6.6节</a>中介绍的（稍加修改的）LeNet， 从零开始定义它，从而详细说明参数交换和同步。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化模型参数</span><br>scale = <span class="hljs-number">0.01</span><br>W1 = torch.randn(size=(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)) * scale<br>b1 = torch.zeros(<span class="hljs-number">20</span>)<br>W2 = torch.randn(size=(<span class="hljs-number">50</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)) * scale<br>b2 = torch.zeros(<span class="hljs-number">50</span>)<br>W3 = torch.randn(size=(<span class="hljs-number">800</span>, <span class="hljs-number">128</span>)) * scale<br>b3 = torch.zeros(<span class="hljs-number">128</span>)<br>W4 = torch.randn(size=(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)) * scale<br>b4 = torch.zeros(<span class="hljs-number">10</span>)<br>params = [W1, b1, W2, b2, W3, b3, W4, b4]<br><br><span class="hljs-comment"># 定义模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lenet</span>(<span class="hljs-params">X, params</span>):<br>    h1_conv = F.conv2d(<span class="hljs-built_in">input</span>=X, weight=params[<span class="hljs-number">0</span>], bias=params[<span class="hljs-number">1</span>])<br>    h1_activation = F.relu(h1_conv)<br>    h1 = F.avg_pool2d(<span class="hljs-built_in">input</span>=h1_activation, kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>    h2_conv = F.conv2d(<span class="hljs-built_in">input</span>=h1, weight=params[<span class="hljs-number">2</span>], bias=params[<span class="hljs-number">3</span>])<br>    h2_activation = F.relu(h2_conv)<br>    h2 = F.avg_pool2d(<span class="hljs-built_in">input</span>=h2_activation, kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>    h2 = h2.reshape(h2.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br>    h3_linear = torch.mm(h2, params[<span class="hljs-number">4</span>]) + params[<span class="hljs-number">5</span>]<br>    h3 = F.relu(h3_linear)<br>    y_hat = torch.mm(h3, params[<span class="hljs-number">6</span>]) + params[<span class="hljs-number">7</span>]<br>    <span class="hljs-keyword">return</span> y_hat<br><br><span class="hljs-comment"># 交叉熵损失函数</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>向多个设备分发参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_params</span>(<span class="hljs-params">params, device</span>):<br>    new_params = [p.to(device) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> params]<br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> new_params:<br>        p.requires_grad_()<br>    <span class="hljs-keyword">return</span> new_params<br>new_params = get_params(params, d2l.try_gpu(<span class="hljs-number">0</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b1 权重:&#x27;</span>, new_params[<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b1 梯度:&#x27;</span>, new_params[<span class="hljs-number">1</span>].grad)<br><span class="hljs-comment"># output</span><br>b1 权重: tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>       device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b1 梯度: <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure>

<p><code>allreduce</code>函数将所有向量相加，并将结果广播给所有GPU</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">allreduce</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(data)):<br>        data[<span class="hljs-number">0</span>][:] += data[i].to(data[<span class="hljs-number">0</span>].device)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(data)):<br>        data[i][:] = data[<span class="hljs-number">0</span>].to(data[i].device)<br>data = [torch.ones((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), device=d2l.try_gpu(i)) * (i + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;allreduce之前：\n&#x27;</span>, data[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, data[<span class="hljs-number">1</span>])<br>allreduce(data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;allreduce之后：\n&#x27;</span>, data[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, data[<span class="hljs-number">1</span>])<br><span class="hljs-comment"># output</span><br>allreduce之前：<br> tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br> tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br>allreduce之后：<br> tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br> tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>我们需要一个简单的工具函数，将一个小批量数据均匀地分布在多个GPU上。 例如，有两个GPU时，我们希望每个GPU可以复制一半的数据。 因为深度学习框架的内置函数编写代码更方便、更简洁，所以在4×5矩阵上使用它进行尝试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">data = torch.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>devices = [torch.device(<span class="hljs-string">&#x27;cuda:0&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda:1&#x27;</span>)]<br>split = nn.parallel.scatter(data, devices)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;input :&#x27;</span>, data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;load into&#x27;</span>, devices)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;output:&#x27;</span>, split)<br><span class="hljs-comment"># output</span><br><span class="hljs-built_in">input</span> : tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>],<br>        [ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>],<br>        [<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>]])<br>load into [device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br>output: (tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>), tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>))<br></code></pre></td></tr></table></figure>

<p>为了方便以后复用，我们定义了可以同时拆分数据和标签的<code>split_batch</code>函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">split_batch</span>(<span class="hljs-params">X, y, devices</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将X和y拆分到多个设备上&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">assert</span> X.shape[<span class="hljs-number">0</span>] == y.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> (nn.parallel.scatter(X, devices),<br>            nn.parallel.scatter(y, devices))<br></code></pre></td></tr></table></figure>

<p>训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch</span>(<span class="hljs-params">X, y, device_params, devices, lr</span>):<br>    X_shards, y_shards = split_batch(X, y, devices)<br>    <span class="hljs-comment"># 在每个GPU上分别计算损失</span><br>    ls = [loss(lenet(X_shard, device_W), y_shard).<span class="hljs-built_in">sum</span>()<br>          <span class="hljs-keyword">for</span> X_shard, y_shard, device_W <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>              X_shards, y_shards, device_params)]<br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> ls:  <span class="hljs-comment"># 反向传播在每个GPU上分别执行</span><br>        l.backward()<br>    <span class="hljs-comment"># 将每个GPU的所有梯度相加，并将其广播到所有GPU</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(device_params[<span class="hljs-number">0</span>])):<br>            allreduce(<br>                [device_params[c][i].grad <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(devices))])<br>    <span class="hljs-comment"># 在每个GPU上分别更新模型参数</span><br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> device_params:<br>        d2l.sgd(param, lr, X.shape[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 在这里，我们使用全尺寸的小批量</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">num_gpus, batch_size, lr</span>):<br>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>    devices = [d2l.try_gpu(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gpus)]<br>    <span class="hljs-comment"># 将模型参数复制到num_gpus个GPU</span><br>    device_params = [get_params(params, d) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> devices]<br>    num_epochs = <span class="hljs-number">10</span><br>    animator = d2l.Animator(<span class="hljs-string">&#x27;epoch&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs])<br>    timer = d2l.Timer()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        timer.start()<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-comment"># 为单个小批量执行多GPU训练</span><br>            train_batch(X, y, device_params, devices, lr)<br>            torch.cuda.synchronize()<br>        timer.stop()<br>        <span class="hljs-comment"># 在GPU0上评估模型</span><br>        animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_accuracy_gpu(<br>            <span class="hljs-keyword">lambda</span> x: lenet(x, device_params[<span class="hljs-number">0</span>]), test_iter, devices[<span class="hljs-number">0</span>]),))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;测试精度：<span class="hljs-subst">&#123;animator.Y[<span class="hljs-number">0</span>][-<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>，<span class="hljs-subst">&#123;timer.avg():<span class="hljs-number">.1</span>f&#125;</span>秒/轮，&#x27;</span><br>          <span class="hljs-string">f&#x27;在<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train(num_gpus=<span class="hljs-number">1</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.80</span>，<span class="hljs-number">2.7</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>)]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">train(num_gpus=<span class="hljs-number">2</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.84</span>，<span class="hljs-number">2.8</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br><br></code></pre></td></tr></table></figure>

<p>多GPU的简洁实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet18</span>(<span class="hljs-params">num_classes, in_channels=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;稍加修改的ResNet-18模型&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">in_channels, out_channels, num_residuals,</span><br><span class="hljs-params">                     first_block=<span class="hljs-literal">False</span></span>):<br>        blk = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                blk.append(d2l.Residual(in_channels, out_channels,<br>                                        use_1x1conv=<span class="hljs-literal">True</span>, strides=<span class="hljs-number">2</span>))<br>            <span class="hljs-keyword">else</span>:<br>                blk.append(d2l.Residual(out_channels, out_channels))<br>        <span class="hljs-keyword">return</span> nn.Sequential(*blk)<br><br>    <span class="hljs-comment"># 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层</span><br>    net = nn.Sequential(<br>        nn.Conv2d(in_channels, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>        nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>        nn.ReLU())<br>    net.add_module(<span class="hljs-string">&quot;resnet_block1&quot;</span>, resnet_block(<br>        <span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block2&quot;</span>, resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block3&quot;</span>, resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block4&quot;</span>, resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;global_avg_pool&quot;</span>, nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br>    net.add_module(<span class="hljs-string">&quot;fc&quot;</span>, nn.Sequential(nn.Flatten(),<br>                                       nn.Linear(<span class="hljs-number">512</span>, num_classes)))<br>    <span class="hljs-keyword">return</span> net<br><br>net = resnet18(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># 获取GPU列表</span><br>devices = d2l.try_all_gpus()<br><span class="hljs-comment"># 我们将在训练代码实现中初始化网络</span><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, num_gpus, batch_size, lr</span>):<br>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>    devices = [d2l.try_gpu(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gpus)]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) <span class="hljs-keyword">in</span> [nn.Linear, nn.Conv2d]:<br>            nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br>    net.apply(init_weights)<br>    <span class="hljs-comment"># 在多个GPU上设置模型</span><br>    net = nn.DataParallel(net, device_ids=devices)<br>    trainer = torch.optim.SGD(net.parameters(), lr)<br>    loss = nn.CrossEntropyLoss()<br>    timer, num_epochs = d2l.Timer(), <span class="hljs-number">10</span><br>    animator = d2l.Animator(<span class="hljs-string">&#x27;epoch&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        net.train()<br>        timer.start()<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            X, y = X.to(devices[<span class="hljs-number">0</span>]), y.to(devices[<span class="hljs-number">0</span>])<br>            l = loss(net(X), y)<br>            l.backward()<br>            trainer.step()<br>        timer.stop()<br>        animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_accuracy_gpu(net, test_iter),))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;测试精度：<span class="hljs-subst">&#123;animator.Y[<span class="hljs-number">0</span>][-<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>，<span class="hljs-subst">&#123;timer.avg():<span class="hljs-number">.1</span>f&#125;</span>秒/轮，&#x27;</span><br>          <span class="hljs-string">f&#x27;在<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train(net, num_gpus=<span class="hljs-number">1</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.1</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.92</span>，<span class="hljs-number">13.7</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>)]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">train(net, num_gpus=<span class="hljs-number">2</span>, batch_size=<span class="hljs-number">512</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.89</span>，<span class="hljs-number">8.4</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br></code></pre></td></tr></table></figure>

      </section>
      <section class="extra">
        
          <ul class="copyright">
  
    <li><strong>本文作者：</strong>茴香豆</li>
    <li><strong>本文链接：</strong><a href="https://hxiangdou.github.io/2022/11/04/DL_14/index.html" title="https:&#x2F;&#x2F;hxiangdou.github.io&#x2F;2022&#x2F;11&#x2F;04&#x2F;DL_14&#x2F;index.html">https:&#x2F;&#x2F;hxiangdou.github.io&#x2F;2022&#x2F;11&#x2F;04&#x2F;DL_14&#x2F;index.html</a></li>
    <li><strong>版权声明：</strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="BY-NC-SA" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请注明出处！</li>
  
</ul>
        
        
          <section class="donate">
  <div id="qrcode-donate">
    <img   class="lazyload" data-original="/images/支付宝.JPG" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" >
  </div>
  <div class="icon">
    <a href="javascript:;" id="alipay"><i class="iconfont iconalipay"></i></a>
    <a href="javascript:;" id="wechat"><i class="iconfont iconwechat-fill"></i></a>
  </div>
</section>
        
        
  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul> 

        
  <nav class="nav">
    <a href="/2022/11/07/DL_15/"><i class="iconfont iconleft"></i>动手学习深度学习（14）图像增广和微调</a>
    <a href="/2022/11/04/Latex/">LaTex学习<i class="iconfont iconright"></i></a>
  </nav>

      </section>
      
        <section class="comments">
  
    <div class="btn" id="comments-btn">查看评论</div>
  
  
<div id="valine"></div>
<script defer src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  window.onload = function () {
    var loadValine = function () {
      new Valine({
        el: '#valine',
        app_id: "eSrfpdL3XjSFRaFUwnuRl3dn-gzGzoHsz",
        app_key: "6DvkgciWlfleRrT7w9r6snJI",
        placeholder: "雁过留痕",
        avatar: "mp",
        pageSize: "10",
        lang: "zh-CN",
      });
    }
    if ( true ) {
      $("#comments-btn").on("click", function () {
        $(this).hide();
        loadValine();
      });
    } else {
      loadValine();
    }
  };
</script>

</section>
      
    </section>
  </div>
</article></div>
      <div class="col-xl-3">
        
          
  <aside class="toc-wrap">
    <h3 class="toc-title">文章目录：</h3>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8Cvs%E6%A8%A1%E5%9E%8B%E5%B9%B6%E8%A1%8C"><span class="toc-text">数据并行vs模型并行</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9AGPU%E8%AE%AD%E7%BB%83"><span class="toc-text">多GPU训练</span></a></li></ol>
  </aside>

        
      </div>
    </div>
  </div>
</main>
  

<footer class="footer">
  <div class="footer-social"><a 
        href="tencent://message/?Menu=yes&uin=1134384717 "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#12B7F5'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconQQ "></i>
      </a><a 
        href="javascript:; "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#09BB07'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconwechat-fill "></i>
      </a><a 
        href="https://www.instagram.com/ "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#DA2E76'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconinstagram "></i>
      </a><a 
        href="https://github.com/Squirrel00011 "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#9f7be1'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  icongithub-fill "></i>
      </a><a 
        href="mailto:1134384717@qq.com "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color=#ff3b00" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconmail"></i>
      </a></div>
  
    <div class="footer-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
  
</footer>
  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
    <div class="fab fab-like">
      <i class="iconfont iconheart"></i>
    </div>
  
  
    <div class="fab fab-daovoice">
      <i class="iconfont iconcomment"></i>
    </div>
  
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  
  
  
    
<script src="/js/color-mode.js"></script>

  
  
    <div class="search">
  <div class="search-container">
    <div class="search-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <div class="search-input-wrapper">
      <i class="search-input-icon iconfont iconsearch"></i>
      <input class="search-input" type="search" id="search-input" placeholder="Search..." autofocus autocomplete="off"
        autocorrect="off" autocapitalize="off">
    </div>
    <div class="search-output" id="search-output"></div>
  </div>
</div>
  
</body>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>





  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.lazyload/1.9.1/jquery.lazyload.min.js"></script>




  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script>






  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.qrcode/1.0/jquery.qrcode.min.js"></script>




<script src="/js/utils.js"></script>
<script src="/js/script.js"></script>



  <script>
  $.getScript("//cdn.jsdelivr.net/npm/leancloud-storage@4.1.0/dist/av-min.js", () => {

    AV.init({
      appId: 'eSrfpdL3XjSFRaFUwnuRl3dn-gzGzoHsz',
      appKey: '6DvkgciWlfleRrT7w9r6snJI',
      serverURLs: 'https://leancloud.cn/',
    });

    const Counter = AV.Object.extend("Counter");
    const Like = AV.Object.extend("Like");

    const showCount = (Counter) => {
      const asyncLimit = new AsyncLimit(2);
      $(".leancloud-counter").each(async (e) => {
        const url = $(".leancloud-counter").eq(e).attr('id').trim();
        const query = new AV.Query("Counter");
        query.equalTo("words", url);
        let count = await asyncLimit.run(() => query.count());
        $(".leancloud-counter").eq(e).text(count ? count : 0);
      });
    }

    const addCount = (Counter) => {
      const url = $(".leancloud-counter").length === 1 ? $(".leancloud-counter").attr('id').trim() : 'https://hxiangdou.github.io';
      var query = new Counter;
      query.save({
        words: url
      });
    }

    const showLike = (Like) => {
      const asyncLimit = new AsyncLimit(2);
      $(".leancloud-like").each(async (e) => {
        const url = $(".leancloud-like").eq(e).attr('id').trim();
        const query = new AV.Query("Like");
        query.equalTo("path", url);
        let count = await asyncLimit.run(() => query.count());
        $(".leancloud-like").eq(e).text(count ? count : 0);
      });
    }

    const addLike = (Like) => {
      const url = $(".leancloud-like").length === 1 ? $(".leancloud-like").attr('id').trim() : 'https://hxiangdou.github.io';
      var query = new Like;
      query.save({
        path: url,
        nickName: 'Anonymous'
      });
      $(".leancloud-like").addClass('islike');
      $(".fab-like").children(".iconfont").removeClass("iconheart").addClass("iconheart-fill").css("color", "#eb3223");
      ZHAOO.zui.message({ text: '爱你哦~', type: 'success' });
      setTimeout(() => showLike(Like), 1000);
    }

    const handleLikeClick = () => {
      const isLike = $(".leancloud-like").length === 1 && $(".leancloud-like").hasClass('islike') ? true : false;
      if (isLike) {
        ZHAOO.zui.message({ text: '小心心不可以收回呢~', type: 'warning' });
      } else {
        addLike(Like);
      }
    }

    $(function () {
      addCount(Counter);
      showCount(Counter);
      showLike(Like);
      $(".fab-like").on("click", function () {
        handleLikeClick();
      });
    });

  });
</script>



  

<script>
  (function (i, s, o, g, r, a, m) {
    i["DaoVoiceObject"] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date();
    a = s.createElement(o), m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    a.charset = "utf-8";
    m.parentNode.insertBefore(a, m)
  })(window, document, "script", "https://widget.daovoice.io/widget/0f81ff2f.js", "daovoice")
  daovoice('init', {
    app_id: "38fcd752"
  }, {
    launcher: {
      disableLauncherIcon: true,
    },
  });
  daovoice('update');
</script>



  <script>
    (function () {
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>













</html>