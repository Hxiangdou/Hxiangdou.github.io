

<!DOCTYPE html>
<html lang="en" color-mode=light>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>动手学习深度学习（15）图像增广和微调 - Hexo</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />
  
  <meta name="description" content="我们提到过大型数据集是成功应用深度神经网络的先决条件。...">
  <meta name="author" content="茴香豆">
  <link rel="icon" href="/images/icons/favicon-16x16.png" type="image/png" sizes="16x16">
  <link rel="icon" href="/images/icons/favicon-32x32.png" type="image/png" sizes="32x32">
  <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180">
  <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon-144x144.png">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
    
<link rel="stylesheet" href="https://at.alicdn.com/t/font_1445822_p6ry5n7lrr.css">

  

  
    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css">

  

  
    
      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/xcode.min.css" name="highlight-style" mode="light">

      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/solarized-dark.min.css" name="highlight-style" mode="dark">

      
  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      isHome: false,
      fancybox: true,
      pjax: false,
      loading: {
        gif: '/images/theme/loading.gif',
        lottie: ''
      },
      lazyload: {
        enable: true,
        only_post: 'false',
        loading: {
          gif: '/images/theme/loading.gif',
          lottie: ''
        }
      },
      donate: {
        enable: true,
        alipay: '/images/支付宝.JPG',
        wechat: '/images/微信.JPG'
      },
      galleries: {
        enable: true
      },
      fab: {
        enable: true,
        always_show: false
      },
      carrier: {
        enable: true
      },
      daovoice: {
        enable: true
      },
      preview: {
        background: {
          default: '',
          api: ''
        },
        motto: {
          default: '我在开了灯的床头下，想问问自己的心啊。',
          typing: true,
          api: 'https://v2.jinrishici.com/one.json',
          data_contents: '["data","content"]'
        },
      },
      qrcode: {
        enable: true,
        type: 'url',
        image: 'https://pic.izhaoo.com/weapp-code.jpg',
      },
      toc: {
        enable: true
      },
      scrollbar: {
        type: 'default'
      },
      notification: {
        enable: false,
        delay: 4500,
        list: '',
        page_white_list: '',
        page_black_list: ''
      },
      search: {
        enable: true,
        path: '/search.xml'
      }
    }
  </script>

  

  

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head>

<body class="lock-screen">
  <div class="loading" id="loading"></div>
  
    


  <nav class="navbar">
    <div class="left">
      
        <i class="iconfont iconhome j-navbar-back-home"></i>
      
      
        <i class="iconfont iconqrcode j-navbar-qrcode"></i>
      
      
        <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i>
      
      
        <i class="iconfont iconsearch j-navbar-search"></i>
      
    </div>
    <div class="center">动手学习深度学习（15）图像增广和微调</div>
    <div class="right">
      <i class="iconfont iconmenu j-navbar-menu"></i>
    </div>
    
      <div id="qrcode-navbar"></div>
    
  </nav>

  
  

<nav class="menu">
  <div class="menu-container">
    <div class="menu-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <ul class="menu-content"><li class="menu-item">
        <a href="/ " class="underline "> 首页</a>
      </li><li class="menu-item">
        <a href="/galleries/ " class="underline "> 相册</a>
      </li><li class="menu-item">
        <a href="/archives/ " class="underline "> 归档</a>
      </li><li class="menu-item">
        <a href="/tags/ " class="underline "> 标签</a>
      </li><li class="menu-item">
        <a href="/categories/ " class="underline "> 分类</a>
      </li><li class="menu-item">
        <a href="/about/ " class="underline "> 关于</a>
      </li></ul>
    
      <div class="menu-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
    
  </div>
</nav>
  <main id="main">
  <div class="article-wrap">
    <div class="row container">
      <div class="col-xl-3"></div>
      <div class="col-xl-6"><article class="article">
  <div class="wrap">
    <section class="head">
  <img   class="lazyload" data-original="/images/pat/2.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">动手学习深度学习（15）图像增广和微调</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>November 07, 2022</span>
      
        <span class="post-info-item">
          <i class="iconfont iconeye"></i><span id="/2022/11/07/DL_15/" class="leancloud-counter" data-flag-title="动手学习深度学习（15）图像增广和微调"></span>
        </span>
        <span class="post-info-item">
          <i class="iconfont iconheart"></i><span id="/2022/11/07/DL_15/" class="leancloud-like" data-flag-title="动手学习深度学习（15）图像增广和微调"></span>
        </span>
      
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>8784</span>
    </div>
  </div>
</section>
    <section class="main">
      <section class="content">
        
        <p>我们提到过大型数据集是成功应用深度神经网络的先决条件。</p>
<h2 id="1-图像增广"><a href="#1-图像增广" class="headerlink" title="1.图像增广"></a>1.图像增广</h2><p>图像增广在对训练图像进行一系列的随机变化之后，生成相似但不同的训练样本，从而扩大了训练集的规模。 此外，应用图像增广的原因是，随机改变训练样本可以减少模型对某些属性的依赖，从而提高模型的泛化能力。例如，我们可以以不同的方式裁剪图像，使感兴趣的对象出现在不同的位置，减少模型对于对象出现位置的依赖。 我们还可以调整亮度、颜色等因素来降低模型对颜色的敏感度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-comment"># 将使用下面这个尺寸为400x500的图像作为示例</span><br>d2l.set_figsize()<br>img = d2l.Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../img/cat1.jpg&#x27;</span>)<br>d2l.plt.imshow(img);<br><span class="hljs-comment"># 定义辅助函数apply。 此函数在输入图像img上多次运行图像增广方法aug并显示所有结果。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply</span>(<span class="hljs-params">img, aug, num_rows=<span class="hljs-number">2</span>, num_cols=<span class="hljs-number">4</span>, scale=<span class="hljs-number">1.5</span></span>):<br>    Y = [aug(img) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_rows * num_cols)]<br>    d2l.show_images(Y, num_rows, num_cols, scale=scale)<br><span class="hljs-comment"># 翻转和裁剪</span><br>apply(img, torchvision.transforms.RandomHorizontalFlip())<br>apply(img, torchvision.transforms.RandomVerticalFlip())<br>shape_aug = torchvision.transforms.RandomResizedCrop(<br>    (<span class="hljs-number">200</span>, <span class="hljs-number">200</span>), scale=(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>), ratio=(<span class="hljs-number">0.5</span>, <span class="hljs-number">2</span>))<br>apply(img, shape_aug)<br><span class="hljs-comment"># 改变颜色</span><br>apply(img, torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0</span>, saturation=<span class="hljs-number">0</span>, hue=<span class="hljs-number">0</span>))<br>apply(img, torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0</span>, contrast=<span class="hljs-number">0</span>, saturation=<span class="hljs-number">0</span>, hue=<span class="hljs-number">0.5</span>))<br>color_aug = torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0.5</span>, saturation=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>)<br>apply(img, color_aug)<br><span class="hljs-comment"># 结合多种图像增广方法</span><br>augs = torchvision.transforms.Compose([<br>    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])<br>apply(img, augs)<br></code></pre></td></tr></table></figure>

<h3 id="利用图像增广进行训练"><a href="#利用图像增广进行训练" class="headerlink" title="利用图像增广进行训练"></a>利用图像增广进行训练</h3><p>这里，我们使用CIFAR-10数据集，而不是我们之前使用的Fashion-MNIST数据集。 这是因为Fashion-MNIST数据集中对象的位置和大小已被规范化，而CIFAR-10数据集中对象的颜色和大小差异更明显。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python">all_images = torchvision.datasets.CIFAR10(train=<span class="hljs-literal">True</span>, root=<span class="hljs-string">&quot;../data&quot;</span>, download=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 我们使用ToTensor实例将一批图像转换为深度学习框架所要求的格式，</span><br><span class="hljs-comment"># 即形状为（批量大小，通道数，高度，宽度）的32位浮点数，取值范围为0到1。</span><br>train_augs = torchvision.transforms.Compose([<br>     torchvision.transforms.RandomHorizontalFlip(),<br>     torchvision.transforms.ToTensor()])<br><br>test_augs = torchvision.transforms.Compose([<br>     torchvision.transforms.ToTensor()])<br><span class="hljs-comment"># 定义一个辅助函数，以便于读取图像和应用图像增广。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_cifar10</span>(<span class="hljs-params">is_train, augs, batch_size</span>):<br>    dataset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;../data&quot;</span>, train=is_train,<br>                                           transform=augs, download=<span class="hljs-literal">True</span>)<br>    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,<br>                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())<br>    <span class="hljs-keyword">return</span> dataloader<br><span class="hljs-comment"># 多GPU训练</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch_ch13</span>(<span class="hljs-params">net, X, y, loss, trainer, devices</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用多GPU进行小批量训练&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>        <span class="hljs-comment"># 微调BERT中所需（稍后讨论）</span><br>        X = [x.to(devices[<span class="hljs-number">0</span>]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>    <span class="hljs-keyword">else</span>:<br>        X = X.to(devices[<span class="hljs-number">0</span>])<br>    y = y.to(devices[<span class="hljs-number">0</span>])<br>    net.train()<br>    trainer.zero_grad()<br>    pred = net(X)<br>    l = loss(pred, y)<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    trainer.step()<br>    train_loss_sum = l.<span class="hljs-built_in">sum</span>()<br>    train_acc_sum = d2l.accuracy(pred, y)<br>    <span class="hljs-keyword">return</span> train_loss_sum, train_acc_sum<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch13</span>(<span class="hljs-params">net, train_iter, test_iter, loss, trainer, num_epochs,</span><br><span class="hljs-params">               devices=d2l.try_all_gpus(<span class="hljs-params"></span>)</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用多GPU进行模型训练&quot;&quot;&quot;</span><br>    timer, num_batches = d2l.Timer(), <span class="hljs-built_in">len</span>(train_iter)<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs], ylim=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>                            legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    net = nn.DataParallel(net, device_ids=devices).to(devices[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-comment"># 4个维度：储存训练损失，训练准确度，实例数，特点数</span><br>        metric = d2l.Accumulator(<span class="hljs-number">4</span>)<br>        <span class="hljs-keyword">for</span> i, (features, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            timer.start()<br>            l, acc = train_batch_ch13(<br>                net, features, labels, loss, trainer, devices)<br>            metric.add(l, acc, labels.shape[<span class="hljs-number">0</span>], labels.numel())<br>            timer.stop()<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % (num_batches // <span class="hljs-number">5</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> i == num_batches - <span class="hljs-number">1</span>:<br>                animator.add(epoch + (i + <span class="hljs-number">1</span>) / num_batches,<br>                             (metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>], metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">3</span>],<br>                              <span class="hljs-literal">None</span>))<br>        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>, train acc &#x27;</span><br>          <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">3</span>]:<span class="hljs-number">.3</span>f&#125;</span>, test acc <span class="hljs-subst">&#123;test_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">2</span>] * num_epochs / timer.<span class="hljs-built_in">sum</span>():<span class="hljs-number">.1</span>f&#125;</span> examples/sec on &#x27;</span><br>          <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br><span class="hljs-comment"># 定义train_with_data_aug函数，使用图像增广来训练模型。</span><br><span class="hljs-comment"># 该函数获取所有的GPU，并使用Adam作为训练的优化算法，将图像增广应用于训练集，</span><br><span class="hljs-comment"># 最后调用刚刚定义的用于训练和评估模型的train_ch13函数。</span><br>batch_size, devices, net = <span class="hljs-number">256</span>, d2l.try_all_gpus(), d2l.resnet18(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) <span class="hljs-keyword">in</span> [nn.Linear, nn.Conv2d]:<br>        nn.init.xavier_uniform_(m.weight)<br><br>net.apply(init_weights)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_with_data_aug</span>(<span class="hljs-params">train_augs, test_augs, net, lr=<span class="hljs-number">0.001</span></span>):<br>    train_iter = load_cifar10(<span class="hljs-literal">True</span>, train_augs, batch_size)<br>    test_iter = load_cifar10(<span class="hljs-literal">False</span>, test_augs, batch_size)<br>    loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br>    trainer = torch.optim.Adam(net.parameters(), lr=lr)<br>    train_ch13(net, train_iter, test_iter, loss, trainer, <span class="hljs-number">10</span>, devices)<br><span class="hljs-comment"># 基于随机左右翻转的图像增广来训练模型。</span><br>train_with_data_aug(train_augs, test_augs, net)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.177, train acc 0.938, test acc 0.835</span><br><span class="hljs-comment"># 5616.3 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>

<h2 id="2-微调（重点技术）"><a href="#2-微调（重点技术）" class="headerlink" title="2.微调（重点技术）"></a>2.微调（重点技术）</h2><ul>
<li>微调通过使用在大数据集上得到的预训练好的模型来初始化模型权重来完成提升精度</li>
<li>预训练模型质量很重要</li>
<li>微调通常速度更快、精度更高</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># 获取数据集</span><br><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">&#x27;hotdog&#x27;</span>] = (d2l.DATA_URL + <span class="hljs-string">&#x27;hotdog.zip&#x27;</span>,    <span class="hljs-string">&#x27;fba480ffa8aa7e0febbb511d181409f899b9baa5&#x27;</span>)<br>data_dir = d2l.download_extract(<span class="hljs-string">&#x27;hotdog&#x27;</span>)<br><span class="hljs-comment"># 创建两个实例来分别读取训练和测试数据集中的所有图像文件。</span><br>train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>))<br>test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>))<br><span class="hljs-comment"># 使用RGB通道的均值和标准差，以标准化每个通道</span><br>normalize = torchvision.transforms.Normalize(<br>    [<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br><br>train_augs = torchvision.transforms.Compose([<br>    torchvision.transforms.RandomResizedCrop(<span class="hljs-number">224</span>),<br>    torchvision.transforms.RandomHorizontalFlip(),<br>    torchvision.transforms.ToTensor(),<br>    normalize])<br><br>test_augs = torchvision.transforms.Compose([<br>    torchvision.transforms.Resize(<span class="hljs-number">256</span>),<br>    torchvision.transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    torchvision.transforms.ToTensor(),<br>    normalize])<br><span class="hljs-comment"># 定义和初始化模型</span><br>pretrained_net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># print(pretrained_net.fc)</span><br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># Linear(in_features=512, out_features=1000, bias=True)</span><br>finetune_net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br>finetune_net.fc = nn.Linear(finetune_net.fc.in_features, <span class="hljs-number">2</span>)<br>nn.init.xavier_uniform_(finetune_net.fc.weight)<br><span class="hljs-comment"># 微调模型</span><br><span class="hljs-comment"># 如果param_group=True，输出层中的模型参数将使用十倍的学习率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_fine_tuning</span>(<span class="hljs-params">net, learning_rate, batch_size=<span class="hljs-number">128</span>, num_epochs=<span class="hljs-number">5</span>,</span><br><span class="hljs-params">                      param_group=<span class="hljs-literal">True</span></span>):<br>    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>), transform=train_augs),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>), transform=test_augs),<br>        batch_size=batch_size)<br>    devices = d2l.try_all_gpus()<br>    loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br>    <span class="hljs-keyword">if</span> param_group:<br>        params_1x = [param <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net.named_parameters()<br>             <span class="hljs-keyword">if</span> name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;fc.weight&quot;</span>, <span class="hljs-string">&quot;fc.bias&quot;</span>]]<br>        trainer = torch.optim.SGD([&#123;<span class="hljs-string">&#x27;params&#x27;</span>: params_1x&#125;,<br>                                   &#123;<span class="hljs-string">&#x27;params&#x27;</span>: net.fc.parameters(),<br>                                    <span class="hljs-string">&#x27;lr&#x27;</span>: learning_rate * <span class="hljs-number">10</span>&#125;],<br>                                lr=learning_rate, weight_decay=<span class="hljs-number">0.001</span>)<br>    <span class="hljs-keyword">else</span>:<br>        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,<br>                                  weight_decay=<span class="hljs-number">0.001</span>)<br>    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,<br>                   devices)<br>train_fine_tuning(finetune_net, <span class="hljs-number">5e-5</span>)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.191, train acc 0.931, test acc 0.949</span><br><span class="hljs-comment"># 1086.6 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>

<p>为了进行比较，我们定义了一个相同的模型，但是将其所有模型参数初始化为随机值。 由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">scratch_net = torchvision.models.resnet18()<br>scratch_net.fc = nn.Linear(scratch_net.fc.in_features, <span class="hljs-number">2</span>)<br>train_fine_tuning(scratch_net, <span class="hljs-number">5e-4</span>, param_group=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.390, train acc 0.828, test acc 0.826</span><br><span class="hljs-comment"># 1610.3 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>

      </section>
      <section class="extra">
        
          <ul class="copyright">
  
    <li><strong>本文作者：</strong>茴香豆</li>
    <li><strong>本文链接：</strong><a href="https://hxiangdou.github.io/2022/11/07/DL_15/index.html" title="https:&#x2F;&#x2F;hxiangdou.github.io&#x2F;2022&#x2F;11&#x2F;07&#x2F;DL_15&#x2F;index.html">https:&#x2F;&#x2F;hxiangdou.github.io&#x2F;2022&#x2F;11&#x2F;07&#x2F;DL_15&#x2F;index.html</a></li>
    <li><strong>版权声明：</strong>本博客所有文章均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" title="BY-NC-SA" target="_blank" rel="noopener">BY-NC-SA</a> 许可协议，转载请注明出处！</li>
  
</ul>
        
        
          <section class="donate">
  <div id="qrcode-donate">
    <img   class="lazyload" data-original="/images/支付宝.JPG" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" >
  </div>
  <div class="icon">
    <a href="javascript:;" id="alipay"><i class="iconfont iconalipay"></i></a>
    <a href="javascript:;" id="wechat"><i class="iconfont iconwechat-fill"></i></a>
  </div>
</section>
        
        
  <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/DeepLearning/" rel="tag">DeepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li></ul> 

        
  <nav class="nav">
    <a href="/2022/11/08/DL_16/"><i class="iconfont iconleft"></i>动手学习深度学习（16）物体检测和数据集</a>
    <a href="/2022/11/04/DL_14/">动手学习深度学习（14）深度学习硬件：计算性能<i class="iconfont iconright"></i></a>
  </nav>

      </section>
      
        <section class="comments">
  
    <div class="btn" id="comments-btn">查看评论</div>
  
  
<div id="valine"></div>
<script defer src="//unpkg.com/valine/dist/Valine.min.js"></script>
<script>
  window.onload = function () {
    var loadValine = function () {
      new Valine({
        el: '#valine',
        app_id: "eSrfpdL3XjSFRaFUwnuRl3dn-gzGzoHsz",
        app_key: "6DvkgciWlfleRrT7w9r6snJI",
        placeholder: "雁过留痕",
        avatar: "mp",
        pageSize: "10",
        lang: "zh-CN",
      });
    }
    if ( true ) {
      $("#comments-btn").on("click", function () {
        $(this).hide();
        loadValine();
      });
    } else {
      loadValine();
    }
  };
</script>

</section>
      
    </section>
  </div>
</article></div>
      <div class="col-xl-3">
        
          
  <aside class="toc-wrap">
    <h3 class="toc-title">文章目录：</h3>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF"><span class="toc-text">1.图像增广</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83"><span class="toc-text">利用图像增广进行训练</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%BE%AE%E8%B0%83%EF%BC%88%E9%87%8D%E7%82%B9%E6%8A%80%E6%9C%AF%EF%BC%89"><span class="toc-text">2.微调（重点技术）</span></a></li></ol>
  </aside>

        
      </div>
    </div>
  </div>
</main>
  

<footer class="footer">
  <div class="footer-social"><a 
        href="tencent://message/?Menu=yes&uin=1134384717 "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#12B7F5'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconQQ "></i>
      </a><a 
        href="javascript:; "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#09BB07'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconwechat-fill "></i>
      </a><a 
        href="https://www.instagram.com/ "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#DA2E76'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconinstagram "></i>
      </a><a 
        href="https://github.com/Squirrel00011 "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color= '#9f7be1'" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  icongithub-fill "></i>
      </a><a 
        href="mailto:1134384717@qq.com "
        target="_blank"
        class="footer-social-item"
        onMouseOver="this.style.color=#ff3b00" 
        onMouseOut="this.style.color='#33333D'">
          <i class="iconfont  iconmail"></i>
      </a></div>
  
    <div class="footer-copyright"><p>Powered by <a target="_blank" href="https://hexo.io">Hexo</a>  |  Theme - <a target="_blank" href="https://github.com/izhaoo/hexo-theme-zhaoo">zhaoo</a></p></div>
  
</footer>
  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
    <div class="fab fab-like">
      <i class="iconfont iconheart"></i>
    </div>
  
  
    <div class="fab fab-daovoice">
      <i class="iconfont iconcomment"></i>
    </div>
  
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  
  
  
    
<script src="/js/color-mode.js"></script>

  
  
    <div class="search">
  <div class="search-container">
    <div class="search-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <div class="search-input-wrapper">
      <i class="search-input-icon iconfont iconsearch"></i>
      <input class="search-input" type="search" id="search-input" placeholder="Search..." autofocus autocomplete="off"
        autocorrect="off" autocapitalize="off">
    </div>
    <div class="search-output" id="search-output"></div>
  </div>
</div>
  
</body>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>





  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.lazyload/1.9.1/jquery.lazyload.min.js"></script>




  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script>






  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.qrcode/1.0/jquery.qrcode.min.js"></script>




<script src="/js/utils.js"></script>
<script src="/js/script.js"></script>



  <script>
  $.getScript("//cdn.jsdelivr.net/npm/leancloud-storage@4.1.0/dist/av-min.js", () => {

    AV.init({
      appId: 'eSrfpdL3XjSFRaFUwnuRl3dn-gzGzoHsz',
      appKey: '6DvkgciWlfleRrT7w9r6snJI',
      serverURLs: 'https://leancloud.cn/',
    });

    const Counter = AV.Object.extend("Counter");
    const Like = AV.Object.extend("Like");

    const showCount = (Counter) => {
      const asyncLimit = new AsyncLimit(2);
      $(".leancloud-counter").each(async (e) => {
        const url = $(".leancloud-counter").eq(e).attr('id').trim();
        const query = new AV.Query("Counter");
        query.equalTo("words", url);
        let count = await asyncLimit.run(() => query.count());
        $(".leancloud-counter").eq(e).text(count ? count : 0);
      });
    }

    const addCount = (Counter) => {
      const url = $(".leancloud-counter").length === 1 ? $(".leancloud-counter").attr('id').trim() : 'https://hxiangdou.github.io';
      var query = new Counter;
      query.save({
        words: url
      });
    }

    const showLike = (Like) => {
      const asyncLimit = new AsyncLimit(2);
      $(".leancloud-like").each(async (e) => {
        const url = $(".leancloud-like").eq(e).attr('id').trim();
        const query = new AV.Query("Like");
        query.equalTo("path", url);
        let count = await asyncLimit.run(() => query.count());
        $(".leancloud-like").eq(e).text(count ? count : 0);
      });
    }

    const addLike = (Like) => {
      const url = $(".leancloud-like").length === 1 ? $(".leancloud-like").attr('id').trim() : 'https://hxiangdou.github.io';
      var query = new Like;
      query.save({
        path: url,
        nickName: 'Anonymous'
      });
      $(".leancloud-like").addClass('islike');
      $(".fab-like").children(".iconfont").removeClass("iconheart").addClass("iconheart-fill").css("color", "#eb3223");
      ZHAOO.zui.message({ text: '爱你哦~', type: 'success' });
      setTimeout(() => showLike(Like), 1000);
    }

    const handleLikeClick = () => {
      const isLike = $(".leancloud-like").length === 1 && $(".leancloud-like").hasClass('islike') ? true : false;
      if (isLike) {
        ZHAOO.zui.message({ text: '小心心不可以收回呢~', type: 'warning' });
      } else {
        addLike(Like);
      }
    }

    $(function () {
      addCount(Counter);
      showCount(Counter);
      showLike(Like);
      $(".fab-like").on("click", function () {
        handleLikeClick();
      });
    });

  });
</script>



  

<script>
  (function (i, s, o, g, r, a, m) {
    i["DaoVoiceObject"] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date();
    a = s.createElement(o), m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    a.charset = "utf-8";
    m.parentNode.insertBefore(a, m)
  })(window, document, "script", "https://widget.daovoice.io/widget/0f81ff2f.js", "daovoice")
  daovoice('init', {
    app_id: "38fcd752"
  }, {
    launcher: {
      disableLauncherIcon: true,
    },
  });
  daovoice('update');
</script>



  <script>
    (function () {
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>













</html>