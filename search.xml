<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>动手学习深度学习（1）课程介绍及环境配置</title>
    <url>/2022/09/22/DL_1/</url>
    <content><![CDATA[<p>准研究生，学习一些研究生阶段需要的预备知识，打好深度学习基础。共34节课。</p>
<h2 id="课程安排"><a href="#课程安排" class="headerlink" title="课程安排"></a>课程安排</h2><p>相关资源：</p>
<p>课程主页：<a href="https://courses.d2l.ai/zh-v2">https://courses.d2l.ai/zh-v2</a></p>
<p>教材：<a href="https://zh-v2.d2l.ai/">https://zh-v2.d2l.ai/</a></p>
<p>课程论坛讨论：<a href="https://discuss.d2l.ai/c/16">https://discuss.d2l.ai/c/16</a></p>
<p>Pytorch论坛：<a href="https://discuss.pytorch.org/">https://discuss.pytorch.org/</a></p>
<h2 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h2><p>数据的一些基本操作</p>
<h3 id="1-访问元素"><a href="#1-访问元素" class="headerlink" title="1. 访问元素"></a>1. 访问元素</h3><p>一个元素 [1, 2]、一行 [1, :]、一列 [:, 1]</p>
<p>子区域 [1:3, 1:]：访问第1到第2行，第2到最后一列的子区域</p>
<p>子区域 [::3, ::2]：每三行一跳，每两列一跳的所有元素构成的子区域</p>
<h3 id="2-张量及其基本操作"><a href="#2-张量及其基本操作" class="headerlink" title="2. 张量及其基本操作"></a>2. 张量及其基本操作</h3><p>张量表示一个数值组成的数组，这个数组可能有多个维度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">x = torch.arange(<span class="hljs-number">12</span>)<br><span class="hljs-comment">#output</span><br>tensor([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>])<br></code></pre></td></tr></table></figure>

<p><code>x.shape</code>访问张量的形状</p>
<p><code>x.numel()</code>访问张量中元素的个数</p>
<p><code>X = x.reshape(3, 4)</code>改变张量的形状而不改变元素数量和值</p>
<p><code>torch.zeros((2, 3, 4))</code>创建三维全0的2x3x4的张量</p>
<p><code>torch.ones((2, 3, 4))</code>创建三维全0的2x3x4的张量</p>
<p><code>torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]])</code>创建指定张量</p>
<p><code>X.sum()</code>对张量中所有元素进行求和</p>
<h4 id="按元素基本运算"><a href="#按元素基本运算" class="headerlink" title="按元素基本运算"></a>按元素基本运算</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#按元素运算</span><br>x = torch.tensor([<span class="hljs-number">1.0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">8</span>])<br>y = torch.tensor([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<br>x + y, x - y, x * y, x / y, x**y, torch.exp(x)<br><span class="hljs-comment">#output</span><br>tensor([ <span class="hljs-number">3.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">6.</span>, <span class="hljs-number">10.</span>])<br>tensor([-<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">2.</span>, <span class="hljs-number">6.</span>])<br>tensor([ <span class="hljs-number">2.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">8.</span>, <span class="hljs-number">16.</span>])<br>tensor([ <span class="hljs-number">0.5000</span>, <span class="hljs-number">1.0000</span>, <span class="hljs-number">2.0000</span>, <span class="hljs-number">4.0000</span>])<br>tensor([ <span class="hljs-number">1.</span>, <span class="hljs-number">4.</span>, <span class="hljs-number">16.</span>, <span class="hljs-number">65.</span>])<br></code></pre></td></tr></table></figure>

<h4 id="多个张量连结"><a href="#多个张量连结" class="headerlink" title="多个张量连结"></a>多个张量连结</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">X = torch.arange(<span class="hljs-number">12</span>, dtype=torch,float32).reshape((<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br>Y = torch.tensor([[<span class="hljs-number">2.0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>]])<br>torch.cat((X, Y), dim=<span class="hljs-number">0</span>)<span class="hljs-comment">#按行连接</span><br>torch.cat((X, Y), dim=<span class="hljs-number">1</span>)<span class="hljs-comment">#按列连接</span><br></code></pre></td></tr></table></figure>

<h4 id="通过逻辑运算符构建二元张量"><a href="#通过逻辑运算符构建二元张量" class="headerlink" title="通过逻辑运算符构建二元张量"></a>通过逻辑运算符构建二元张量</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">X == Y<br><span class="hljs-comment">#output</span><br>tensor([[<span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>,  <span class="hljs-literal">True</span>],<br>		[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>],<br>		[<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]])<br></code></pre></td></tr></table></figure>

<h4 id="广播机制"><a href="#广播机制" class="headerlink" title="广播机制"></a>广播机制</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">a = torch.arange(<span class="hljs-number">3</span>).reshape((<span class="hljs-number">3</span>, <span class="hljs-number">1</span>))<br>b = torch.arange(<span class="hljs-number">2</span>).rashape((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>a + b<br><span class="hljs-comment">#output</span><br>tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>		[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>],<br>		[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]])<br></code></pre></td></tr></table></figure>

<h4 id="运行一些操作可能导致为新结果分配内存"><a href="#运行一些操作可能导致为新结果分配内存" class="headerlink" title="运行一些操作可能导致为新结果分配内存"></a>运行一些操作可能导致为新结果分配内存</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">before = <span class="hljs-built_in">id</span>(Y)<br>Y = Y + X<br><span class="hljs-built_in">id</span>(Y) == before<br><span class="hljs-comment">#output</span><br><span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure>

<p>执行原地操作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">Z = torch.zeros_like(Y)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">id</span>(Z))<br>Z[:] = X + Y<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">id</span>(Z))<br><span class="hljs-comment">#output</span><br><span class="hljs-number">140146615319872</span><br><span class="hljs-number">140146615319872</span><br></code></pre></td></tr></table></figure>

<p>如果在后续计算中没有重复使用X， 我们也可以使用 <code>X[:] = X + Y</code>或 <code>X += Y</code>来减少操作的内存开销。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#仅适用于张量，若X，Y为数字则结果为False</span><br>before = <span class="hljs-built_in">id</span>(X)<br>X += Y<br><span class="hljs-built_in">id</span>(X) == before<br><span class="hljs-comment">#output</span><br><span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure>

<h2 id="简单的数据预处理"><a href="#简单的数据预处理" class="headerlink" title="简单的数据预处理"></a>简单的数据预处理</h2><p>创建一个人工数据集，并存储在csv（逗号分隔值）文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-comment"># 创建一个csv文件</span><br>os.makedirs(os.path.join(<span class="hljs-string">&#x27;..&#x27;</span>, <span class="hljs-string">&#x27;data&#x27;</span>), exist_ok=<span class="hljs-literal">True</span>)<br>data_file = os.path.join(<span class="hljs-string">&#x27;..&#x27;</span>, <span class="hljs-string">&#x27;data&#x27;</span>, <span class="hljs-string">&#x27;house_tiny.csv&#x27;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(data_file, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>	f.write(<span class="hljs-string">&#x27;NumRooms,Alley,Price\n&#x27;</span>) <span class="hljs-comment"># 列名</span><br>	f.write(<span class="hljs-string">&#x27;NA,Pave,127500\n&#x27;</span>) <span class="hljs-comment"># 每行表示一个数据样本</span><br>	f.write(<span class="hljs-string">&#x27;2,NA,106000\n&#x27;</span>)<br>	f.write(<span class="hljs-string">&#x27;4,NA,178100\n&#x27;</span>)<br>	f.write(<span class="hljs-string">&#x27;NA,NA,140000\n&#x27;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-comment"># 读取文件</span><br>data = pd.read_csv(data_file)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">inputs, outputs = data.iloc[:, <span class="hljs-number">0</span>:<span class="hljs-number">2</span>], data.iloc[:, <span class="hljs-number">2</span>]<br><span class="hljs-comment"># 数值型的缺失值利用均值填充</span><br>inputs = inputs.fillna(inputs.mean())<br><span class="hljs-built_in">print</span>(inputs)<br><span class="hljs-comment"># 非数值型的缺失值，我们将“NAN”视为一个类别</span><br>inputs = pd.get_dummies(inputs, dummy_na=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(inputs)<br></code></pre></td></tr></table></figure>

<p>现在inputs和outputs中的所有条目都是数值类型，他们可以转换为张量格式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（10）卷积层和池化层</title>
    <url>/2022/10/30/DL_10/</url>
    <content><![CDATA[<p><em>卷积神经网络</em>（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。</p>
<p><strong>两个原则</strong>：平移不变性，局部性</p>
<p>详细讲解了为什么要使用卷积，以及如何从全连接层推理至卷积层。建议完整观看视频。</p>
<p><a href="https://www.bilibili.com/video/BV1L64y1m7Nh/?spm_id_from=autoNext&vd_source=f1e7eb1d150afc7b732a2b8c557e6d35">19 卷积层【动手学深度学习v2】_bilibili</a></p>
<ul>
<li>卷积层将输入和核矩阵进行交叉相关，加上偏移后得到输出</li>
<li>核矩阵和偏移是可学习的参数</li>
<li>核矩阵的大小是超参数</li>
</ul>
<h2 id="图像卷积"><a href="#图像卷积" class="headerlink" title="图像卷积"></a>图像卷积</h2><h3 id="互相关运算"><a href="#互相关运算" class="headerlink" title="互相关运算"></a>互相关运算</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d</span>(<span class="hljs-params">X, K</span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;</span><br>    h, w = K.shape<br>    Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - w + <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]):<br>            Y[i, j] = (X[i:i + h, j:j + w] * K).<span class="hljs-built_in">sum</span>()<br>    <span class="hljs-keyword">return</span> Y<br><br>X = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]])<br>K = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]])<br>corr2d(X, K)<br><span class="hljs-comment"># output</span><br>tensor([[<span class="hljs-number">19.</span>, <span class="hljs-number">25.</span>],<br>        [<span class="hljs-number">37.</span>, <span class="hljs-number">43.</span>]])<br></code></pre></td></tr></table></figure>

<h3 id="实现二维卷积层"><a href="#实现二维卷积层" class="headerlink" title="实现二维卷积层"></a>实现二维卷积层</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在__init__构造函数中，将weight和bias声明为两个模型参数。</span><br><span class="hljs-comment"># 前向传播函数调用corr2d函数并添加偏置。</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Conv2D</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, kernel_size</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.weight = nn.Parameter(torch.rand(kernel_size))<br>        self.bias = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> corr2d(x, self.weight) + self.bias<br></code></pre></td></tr></table></figure>

<h2 id="填充与步幅"><a href="#填充与步幅" class="headerlink" title="填充与步幅"></a>填充与步幅</h2><p>填充：在输入的周围添加额外的行&#x2F;列</p>
<p>步幅：卷积核的滑动步长</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-comment"># 为了方便起见，我们定义了一个计算卷积层的函数。</span><br><span class="hljs-comment"># 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">comp_conv2d</span>(<span class="hljs-params">conv2d, X</span>):<br>    <span class="hljs-comment"># 这里的（1，1）表示批量大小和通道数都是1</span><br>    X = X.reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>) + X.shape)<br>    Y = conv2d(X)<br>    <span class="hljs-comment"># 省略前两个维度：批量大小和通道</span><br>    <span class="hljs-keyword">return</span> Y.reshape(Y.shape[<span class="hljs-number">2</span>:])<br><br><span class="hljs-comment"># 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列</span><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>X = torch.rand(size=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">8</span>])<br><br><span class="hljs-comment"># 当卷积核的高度和宽度不同时，我们可以填充不同的高度和宽度，</span><br><span class="hljs-comment"># 使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，</span><br><span class="hljs-comment"># 高度和宽度两边的填充分别为2和1。</span><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>), padding=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">8</span>])<br><br><span class="hljs-comment"># 我们将高度和宽度的步幅设置为2，从而将输入的高度和宽度减半。</span><br>conv2d = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">4</span>])<br><br><span class="hljs-comment"># 稍微复杂的例子</span><br>conv2d = nn.Conv2D(<span class="hljs-number">1</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), strides=(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(comp_conv2d(conv2d, X).shape)<br><span class="hljs-comment"># output</span><br>(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>

<h2 id="多个输入和输出通道"><a href="#多个输入和输出通道" class="headerlink" title="多个输入和输出通道"></a>多个输入和输出通道</h2><p>多个输入通道：</p>
<ul>
<li>每个通道都有一个卷积核，结果是所有通道卷积结果的和。</li>
</ul>
<p>多个输出通道：</p>
<ul>
<li>我们可以有多个三维卷积核，每个核生成一个输出通道。</li>
</ul>
<p>多个输入输出通道：</p>
<ul>
<li>每个输出通道可以识别特定的模式</li>
<li>输入通道核始别并组合输入中的模式</li>
</ul>
<p>1x1卷积层：不识别空间模式，只是融合通道。</p>
<p>假设输入为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.49ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 4516.7 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">c_i×h×w</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="613" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="1000" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="2000" y="0"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="2799" y="0"></use>
 <use xlink:href="#E1-MJMATHI-77" x="3800" y="0"></use>
</g>
</svg>，卷积核大小为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.375ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 7480.7 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">c_o×c_i×k_h×k_w</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6F" x="613" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="1099" y="0"></use>
<g transform="translate(2099,0)">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="613" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="3099" y="0"></use>
<g transform="translate(4100,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="737" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="5351" y="0"></use>
<g transform="translate(6352,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="737" y="-213"></use>
</g>
</g>
</svg>，填充为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.77ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3345.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(p_h, p_w)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="712" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1400" y="0"></use>
<g transform="translate(1845,0)">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="712" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2955" y="0"></use>
</g>
</svg>，步幅为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.612ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3277.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(s_h, s_w)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1366" y="0"></use>
<g transform="translate(1811,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2887" y="0"></use>
</g>
</svg>。</p>
<ol>
<li>前向传播的计算成本（乘法和加法）:<br>MATHJAX-SSR-0</li>
<li>参数内存占用:</li>
</ol>
<p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="90.857ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 39118.8 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">c_i×h×w+c_o×c_i×k_h×k_w+c_o×⌊(ℎ−𝑘_ℎ+𝑝_ℎ+𝑠_ℎ)/𝑠_ℎ⌋×⌊(𝑤−𝑘_𝑤+𝑝_𝑤+𝑠_𝑤)/𝑠_𝑤⌋</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
<path stroke-width="1" id="E1-MJMAIN-230A" d="M174 734Q174 735 175 737T177 740T180 744T184 747T189 749T196 750Q206 748 214 735V-210H310H373Q401 -210 411 -213T422 -230T411 -247T369 -251Q362 -251 338 -251T298 -250H190Q178 -246 174 -234V734Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMAIN-230B" d="M229 734Q229 735 230 737T232 740T235 744T239 747T244 749T251 750Q262 748 269 735V-235Q266 -240 256 -249L147 -250H77Q43 -250 32 -247T21 -230T32 -213T72 -209Q79 -209 99 -209T133 -210H229V734Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="613" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="1000" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="2000" y="0"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="2799" y="0"></use>
 <use xlink:href="#E1-MJMATHI-77" x="3800" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2B" x="4738" y="0"></use>
<g transform="translate(5739,0)">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6F" x="613" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="6838" y="0"></use>
<g transform="translate(7839,0)">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="613" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="8839" y="0"></use>
<g transform="translate(9840,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="737" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="11091" y="0"></use>
<g transform="translate(12092,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="737" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="13442" y="0"></use>
<g transform="translate(14443,0)">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6F" x="613" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-D7" x="15542" y="0"></use>
 <use xlink:href="#E1-MJMAIN-230A" x="16543" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="16987" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="17377" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="18175" y="0"></use>
<g transform="translate(19176,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="737" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="20427" y="0"></use>
<g transform="translate(21428,0)">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="712" y="-326"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="22661" y="0"></use>
<g transform="translate(23662,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="24639" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="25029" y="0"></use>
<g transform="translate(25529,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-230B" x="26506" y="0"></use>
 <use xlink:href="#E1-MJMAIN-D7" x="27173" y="0"></use>
 <use xlink:href="#E1-MJMAIN-230A" x="28174" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="28618" y="0"></use>
 <use xlink:href="#E1-MJMATHI-77" x="29008" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="29947" y="0"></use>
<g transform="translate(30947,0)">
 <use xlink:href="#E1-MJMATHI-6B" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="737" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="32298" y="0"></use>
<g transform="translate(33298,0)">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="712" y="-326"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="34631" y="0"></use>
<g transform="translate(35632,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="36708" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="37097" y="0"></use>
<g transform="translate(37598,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-77" x="663" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-230B" x="38674" y="0"></use>
</g>
</svg></p>
<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-comment"># 多输入通道互相关运算</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in</span>(<span class="hljs-params">X, K</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(d2l.corr2d(x, k) <span class="hljs-keyword">for</span> x, k <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(X, K))<br><span class="hljs-comment"># 验证互相关运算的输出</span><br>X = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]],<br>               [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>], [<span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>, <span class="hljs-number">6.0</span>], [<span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">9.0</span>]]])<br>K = torch.tensor([[[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>], [<span class="hljs-number">2.0</span>, <span class="hljs-number">3.0</span>]], [[<span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>]]])<br><br><span class="hljs-built_in">print</span>(corr2d_multi_in(X, K))<br><span class="hljs-comment"># output</span><br>tensor([[ <span class="hljs-number">56.</span>,  <span class="hljs-number">72.</span>],<br>        [<span class="hljs-number">104.</span>, <span class="hljs-number">120.</span>]])<br><br><span class="hljs-comment"># 多输出通道互相关运算</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in_out</span>(<span class="hljs-params">X, K</span>):<br>    <span class="hljs-comment"># 迭代“K”的第0个维度，每次都对输入“X”执行互相关运算。</span><br>    <span class="hljs-comment"># 最后将所有结果都叠加在一起</span><br>    <span class="hljs-keyword">return</span> torch.stack([corr2d_multi_in(X, k) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> K], <span class="hljs-number">0</span>)<br>K = torch.stack((K, K + <span class="hljs-number">1</span>, K + <span class="hljs-number">2</span>), <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(K.shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>])<br><span class="hljs-built_in">print</span>(corr2d_multi_in_out(X, K))<br><span class="hljs-comment"># output</span><br>tensor([[[ <span class="hljs-number">56.</span>,  <span class="hljs-number">72.</span>],<br>         [<span class="hljs-number">104.</span>, <span class="hljs-number">120.</span>]],<br><br>        [[ <span class="hljs-number">76.</span>, <span class="hljs-number">100.</span>],<br>         [<span class="hljs-number">148.</span>, <span class="hljs-number">172.</span>]],<br><br>        [[ <span class="hljs-number">96.</span>, <span class="hljs-number">128.</span>],<br>         [<span class="hljs-number">192.</span>, <span class="hljs-number">224.</span>]]])<br><br><span class="hljs-comment"># 使用全连接层实现1x1卷积</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">corr2d_multi_in_out_1x1</span>(<span class="hljs-params">X, K</span>):<br>    c_i, h, w = X.shape<br>    c_o = K.shape[<span class="hljs-number">0</span>]<br>    X = X.reshape((c_i, h * w))<br>    K = K.reshape((c_o, c_i))<br>    <span class="hljs-comment"># 全连接层中的矩阵乘法</span><br>    Y = torch.matmul(K, X)<br>    <span class="hljs-keyword">return</span> Y.reshape((c_o, h, w))<br>X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>K = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><br>Y1 = corr2d_multi_in_out_1x1(X, K)<br>Y2 = corr2d_multi_in_out(X, K)<br><span class="hljs-keyword">assert</span> <span class="hljs-built_in">float</span>(torch.<span class="hljs-built_in">abs</span>(Y1 - Y2).<span class="hljs-built_in">sum</span>()) &lt; <span class="hljs-number">1e-6</span><br></code></pre></td></tr></table></figure>

<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。</p>
<p>本节将介绍<em>汇聚</em>（pooling）层，它具有双重目的：降低卷积层对位置的敏感性，同时降低对空间降采样表示的敏感性。</p>
<ul>
<li>池化层与卷积层类似，都具有填充和步幅</li>
<li>没有可学习参数</li>
<li>在每个输入通道应用池化层以获得相应的输出通道</li>
<li>输出通道数 &#x3D; 输入通道数</li>
</ul>
<p>最大池化层：每个窗口中最强的模式信号</p>
<p>平均池化层：将最大池化层中的“最大”操作替换为“平均”</p>
<h2 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">pool2d</span>(<span class="hljs-params">X, pool_size, mode=<span class="hljs-string">&#x27;max&#x27;</span></span>):<br>    p_h, p_w = pool_size<br>    Y = torch.zeros((X.shape[<span class="hljs-number">0</span>] - p_h + <span class="hljs-number">1</span>, X.shape[<span class="hljs-number">1</span>] - p_w + <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(Y.shape[<span class="hljs-number">1</span>]):<br>            <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;max&#x27;</span>:<br>                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="hljs-built_in">max</span>()<br>            <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;avg&#x27;</span>:<br>                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()<br>    <span class="hljs-keyword">return</span> Y<br>X = torch.tensor([[<span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">2.0</span>], [<span class="hljs-number">3.0</span>, <span class="hljs-number">4.0</span>, <span class="hljs-number">5.0</span>], [<span class="hljs-number">6.0</span>, <span class="hljs-number">7.0</span>, <span class="hljs-number">8.0</span>]])<br><span class="hljs-built_in">print</span>(pool2d(X, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))<br><span class="hljs-comment"># output</span><br>tensor([[<span class="hljs-number">4.</span>, <span class="hljs-number">5.</span>],<br>        [<span class="hljs-number">7.</span>, <span class="hljs-number">8.</span>]])<br><span class="hljs-built_in">print</span>(pool2d(X, (<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-string">&#x27;avg&#x27;</span>))<br><span class="hljs-comment"># output</span><br>tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">3.</span>],<br>        [<span class="hljs-number">5.</span>, <span class="hljs-number">6.</span>]])<br><br><span class="hljs-comment"># 填充和步幅</span><br>X = torch.arange(<span class="hljs-number">16</span>, dtype=torch.float32).reshape((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(X)<br><span class="hljs-comment"># output</span><br>tensor([[[[ <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>],<br>          [ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>],<br>          [ <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">11.</span>],<br>          [<span class="hljs-number">12.</span>, <span class="hljs-number">13.</span>, <span class="hljs-number">14.</span>, <span class="hljs-number">15.</span>]]]])<br><span class="hljs-comment"># 默认情况下，深度学习框架中的步幅与汇聚窗口的大小相同。</span><br>pool2d = nn.MaxPool2d(<span class="hljs-number">3</span>)<br><span class="hljs-built_in">print</span>(pool2d(X))<br><span class="hljs-comment"># output</span><br>tensor([[[[<span class="hljs-number">10.</span>]]]])<br><br><span class="hljs-comment"># 填充和步幅可以手动设定。</span><br>pool2d = nn.MaxPool2d(<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(pool2d(X))<br><span class="hljs-comment"># output</span><br>tensor([[[[ <span class="hljs-number">5.</span>,  <span class="hljs-number">7.</span>],<br>          [<span class="hljs-number">13.</span>, <span class="hljs-number">15.</span>]]]])<br><br><span class="hljs-comment"># 当然，我们可以设定一个任意大小的矩形汇聚窗口，</span><br><span class="hljs-comment"># 并分别设定填充和步幅的高度和宽度。</span><br>pool2d = nn.MaxPool2d((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br><span class="hljs-built_in">print</span>(pool2d(X))<br><span class="hljs-comment"># output</span><br>tensor([[[[ <span class="hljs-number">5.</span>,  <span class="hljs-number">7.</span>],<br>          [<span class="hljs-number">13.</span>, <span class="hljs-number">15.</span>]]]])<br><br><span class="hljs-comment"># 多个通道</span><br>X = torch.cat((X, X + <span class="hljs-number">1</span>), <span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(X)<br><span class="hljs-comment"># output</span><br>tensor([[[[ <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>],<br>          [ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>],<br>          [ <span class="hljs-number">8.</span>,  <span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">11.</span>],<br>          [<span class="hljs-number">12.</span>, <span class="hljs-number">13.</span>, <span class="hljs-number">14.</span>, <span class="hljs-number">15.</span>]],<br><br>         [[ <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>,  <span class="hljs-number">3.</span>,  <span class="hljs-number">4.</span>],<br>          [ <span class="hljs-number">5.</span>,  <span class="hljs-number">6.</span>,  <span class="hljs-number">7.</span>,  <span class="hljs-number">8.</span>],<br>          [ <span class="hljs-number">9.</span>, <span class="hljs-number">10.</span>, <span class="hljs-number">11.</span>, <span class="hljs-number">12.</span>],<br>          [<span class="hljs-number">13.</span>, <span class="hljs-number">14.</span>, <span class="hljs-number">15.</span>, <span class="hljs-number">16.</span>]]]])<br>pool2d = nn.MaxPool2d(<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(pool2d(X))<br><span class="hljs-comment"># output</span><br>tensor([[[[ <span class="hljs-number">5.</span>,  <span class="hljs-number">7.</span>],<br>          [<span class="hljs-number">13.</span>, <span class="hljs-number">15.</span>]],<br><br>         [[ <span class="hljs-number">6.</span>,  <span class="hljs-number">8.</span>],<br>          [<span class="hljs-number">14.</span>, <span class="hljs-number">16.</span>]]]])<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（11）LeNet</title>
    <url>/2022/10/31/DL_11/</url>
    <content><![CDATA[<p>在本节中，我们将介绍LeNet，它是最早发布的卷积神经网络之一，因其在计算机视觉任务中的高效性能而受到广泛关注。 </p>
<h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>net = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Flatten(),<br>    nn.Linear(<span class="hljs-number">16</span> * <span class="hljs-number">5</span> * <span class="hljs-number">5</span>, <span class="hljs-number">120</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>))<br><span class="hljs-comment"># 通过在每一层打印输出的形状，我们可以检查模型</span><br>X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), dtype=torch.float32)<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape: \t&#x27;</span>,X.shape)<br><span class="hljs-comment"># output</span><br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>Sigmoid output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>AvgPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>])<br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>])<br>Sigmoid output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>])<br>AvgPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>Flatten output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">400</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">120</span>])<br>Sigmoid output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">120</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">84</span>])<br>Sigmoid output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">84</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy_gpu</span>(<span class="hljs-params">net, data_iter, device=<span class="hljs-literal">None</span></span>): <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;使用GPU计算模型在数据集上的精度&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()  <span class="hljs-comment"># 设置为评估模式</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>            device = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(net.parameters())).device<br>    <span class="hljs-comment"># 正确预测的数量，总预测的数量</span><br>    metric = d2l.Accumulator(<span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>                <span class="hljs-comment"># BERT微调所需的（之后将介绍）</span><br>                X = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>            <span class="hljs-keyword">else</span>:<br>                X = X.to(device)<br>            y = y.to(device)<br>            metric.add(d2l.accuracy(net(X), y), y.numel())<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch6</span>(<span class="hljs-params">net, train_iter, test_iter, num_epochs, lr, device</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用GPU训练模型(在第六章定义)&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear <span class="hljs-keyword">or</span> <span class="hljs-built_in">type</span>(m) == nn.Conv2d:<br>            nn.init.xavier_uniform_(m.weight)<br>    net.apply(init_weights)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;training on&#x27;</span>, device)<br>    net.to(device)<br>    optimizer = torch.optim.SGD(net.parameters(), lr=lr)<br>    loss = nn.CrossEntropyLoss()<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs],<br>                            legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    timer, num_batches = d2l.Timer(), <span class="hljs-built_in">len</span>(train_iter)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-comment"># 训练损失之和，训练准确率之和，样本数</span><br>        metric = d2l.Accumulator(<span class="hljs-number">3</span>)<br>        net.train()<br>        <span class="hljs-keyword">for</span> i, (X, y) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            timer.start()<br>            optimizer.zero_grad()<br>            X, y = X.to(device), y.to(device)<br>            y_hat = net(X)<br>            l = loss(y_hat, y)<br>            l.backward()<br>            optimizer.step()<br>            <span class="hljs-keyword">with</span> torch.no_grad():<br>                metric.add(l * X.shape[<span class="hljs-number">0</span>], d2l.accuracy(y_hat, y), X.shape[<span class="hljs-number">0</span>])<br>            timer.stop()<br>            train_l = metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]<br>            train_acc = metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % (num_batches // <span class="hljs-number">5</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> i == num_batches - <span class="hljs-number">1</span>:<br>                animator.add(epoch + (i + <span class="hljs-number">1</span>) / num_batches,<br>                             (train_l, train_acc, <span class="hljs-literal">None</span>))<br>        test_acc = evaluate_accuracy_gpu(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;train_l:<span class="hljs-number">.3</span>f&#125;</span>, train acc <span class="hljs-subst">&#123;train_acc:<span class="hljs-number">.3</span>f&#125;</span>, &#x27;</span><br>          <span class="hljs-string">f&#x27;test acc <span class="hljs-subst">&#123;test_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">2</span>] * num_epochs / timer.<span class="hljs-built_in">sum</span>():<span class="hljs-number">.1</span>f&#125;</span> examples/sec &#x27;</span><br>          <span class="hljs-string">f&#x27;on <span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(device)&#125;</span>&#x27;</span>)<br>lr, num_epochs = <span class="hljs-number">0.9</span>, <span class="hljs-number">10</span><br>train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.468</span>, train acc <span class="hljs-number">0.824</span>, test acc <span class="hljs-number">0.806</span><br><span class="hljs-number">83857.2</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（13）现代卷积神经网络（2）</title>
    <url>/2022/11/01/DL_13/</url>
    <content><![CDATA[<p>训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。 在本节中，我们将介绍<em>批量规范化</em>（batch normalization），这是一种流行且有效的技术，可持续加速深层网络的收敛速度。</p>
<h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><p>固定小批量里面的均值和方差，批量归一化是线性变换<br>MATHJAX-SSR-6</p>
<p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="27.06ex" height="6.176ex" style="vertical-align: -2.338ex;" viewBox="0 -1652.5 11650.8 2659.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\mathrm{BN}(\mathbf{x}) = \boldsymbol{\gamma} \odot \frac{\mathbf{x} - \hat{\boldsymbol{\mu}}_\mathcal{B}}{\hat{\boldsymbol{\sigma}}_\mathcal{B}} + \boldsymbol{\beta}.</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-42" d="M131 622Q124 629 120 631T104 634T61 637H28V683H229H267H346Q423 683 459 678T531 651Q574 627 599 590T624 512Q624 461 583 419T476 360L466 357Q539 348 595 302T651 187Q651 119 600 67T469 3Q456 1 242 0H28V46H61Q103 47 112 49T131 61V622ZM511 513Q511 560 485 594T416 636Q415 636 403 636T371 636T333 637Q266 637 251 636T232 628Q229 624 229 499V374H312L396 375L406 377Q410 378 417 380T442 393T474 417T499 456T511 513ZM537 188Q537 239 509 282T430 336L329 337H229V200V116Q229 57 234 52Q240 47 334 47H383Q425 47 443 53Q486 67 511 104T537 188Z"></path>
<path stroke-width="1" id="E1-MJMAIN-4E" d="M42 46Q74 48 94 56T118 69T128 86V634H124Q114 637 52 637H25V683H232L235 680Q237 679 322 554T493 303L578 178V598Q572 608 568 613T544 627T492 637H475V683H483Q498 680 600 680Q706 680 715 683H724V637H707Q634 633 622 598L621 302V6L614 0H600Q585 0 582 3T481 150T282 443T171 605V345L172 86Q183 50 257 46H274V0H265Q250 3 150 3Q48 3 33 0H25V46H42Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHBI-3B3" d="M5 269Q5 285 19 312T57 368T124 421T215 451H241Q274 451 303 439T353 406T389 361T416 311T432 266T442 232L444 220L446 216L450 226Q473 278 513 357T561 441Q566 444 584 444H594Q617 444 617 430Q617 426 596 389T536 273T462 110L452 84L451 70Q447 12 427 -76T388 -192Q375 -211 355 -211Q339 -211 332 -198T325 -171Q325 -114 386 64L393 84V98Q393 181 371 241Q360 280 319 303T210 327Q158 327 126 317T84 296T68 272T59 258Q55 256 36 256Q23 256 18 256T9 260T5 269Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2299" d="M56 250Q56 394 156 488T384 583Q530 583 626 485T722 250Q722 110 625 14T390 -83Q249 -83 153 14T56 250ZM682 250Q682 322 649 387T546 497T381 542Q272 542 184 459T95 250Q95 132 178 45T389 -42Q515 -42 598 45T682 250ZM311 250Q311 285 332 304T375 328Q376 328 382 328T392 329Q424 326 445 305T466 250Q466 217 445 195T389 172Q354 172 333 195T311 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHBI-3BC" d="M294 -8Q265 -8 244 -5T213 1T201 4Q200 4 192 -32T172 -111T155 -168Q134 -211 86 -211Q62 -211 48 -196T34 -158Q37 -144 103 123T174 404Q182 424 201 438T244 452Q271 452 284 436T298 404Q298 392 267 269T235 114Q235 43 305 43Q342 43 375 68T418 110Q420 112 455 253T492 397Q514 444 562 444Q587 444 601 429T615 397Q615 387 599 320T563 178T542 93Q540 81 540 72Q540 42 558 42Q580 42 596 75Q606 94 616 134Q621 155 624 158T646 162H651H662Q682 162 682 148Q681 142 679 132T665 94T641 47T602 9T548 -8Q523 -8 502 -3T468 11T446 27T432 40L429 46Q367 -8 294 -8Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJCAL-42" d="M304 342Q292 342 292 353Q292 372 323 391Q331 396 417 428T533 487Q563 512 563 555V562Q563 575 557 589T530 618T475 636Q429 636 396 613T330 539Q263 446 210 238Q196 183 173 120Q135 31 121 16Q108 1 85 -10T47 -22T32 -10Q32 -5 44 18T77 93T112 206Q135 296 154 395T182 550T191 615Q191 616 190 616Q188 616 179 611T157 601T131 594Q113 594 113 605Q113 623 144 644Q154 650 205 676T267 703Q277 705 279 705Q295 705 295 693Q295 686 288 635T278 575Q278 572 287 582Q336 635 402 669T540 704Q603 704 633 673T664 599Q664 559 638 523T580 462Q553 440 504 413L491 407L504 402Q566 381 596 338T627 244Q627 172 575 110T444 13T284 -22Q208 -22 158 28Q144 42 146 50Q150 67 178 85T230 103Q236 103 246 95T267 75T302 56T357 47Q436 47 486 93Q526 136 526 198V210Q526 228 518 249T491 292T436 330T350 345Q335 345 321 344T304 342Z"></path>
<path stroke-width="1" id="E1-MJMATHBI-3C3" d="M35 151Q35 190 51 236T99 327T184 404T306 443Q307 443 316 443T342 443T378 444T425 444T476 444Q606 444 626 444T655 439Q677 426 677 400Q677 358 639 340Q625 333 563 333Q510 333 510 331Q518 319 518 272Q518 155 437 74T226 -8Q123 -8 79 41T35 151ZM396 278Q396 314 375 323T305 332Q249 332 222 310T180 243Q171 219 162 178T153 116V110Q153 43 234 43Q347 43 382 199Q383 203 383 204Q396 255 396 278Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHBI-3B2" d="M59 -194H49Q31 -194 28 -182Q28 -178 107 139T192 473Q212 533 248 580T324 652T395 689T450 701H461Q514 701 551 688T605 652T630 607T637 561Q637 546 634 526T611 465T556 393Q572 382 590 347T608 262Q608 146 522 69T299 -8Q279 -8 261 -6T228 2T204 13T183 26T169 37T157 48L150 56L120 -64Q113 -90 104 -128Q93 -175 89 -184T73 -194H59ZM531 592Q531 651 463 651Q399 651 341 600T253 466Q250 458 217 327T182 185Q180 176 180 159Q180 108 212 76T301 44Q330 44 354 51T393 65T423 91T444 118T459 151T468 179T475 206Q490 264 491 296Q491 313 489 326T484 345L482 350Q481 350 477 348T464 344T444 340T413 335T372 333T334 334T301 340T274 355T265 380Q265 444 397 444Q425 444 445 441T476 436L485 433Q489 433 499 458Q509 482 520 527T531 592ZM424 390Q424 393 389 393Q383 393 374 393T362 392Q348 392 333 388Q345 384 379 384Q424 384 424 390Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-42" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-4E" x="708" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1459" y="0"></use>
 <use xlink:href="#E1-MJMAINB-78" x="1848" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2456" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3123" y="0"></use>
 <use xlink:href="#E1-MJMATHBI-3B3" x="4179" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2299" x="5019" y="0"></use>
<g transform="translate(5797,0)">
<g transform="translate(342,0)">
<rect stroke="none" width="3228" height="60" x="0" y="220"></rect>
<g transform="translate(60,783)">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="829" y="0"></use>
<g transform="translate(1830,0)">
 <use xlink:href="#E1-MJMATHBI-3BC" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="135" y="30"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJCAL-42" x="1001" y="-350"></use>
</g>
</g>
<g transform="translate(986,-739)">
 <use xlink:href="#E1-MJMATHBI-3C3" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="93" y="23"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJCAL-42" x="970" y="-219"></use>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="9711" y="0"></use>
 <use xlink:href="#E1-MJMATHBI-3B2" x="10711" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="11372" y="0"></use>
</g>
</svg></p>
<p>均值 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.332ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 573.5 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\beta</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
</g>
</svg> 和方差 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.262ex" height="2.176ex" style="vertical-align: -0.838ex;" viewBox="0 -576.1 543.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\gamma</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B3" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B3" x="0" y="0"></use>
</g>
</svg> 为学习参数。</p>
<p>作用在</p>
<ul>
<li>全连接层和卷积层输出上，激活函数前</li>
<li>全连接层和卷积层输入上</li>
</ul>
<p>全连接层，作用在特征维；卷积层，作用在通道维。</p>
<p>可以加速收敛速度（通过匀速更大的学习率），但一般不改变模型精度。</p>
<h3 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_norm</span>(<span class="hljs-params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):<br>    <span class="hljs-comment"># 通过is_grad_enabled来判断当前模式是训练模式还是预测模式</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> torch.is_grad_enabled():<br>        <span class="hljs-comment"># 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差</span><br>        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(X.shape) <span class="hljs-keyword">in</span> (<span class="hljs-number">2</span>, <span class="hljs-number">4</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(X.shape) == <span class="hljs-number">2</span>:<br>            <span class="hljs-comment"># 使用全连接层的情况，计算特征维上的均值和方差</span><br>            mean = X.mean(dim=<span class="hljs-number">0</span>)<br>            var = ((X - mean) ** <span class="hljs-number">2</span>).mean(dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span><br>            <span class="hljs-comment"># 这里我们需要保持X的形状以便后面可以做广播运算</span><br>            mean = X.mean(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)<br>            var = ((X - mean) ** <span class="hljs-number">2</span>).mean(dim=(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), keepdim=<span class="hljs-literal">True</span>)<br>        <span class="hljs-comment"># 训练模式下，用当前的均值和方差做标准化</span><br>        X_hat = (X - mean) / torch.sqrt(var + eps)<br>        <span class="hljs-comment"># 更新移动平均的均值和方差</span><br>        moving_mean = momentum * moving_mean + (<span class="hljs-number">1.0</span> - momentum) * mean<br>        moving_var = momentum * moving_var + (<span class="hljs-number">1.0</span> - momentum) * var<br>    Y = gamma * X_hat + beta  <span class="hljs-comment"># 缩放和移位</span><br>    <span class="hljs-keyword">return</span> Y, moving_mean.data, moving_var.data<br></code></pre></td></tr></table></figure>

<p>创建一个正确的<code>BatchNorm</code>图层</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">BatchNorm</span>(nn.Module):<br>    <span class="hljs-comment"># num_features：完全连接层的输出数量或卷积层的输出通道数。</span><br>    <span class="hljs-comment"># num_dims：2表示完全连接层，4表示卷积层</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_features, num_dims</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">if</span> num_dims == <span class="hljs-number">2</span>:<br>            shape = (<span class="hljs-number">1</span>, num_features)<br>        <span class="hljs-keyword">else</span>:<br>            shape = (<span class="hljs-number">1</span>, num_features, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0</span><br>        self.gamma = nn.Parameter(torch.ones(shape))<br>        self.beta = nn.Parameter(torch.zeros(shape))<br>        <span class="hljs-comment"># 非模型参数的变量初始化为0和1</span><br>        self.moving_mean = torch.zeros(shape)<br>        self.moving_var = torch.ones(shape)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># 如果X不在内存上，将moving_mean和moving_var</span><br>        <span class="hljs-comment"># 复制到X所在显存上</span><br>        <span class="hljs-keyword">if</span> self.moving_mean.device != X.device:<br>            self.moving_mean = self.moving_mean.to(X.device)<br>            self.moving_var = self.moving_var.to(X.device)<br>        <span class="hljs-comment"># 保存更新过的moving_mean和moving_var</span><br>        Y, self.moving_mean, self.moving_var = batch_norm(<br>            X, self.gamma, self.beta, self.moving_mean,<br>            self.moving_var, eps=<span class="hljs-number">1e-5</span>, momentum=<span class="hljs-number">0.9</span>)<br>        <span class="hljs-keyword">return</span> Y<br></code></pre></td></tr></table></figure>

<p>应用<code>BatchNorm</code>于LeNet模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">net = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>), BatchNorm(<span class="hljs-number">6</span>, num_dims=<span class="hljs-number">4</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>), BatchNorm(<span class="hljs-number">16</span>, num_dims=<span class="hljs-number">4</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>), nn.Flatten(),<br>    nn.Linear(<span class="hljs-number">16</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>, <span class="hljs-number">120</span>), BatchNorm(<span class="hljs-number">120</span>, num_dims=<span class="hljs-number">2</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>), BatchNorm(<span class="hljs-number">84</span>, num_dims=<span class="hljs-number">2</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>

<p>在Fashion-MNIST数据集上的效果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">1.0</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.268</span>, train acc <span class="hljs-number">0.900</span>, test acc <span class="hljs-number">0.831</span><br><span class="hljs-number">38739.6</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<h3 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">net = nn.Sequential(<br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">5</span>), nn.BatchNorm2d(<span class="hljs-number">6</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, kernel_size=<span class="hljs-number">5</span>), nn.BatchNorm2d(<span class="hljs-number">16</span>), nn.Sigmoid(),<br>    nn.AvgPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>), nn.Flatten(),<br>    nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">120</span>), nn.BatchNorm1d(<span class="hljs-number">120</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>), nn.BatchNorm1d(<span class="hljs-number">84</span>), nn.Sigmoid(),<br>    nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>))<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.269</span>, train acc <span class="hljs-number">0.901</span>, test acc <span class="hljs-number">0.853</span><br><span class="hljs-number">64557.2</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<h2 id="ResNet残差网络"><a href="#ResNet残差网络" class="headerlink" title="ResNet残差网络"></a>ResNet残差网络</h2><p><a href="https://www.bilibili.com/video/BV1bV41177ap/?spm_id_from=333.999.0.0&vd_source=f1e7eb1d150afc7b732a2b8c557e6d35">残差网络 ResNet【动手学深度学习v2】</a></p>
<p>通过视频可以更直观的理解残差网络的作用和改进之处。</p>
<p>残差块的实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Residual</span>(nn.Module):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_channels, num_channels,</span><br><span class="hljs-params">                 use_1x1conv=<span class="hljs-literal">False</span>, strides=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.conv1 = nn.Conv2d(input_channels, num_channels,<br>                               kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>, stride=strides)<br>        self.conv2 = nn.Conv2d(num_channels, num_channels,<br>                               kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> use_1x1conv:<br>            self.conv3 = nn.Conv2d(input_channels, num_channels,<br>                                   kernel_size=<span class="hljs-number">1</span>, stride=strides)<br>        <span class="hljs-keyword">else</span>:<br>            self.conv3 = <span class="hljs-literal">None</span><br>        self.bn1 = nn.BatchNorm2d(num_channels)<br>        self.bn2 = nn.BatchNorm2d(num_channels)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        Y = F.relu(self.bn1(self.conv1(X)))<br>        Y = self.bn2(self.conv2(Y))<br>        <span class="hljs-keyword">if</span> self.conv3:<br>            X = self.conv3(X)<br>        Y += X<br>        <span class="hljs-keyword">return</span> F.relu(Y)<br></code></pre></td></tr></table></figure>

<p>查看输入和输出形状一致的情况</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">blk = Residual(<span class="hljs-number">3</span>,<span class="hljs-number">3</span>)<br>X = torch.rand(<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>)<br>Y = blk(X)<br><span class="hljs-built_in">print</span>(Y.shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>])<br></code></pre></td></tr></table></figure>

<p>我们也可以在增加输出通道数的同时，减半输出的高和宽。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">blk = Residual(<span class="hljs-number">3</span>,<span class="hljs-number">6</span>, use_1x1conv=<span class="hljs-literal">True</span>, strides=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(blk(X).shape)<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure>

<h3 id="ResNet模型"><a href="#ResNet模型" class="headerlink" title="ResNet模型"></a>ResNet模型</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">b1 = nn.Sequential(nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>),<br>                   nn.BatchNorm2d(<span class="hljs-number">64</span>), nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 注意我们对第一个模块做了特别处理</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">input_channels, num_channels, num_residuals,</span><br><span class="hljs-params">                 first_block=<span class="hljs-literal">False</span></span>):<br>    blk = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>            blk.append(Residual(input_channels, num_channels,<br>                                use_1x1conv=<span class="hljs-literal">True</span>, strides=<span class="hljs-number">2</span>))<br>        <span class="hljs-keyword">else</span>:<br>            blk.append(Residual(num_channels, num_channels))<br>    <span class="hljs-keyword">return</span> blk<br><span class="hljs-comment"># 接着在ResNet加入所有残差块，每个模块使用2个残差块</span><br>b2 = nn.Sequential(*resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>))<br>b3 = nn.Sequential(*resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>))<br>b4 = nn.Sequential(*resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>))<br>b5 = nn.Sequential(*resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment"># 在ResNet中加入全剧平均汇聚层，以及全连接输出。</span><br>net = nn.Sequential(b1, b2, b3, b4, b5,<br>                    nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>                    nn.Flatten(), nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>))<br></code></pre></td></tr></table></figure>

<p>在训练ResNet之前，让我们观察一下ResNet中不同模块的输入形状是如何变化的。 在之前所有架构中，分辨率降低，通道数量增加，直到全局平均汇聚层聚集所有特征。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br><span class="hljs-comment"># output</span><br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">56</span>, <span class="hljs-number">56</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">56</span>, <span class="hljs-number">56</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">128</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">512</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>])<br>AdaptiveAvgPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">512</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>Flatten output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">512</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<p>训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">0.05</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">96</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.011</span>, train acc <span class="hljs-number">0.997</span>, test acc <span class="hljs-number">0.915</span><br><span class="hljs-number">4701.1</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（14）深度学习硬件：计算性能</title>
    <url>/2022/11/04/DL_14/</url>
    <content><![CDATA[<p>很好地理解算法和模型才可以捕获统计方面的问题，构建出具有出色性能的系统。同时，至少对底层硬件有一定的了解也是必不可少的。本节的内容可以作为理解某些算法为什么比其他算法更高效以及如何实现良好吞吐量的起点。</p>
<h2 id="数据并行vs模型并行"><a href="#数据并行vs模型并行" class="headerlink" title="数据并行vs模型并行"></a>数据并行vs模型并行</h2><ul>
<li>数据并行：将小批量分成n块，每个GPU拿到完整参数计算一块数据的梯度；通常性能更好</li>
<li>模型并行：将模型分成n块，每个GPU拿到一块模型计算它的前向后后向结果；通常用于模型大到单GPU放不下</li>
</ul>
<h2 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br></code></pre></td></tr></table></figure>

<p>我们使用 <a href="https://zh.d2l.ai/chapter_convolutional-neural-networks/lenet.html#sec-lenet">6.6节</a>中介绍的（稍加修改的）LeNet， 从零开始定义它，从而详细说明参数交换和同步。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 初始化模型参数</span><br>scale = <span class="hljs-number">0.01</span><br>W1 = torch.randn(size=(<span class="hljs-number">20</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>)) * scale<br>b1 = torch.zeros(<span class="hljs-number">20</span>)<br>W2 = torch.randn(size=(<span class="hljs-number">50</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>)) * scale<br>b2 = torch.zeros(<span class="hljs-number">50</span>)<br>W3 = torch.randn(size=(<span class="hljs-number">800</span>, <span class="hljs-number">128</span>)) * scale<br>b3 = torch.zeros(<span class="hljs-number">128</span>)<br>W4 = torch.randn(size=(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)) * scale<br>b4 = torch.zeros(<span class="hljs-number">10</span>)<br>params = [W1, b1, W2, b2, W3, b3, W4, b4]<br><br><span class="hljs-comment"># 定义模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">lenet</span>(<span class="hljs-params">X, params</span>):<br>    h1_conv = F.conv2d(<span class="hljs-built_in">input</span>=X, weight=params[<span class="hljs-number">0</span>], bias=params[<span class="hljs-number">1</span>])<br>    h1_activation = F.relu(h1_conv)<br>    h1 = F.avg_pool2d(<span class="hljs-built_in">input</span>=h1_activation, kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>    h2_conv = F.conv2d(<span class="hljs-built_in">input</span>=h1, weight=params[<span class="hljs-number">2</span>], bias=params[<span class="hljs-number">3</span>])<br>    h2_activation = F.relu(h2_conv)<br>    h2 = F.avg_pool2d(<span class="hljs-built_in">input</span>=h2_activation, kernel_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br>    h2 = h2.reshape(h2.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br>    h3_linear = torch.mm(h2, params[<span class="hljs-number">4</span>]) + params[<span class="hljs-number">5</span>]<br>    h3 = F.relu(h3_linear)<br>    y_hat = torch.mm(h3, params[<span class="hljs-number">6</span>]) + params[<span class="hljs-number">7</span>]<br>    <span class="hljs-keyword">return</span> y_hat<br><br><span class="hljs-comment"># 交叉熵损失函数</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>向多个设备分发参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_params</span>(<span class="hljs-params">params, device</span>):<br>    new_params = [p.to(device) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> params]<br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> new_params:<br>        p.requires_grad_()<br>    <span class="hljs-keyword">return</span> new_params<br>new_params = get_params(params, d2l.try_gpu(<span class="hljs-number">0</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b1 权重:&#x27;</span>, new_params[<span class="hljs-number">1</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;b1 梯度:&#x27;</span>, new_params[<span class="hljs-number">1</span>].grad)<br><span class="hljs-comment"># output</span><br>b1 权重: tensor([<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>],<br>       device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>, requires_grad=<span class="hljs-literal">True</span>)<br>b1 梯度: <span class="hljs-literal">None</span><br></code></pre></td></tr></table></figure>

<p><code>allreduce</code>函数将所有向量相加，并将结果广播给所有GPU</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">allreduce</span>(<span class="hljs-params">data</span>):<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(data)):<br>        data[<span class="hljs-number">0</span>][:] += data[i].to(data[<span class="hljs-number">0</span>].device)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(data)):<br>        data[i][:] = data[<span class="hljs-number">0</span>].to(data[i].device)<br>data = [torch.ones((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>), device=d2l.try_gpu(i)) * (i + <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;allreduce之前：\n&#x27;</span>, data[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, data[<span class="hljs-number">1</span>])<br>allreduce(data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;allreduce之后：\n&#x27;</span>, data[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;\n&#x27;</span>, data[<span class="hljs-number">1</span>])<br><span class="hljs-comment"># output</span><br>allreduce之前：<br> tensor([[<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br> tensor([[<span class="hljs-number">2.</span>, <span class="hljs-number">2.</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br>allreduce之后：<br> tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>)<br> tensor([[<span class="hljs-number">3.</span>, <span class="hljs-number">3.</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>我们需要一个简单的工具函数，将一个小批量数据均匀地分布在多个GPU上。 例如，有两个GPU时，我们希望每个GPU可以复制一半的数据。 因为深度学习框架的内置函数编写代码更方便、更简洁，所以在4×5矩阵上使用它进行尝试。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">data = torch.arange(<span class="hljs-number">20</span>).reshape(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br>devices = [torch.device(<span class="hljs-string">&#x27;cuda:0&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda:1&#x27;</span>)]<br>split = nn.parallel.scatter(data, devices)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;input :&#x27;</span>, data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;load into&#x27;</span>, devices)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;output:&#x27;</span>, split)<br><span class="hljs-comment"># output</span><br><span class="hljs-built_in">input</span> : tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>],<br>        [ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>],<br>        [<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>]])<br>load into [device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br>output: (tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]], device=<span class="hljs-string">&#x27;cuda:0&#x27;</span>), tensor([[<span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>],<br>        [<span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>]], device=<span class="hljs-string">&#x27;cuda:1&#x27;</span>))<br></code></pre></td></tr></table></figure>

<p>为了方便以后复用，我们定义了可以同时拆分数据和标签的<code>split_batch</code>函数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">split_batch</span>(<span class="hljs-params">X, y, devices</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;将X和y拆分到多个设备上&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">assert</span> X.shape[<span class="hljs-number">0</span>] == y.shape[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">return</span> (nn.parallel.scatter(X, devices),<br>            nn.parallel.scatter(y, devices))<br></code></pre></td></tr></table></figure>

<p>训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch</span>(<span class="hljs-params">X, y, device_params, devices, lr</span>):<br>    X_shards, y_shards = split_batch(X, y, devices)<br>    <span class="hljs-comment"># 在每个GPU上分别计算损失</span><br>    ls = [loss(lenet(X_shard, device_W), y_shard).<span class="hljs-built_in">sum</span>()<br>          <span class="hljs-keyword">for</span> X_shard, y_shard, device_W <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(<br>              X_shards, y_shards, device_params)]<br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> ls:  <span class="hljs-comment"># 反向传播在每个GPU上分别执行</span><br>        l.backward()<br>    <span class="hljs-comment"># 将每个GPU的所有梯度相加，并将其广播到所有GPU</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(device_params[<span class="hljs-number">0</span>])):<br>            allreduce(<br>                [device_params[c][i].grad <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(devices))])<br>    <span class="hljs-comment"># 在每个GPU上分别更新模型参数</span><br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> device_params:<br>        d2l.sgd(param, lr, X.shape[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 在这里，我们使用全尺寸的小批量</span><br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">num_gpus, batch_size, lr</span>):<br>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>    devices = [d2l.try_gpu(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gpus)]<br>    <span class="hljs-comment"># 将模型参数复制到num_gpus个GPU</span><br>    device_params = [get_params(params, d) <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> devices]<br>    num_epochs = <span class="hljs-number">10</span><br>    animator = d2l.Animator(<span class="hljs-string">&#x27;epoch&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs])<br>    timer = d2l.Timer()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        timer.start()<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-comment"># 为单个小批量执行多GPU训练</span><br>            train_batch(X, y, device_params, devices, lr)<br>            torch.cuda.synchronize()<br>        timer.stop()<br>        <span class="hljs-comment"># 在GPU0上评估模型</span><br>        animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_accuracy_gpu(<br>            <span class="hljs-keyword">lambda</span> x: lenet(x, device_params[<span class="hljs-number">0</span>]), test_iter, devices[<span class="hljs-number">0</span>]),))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;测试精度：<span class="hljs-subst">&#123;animator.Y[<span class="hljs-number">0</span>][-<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>，<span class="hljs-subst">&#123;timer.avg():<span class="hljs-number">.1</span>f&#125;</span>秒/轮，&#x27;</span><br>          <span class="hljs-string">f&#x27;在<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train(num_gpus=<span class="hljs-number">1</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.80</span>，<span class="hljs-number">2.7</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>)]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train(num_gpus=<span class="hljs-number">2</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.84</span>，<span class="hljs-number">2.8</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br><br></code></pre></td></tr></table></figure>

<p>多GPU的简洁实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet18</span>(<span class="hljs-params">num_classes, in_channels=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;稍加修改的ResNet-18模型&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">resnet_block</span>(<span class="hljs-params">in_channels, out_channels, num_residuals,</span><br><span class="hljs-params">                     first_block=<span class="hljs-literal">False</span></span>):<br>        blk = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_residuals):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> first_block:<br>                blk.append(d2l.Residual(in_channels, out_channels,<br>                                        use_1x1conv=<span class="hljs-literal">True</span>, strides=<span class="hljs-number">2</span>))<br>            <span class="hljs-keyword">else</span>:<br>                blk.append(d2l.Residual(out_channels, out_channels))<br>        <span class="hljs-keyword">return</span> nn.Sequential(*blk)<br><br>    <span class="hljs-comment"># 该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层</span><br>    net = nn.Sequential(<br>        nn.Conv2d(in_channels, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>        nn.BatchNorm2d(<span class="hljs-number">64</span>),<br>        nn.ReLU())<br>    net.add_module(<span class="hljs-string">&quot;resnet_block1&quot;</span>, resnet_block(<br>        <span class="hljs-number">64</span>, <span class="hljs-number">64</span>, <span class="hljs-number">2</span>, first_block=<span class="hljs-literal">True</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block2&quot;</span>, resnet_block(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block3&quot;</span>, resnet_block(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;resnet_block4&quot;</span>, resnet_block(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, <span class="hljs-number">2</span>))<br>    net.add_module(<span class="hljs-string">&quot;global_avg_pool&quot;</span>, nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)))<br>    net.add_module(<span class="hljs-string">&quot;fc&quot;</span>, nn.Sequential(nn.Flatten(),<br>                                       nn.Linear(<span class="hljs-number">512</span>, num_classes)))<br>    <span class="hljs-keyword">return</span> net<br><br>net = resnet18(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># 获取GPU列表</span><br>devices = d2l.try_all_gpus()<br><span class="hljs-comment"># 我们将在训练代码实现中初始化网络</span><br><br><span class="hljs-comment">#训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">net, num_gpus, batch_size, lr</span>):<br>    train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>    devices = [d2l.try_gpu(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_gpus)]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) <span class="hljs-keyword">in</span> [nn.Linear, nn.Conv2d]:<br>            nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br>    net.apply(init_weights)<br>    <span class="hljs-comment"># 在多个GPU上设置模型</span><br>    net = nn.DataParallel(net, device_ids=devices)<br>    trainer = torch.optim.SGD(net.parameters(), lr)<br>    loss = nn.CrossEntropyLoss()<br>    timer, num_epochs = d2l.Timer(), <span class="hljs-number">10</span><br>    animator = d2l.Animator(<span class="hljs-string">&#x27;epoch&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        net.train()<br>        timer.start()<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            X, y = X.to(devices[<span class="hljs-number">0</span>]), y.to(devices[<span class="hljs-number">0</span>])<br>            l = loss(net(X), y)<br>            l.backward()<br>            trainer.step()<br>        timer.stop()<br>        animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_accuracy_gpu(net, test_iter),))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;测试精度：<span class="hljs-subst">&#123;animator.Y[<span class="hljs-number">0</span>][-<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>，<span class="hljs-subst">&#123;timer.avg():<span class="hljs-number">.1</span>f&#125;</span>秒/轮，&#x27;</span><br>          <span class="hljs-string">f&#x27;在<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train(net, num_gpus=<span class="hljs-number">1</span>, batch_size=<span class="hljs-number">256</span>, lr=<span class="hljs-number">0.1</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.92</span>，<span class="hljs-number">13.7</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>)]<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">train(net, num_gpus=<span class="hljs-number">2</span>, batch_size=<span class="hljs-number">512</span>, lr=<span class="hljs-number">0.2</span>)<br><span class="hljs-comment"># output</span><br>测试精度：<span class="hljs-number">0.89</span>，<span class="hljs-number">8.4</span>秒/轮，在[device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">0</span>), device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>, index=<span class="hljs-number">1</span>)]<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（12）现代卷积神经网络（1）</title>
    <url>/2022/10/31/DL_12/</url>
    <content><![CDATA[<p>本章我们将带你了解现代的卷积神经网络架构，在本章中的每一个模型都曾一度占据主导地位，其中许多模型都是ImageNet竞赛的优胜者。</p>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>是一个更深更大的LeNet，主要改进：dropout、ReLu、MaxPooling</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>net = nn.Sequential(<br>    <span class="hljs-comment"># 这里，我们使用一个11*11的更大窗口来捕捉对象。</span><br>    <span class="hljs-comment"># 同时，步幅为4，以减少输出的高度和宽度。</span><br>    <span class="hljs-comment"># 另外，输出通道的数目远大于LeNet</span><br>    nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span><br>    nn.Conv2d(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    <span class="hljs-comment"># 使用三个连续的卷积层和较小的卷积窗口。</span><br>    <span class="hljs-comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span><br>    <span class="hljs-comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span><br>    nn.Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.Conv2d(<span class="hljs-number">384</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>), nn.ReLU(),<br>    nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Flatten(),<br>    <span class="hljs-comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span><br>    nn.Linear(<span class="hljs-number">6400</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>    nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>), nn.ReLU(),<br>    nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>    <span class="hljs-comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span><br>    nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>))<br><span class="hljs-comment"># 构造一个高度和宽度都为224的单通道数据，来观察每一层输出的形状。</span><br>X = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X=layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>,X.shape)<br><span class="hljs-comment"># output</span><br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">54</span>, <span class="hljs-number">54</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">54</span>, <span class="hljs-number">54</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">26</span>, <span class="hljs-number">26</span>])<br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">26</span>, <span class="hljs-number">26</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">26</span>, <span class="hljs-number">26</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>Conv2d output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>Flatten output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">6400</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Dropout output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Dropout output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 读取数据集</span><br>batch_size = <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br><span class="hljs-comment"># 训练AlexNet</span><br>lr, num_epochs = <span class="hljs-number">0.01</span>, <span class="hljs-number">10</span><br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.327</span>, train acc <span class="hljs-number">0.881</span>, test acc <span class="hljs-number">0.885</span><br><span class="hljs-number">4149.6</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<h2 id="VGG-使用块的网络"><a href="#VGG-使用块的网络" class="headerlink" title="VGG 使用块的网络"></a>VGG 使用块的网络</h2><p>更大更深的AlexNet（重复的VGG块）</p>
<ul>
<li>VGG使用可重复使用的卷积块来构建深度卷积神经网络</li>
<li>不同的卷积块个数和超参数可以得到不同复杂度的变种</li>
</ul>
<p>VGG块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg_block</span>(<span class="hljs-params">num_convs, in_channels, out_channels</span>):<br>    layers = []<br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_convs):<br>        layers.append(nn.Conv2d(in_channels, out_channels,<br>                                kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>))<br>        layers.append(nn.ReLU())<br>        in_channels = out_channels<br>    layers.append(nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>,stride=<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br></code></pre></td></tr></table></figure>

<p>VGG网络</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">conv_arch = ((<span class="hljs-number">1</span>, <span class="hljs-number">64</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">512</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">512</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">vgg</span>(<span class="hljs-params">conv_arch</span>):<br>    conv_blks = []<br>    in_channels = <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 卷积层部分</span><br>    <span class="hljs-keyword">for</span> (num_convs, out_channels) <span class="hljs-keyword">in</span> conv_arch:<br>        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))<br>        in_channels = out_channels<br><br>    <span class="hljs-keyword">return</span> nn.Sequential(<br>        *conv_blks, nn.Flatten(),<br>        <span class="hljs-comment"># 全连接层部分</span><br>        nn.Linear(out_channels * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">4096</span>), nn.ReLU(), nn.Dropout(<span class="hljs-number">0.5</span>),<br>        nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">4096</span>), nn.ReLU(), nn.Dropout(<span class="hljs-number">0.5</span>),<br>        nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>))<br><br>net = vgg(conv_arch)<br><span class="hljs-comment"># 构建一个高度和宽度为224的单通道数据样本，以观察每个层输出的形状。</span><br>X = torch.randn(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> net:<br>    X = blk(X)<br>    <span class="hljs-built_in">print</span>(blk.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>,X.shape)<br><span class="hljs-comment"># output</span><br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">112</span>, <span class="hljs-number">112</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">128</span>, <span class="hljs-number">56</span>, <span class="hljs-number">56</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">512</span>, <span class="hljs-number">14</span>, <span class="hljs-number">14</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">512</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>])<br>Flatten output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">25088</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Dropout output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>ReLU output shape:   torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Dropout output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">4096</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<p>构建一个通道数较少的网络，足够用于训练Fashion-MNIST数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">ratio = <span class="hljs-number">4</span><br>small_conv_arch = [(pair[<span class="hljs-number">0</span>], pair[<span class="hljs-number">1</span>] // ratio) <span class="hljs-keyword">for</span> pair <span class="hljs-keyword">in</span> conv_arch]<br>net = vgg(small_conv_arch)<br>lr, num_epochs, batch_size = <span class="hljs-number">0.05</span>, <span class="hljs-number">10</span>, <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.177</span>, train acc <span class="hljs-number">0.934</span>, test acc <span class="hljs-number">0.911</span><br><span class="hljs-number">2562.3</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<h2 id="NiN-网络中的网络"><a href="#NiN-网络中的网络" class="headerlink" title="NiN 网络中的网络"></a>NiN 网络中的网络</h2><p>NiN块：一个卷积层后跟两个全连接层</p>
<ul>
<li>步幅1， 无填充，输出形状跟卷积层输出一样</li>
<li>起到全连接层的作用</li>
</ul>
<p>NiN架构：</p>
<ul>
<li>无全连接层</li>
<li>交替使用NiN块和步幅为2的MaxPooling层<ul>
<li>逐步减小高宽和增大通道数</li>
</ul>
</li>
<li>最后使用全局平均池化层得到输出<ul>
<li>其输入通道数是类别数</li>
</ul>
</li>
</ul>
<p>NiN使用全局平均池化层来替代VGG和AlexNet中的全连接层</p>
<ul>
<li>不容易过拟合，更少的参数个数</li>
</ul>
<p>NiN块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">nin_block</span>(<span class="hljs-params">in_channels, out_channels, kernel_size, strides, padding</span>):<br>    <span class="hljs-keyword">return</span> nn.Sequential(<br>        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),<br>        nn.ReLU(),<br>        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="hljs-number">1</span>), nn.ReLU(),<br>        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="hljs-number">1</span>), nn.ReLU())<br></code></pre></td></tr></table></figure>

<p>NiN模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">net = nn.Sequential(<br>    nin_block(<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, kernel_size=<span class="hljs-number">11</span>, strides=<span class="hljs-number">4</span>, padding=<span class="hljs-number">0</span>),<br>    nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    nin_block(<span class="hljs-number">96</span>, <span class="hljs-number">256</span>, kernel_size=<span class="hljs-number">5</span>, strides=<span class="hljs-number">1</span>, padding=<span class="hljs-number">2</span>),<br>    nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    nin_block(<span class="hljs-number">256</span>, <span class="hljs-number">384</span>, kernel_size=<span class="hljs-number">3</span>, strides=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>    nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),<br>    nn.Dropout(<span class="hljs-number">0.5</span>),<br>    <span class="hljs-comment"># 标签类别数是10</span><br>    nin_block(<span class="hljs-number">384</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">3</span>, strides=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>    nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>)),<br>    <span class="hljs-comment"># 将四维的输出转成二维的输出，其形状为(批量大小,10)</span><br>    nn.Flatten())<br><span class="hljs-comment"># 查看每个块的形状</span><br>X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br><span class="hljs-comment"># output</span><br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">54</span>, <span class="hljs-number">54</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">26</span>, <span class="hljs-number">26</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">26</span>, <span class="hljs-number">26</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">256</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>MaxPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>Dropout output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">384</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>])<br>AdaptiveAvgPool2d output shape:      torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])<br>Flatten output shape:        torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练模型</span><br>lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">224</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.363</span>, train acc <span class="hljs-number">0.865</span>, test acc <span class="hljs-number">0.879</span><br><span class="hljs-number">3212.2</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p><a href="https://www.bilibili.com/video/BV1b5411g7Xo/?spm_id_from=autoNext&vd_source=f1e7eb1d150afc7b732a2b8c557e6d35">GoogLeNet &#x2F; Inception V3【动手学深度学习v2】</a></p>
<p>Inception块：4个路径从不同层面抽取信息，然后再输出通道合并</p>
<ul>
<li>优点是模型参数小，计算复杂度低</li>
</ul>
<p>GoogLeNet使用了9个Inception块</p>
<p>实现</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Inception</span>(nn.Module):<br>    <span class="hljs-comment"># c1--c4是每条路径的输出通道数</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, c1, c2, c3, c4, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(Inception, self).__init__(**kwargs)<br>        <span class="hljs-comment"># 线路1，单1x1卷积层</span><br>        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 线路2，1x1卷积层后接3x3卷积层</span><br>        self.p2_1 = nn.Conv2d(in_channels, c2[<span class="hljs-number">0</span>], kernel_size=<span class="hljs-number">1</span>)<br>        self.p2_2 = nn.Conv2d(c2[<span class="hljs-number">0</span>], c2[<span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># 线路3，1x1卷积层后接5x5卷积层</span><br>        self.p3_1 = nn.Conv2d(in_channels, c3[<span class="hljs-number">0</span>], kernel_size=<span class="hljs-number">1</span>)<br>        self.p3_2 = nn.Conv2d(c3[<span class="hljs-number">0</span>], c3[<span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 线路4，3x3最大汇聚层后接1x1卷积层</span><br>        self.p4_1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        p1 = F.relu(self.p1_1(x))<br>        p2 = F.relu(self.p2_2(F.relu(self.p2_1(x))))<br>        p3 = F.relu(self.p3_2(F.relu(self.p3_1(x))))<br>        p4 = F.relu(self.p4_2(self.p4_1(x)))<br>        <span class="hljs-comment"># 在通道维度上连结输出</span><br>        <span class="hljs-keyword">return</span> torch.cat((p1, p2, p3, p4), dim=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<p>接下来逐一实现GoogLeNet的每个模块</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一个模块</span><br>b1 = nn.Sequential(nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>),<br>                   nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 第二个模块</span><br>b2 = nn.Sequential(nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">1</span>),<br>                   nn.ReLU(),<br>                   nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),<br>                   nn.ReLU(),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 第三个模块</span><br>b3 = nn.Sequential(Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">128</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">32</span>), <span class="hljs-number">32</span>),<br>                   Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">192</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">96</span>), <span class="hljs-number">64</span>),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 第四个模块</span><br>b4 = nn.Sequential(Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, (<span class="hljs-number">96</span>, <span class="hljs-number">208</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">48</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, (<span class="hljs-number">112</span>, <span class="hljs-number">224</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, (<span class="hljs-number">128</span>, <span class="hljs-number">256</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, (<span class="hljs-number">144</span>, <span class="hljs-number">288</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">64</span>), <span class="hljs-number">64</span>),<br>                   Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>))<br><span class="hljs-comment"># 第五个模块</span><br>b5 = nn.Sequential(Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, (<span class="hljs-number">160</span>, <span class="hljs-number">320</span>), (<span class="hljs-number">32</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, (<span class="hljs-number">192</span>, <span class="hljs-number">384</span>), (<span class="hljs-number">48</span>, <span class="hljs-number">128</span>), <span class="hljs-number">128</span>),<br>                   nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>,<span class="hljs-number">1</span>)),<br>                   nn.Flatten())<br><br>net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>))<br><span class="hljs-comment"># 下面演示各个模块输出的形状变化</span><br>X = torch.rand(size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">96</span>))<br><span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> net:<br>    X = layer(X)<br>    <span class="hljs-built_in">print</span>(layer.__class__.__name__,<span class="hljs-string">&#x27;output shape:\t&#x27;</span>, X.shape)<br><span class="hljs-comment"># output</span><br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">24</span>, <span class="hljs-number">24</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">192</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">480</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">832</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>])<br>Sequential output shape:     torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">1024</span>])<br>Linear output shape:         torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">10</span>])<br></code></pre></td></tr></table></figure>

<p>训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">lr, num_epochs, batch_size = <span class="hljs-number">0.1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">128</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=<span class="hljs-number">96</span>)<br>d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())<br><span class="hljs-comment"># output</span><br>loss <span class="hljs-number">0.254</span>, train acc <span class="hljs-number">0.904</span>, test acc <span class="hljs-number">0.885</span><br><span class="hljs-number">3570.5</span> examples/sec on cuda:<span class="hljs-number">0</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（17）锚框</title>
    <url>/2022/11/08/DL_17/</url>
    <content><![CDATA[<p>以每个像素为中心，生成多个缩放比和宽高比（aspect ratio）不同的边界框。 这些边界框被称为<em>锚框</em>（anchor box）。</p>
<p><a href="https://zh.d2l.ai/chapter_computer-vision/anchor.html">13.4. 锚框 — 动手学深度学习 2.0.0-beta1 documentation (d2l.ai)</a></p>
<p>结合上面连接中课本的代码和图片进行理解比较容易理解。</p>
<ul>
<li>提出多个被称为锚框的区域</li>
<li>预测每个锚框里是否含有关注的物体</li>
<li>如果是，预测从这个锚框到真实边缘框的偏移</li>
</ul>
<h3 id="IoU-交并比"><a href="#IoU-交并比" class="headerlink" title="IoU-交并比"></a>IoU-交并比</h3><p>IoU用来计算两个框之间的相似度，0表示无重叠，1表示重叠。</p>
<p>这是Jacquard指数的一种特殊情况，给定两个集合A和B。<br>MATHJAX-SSR-10</p>
<h3 id="赋予锚框标号"><a href="#赋予锚框标号" class="headerlink" title="赋予锚框标号"></a>赋予锚框标号</h3><p>每个锚框是一个训练样本，将每个锚框，要么标注为背景，要么关联上一个真实边缘框。我们可能会生成大量的锚框（这个导致大量的负类样本）。</p>
<h3 id="使用非极大值抑制（NMS）输出"><a href="#使用非极大值抑制（NMS）输出" class="headerlink" title="使用非极大值抑制（NMS）输出"></a>使用非极大值抑制（NMS）输出</h3><p>每个锚框预测一个边缘框，NMS可以合并相似的预测</p>
<ul>
<li>选择是非背景类的最大预测值</li>
<li>去掉所有其他和他IoU值大于 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.09ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 469.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\theta</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
</g>
</svg> 的预测</li>
<li>重复上述过程直到所有预测要么被选中，要么被去掉</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（15）图像增广和微调</title>
    <url>/2022/11/07/DL_15/</url>
    <content><![CDATA[<p>我们提到过大型数据集是成功应用深度神经网络的先决条件。</p>
<h2 id="1-图像增广"><a href="#1-图像增广" class="headerlink" title="1.图像增广"></a>1.图像增广</h2><p>图像增广在对训练图像进行一系列的随机变化之后，生成相似但不同的训练样本，从而扩大了训练集的规模。 此外，应用图像增广的原因是，随机改变训练样本可以减少模型对某些属性的依赖，从而提高模型的泛化能力。例如，我们可以以不同的方式裁剪图像，使感兴趣的对象出现在不同的位置，减少模型对于对象出现位置的依赖。 我们还可以调整亮度、颜色等因素来降低模型对颜色的敏感度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-comment"># 将使用下面这个尺寸为400x500的图像作为示例</span><br>d2l.set_figsize()<br>img = d2l.Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;../img/cat1.jpg&#x27;</span>)<br>d2l.plt.imshow(img);<br><span class="hljs-comment"># 定义辅助函数apply。 此函数在输入图像img上多次运行图像增广方法aug并显示所有结果。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">apply</span>(<span class="hljs-params">img, aug, num_rows=<span class="hljs-number">2</span>, num_cols=<span class="hljs-number">4</span>, scale=<span class="hljs-number">1.5</span></span>):<br>    Y = [aug(img) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_rows * num_cols)]<br>    d2l.show_images(Y, num_rows, num_cols, scale=scale)<br><span class="hljs-comment"># 翻转和裁剪</span><br>apply(img, torchvision.transforms.RandomHorizontalFlip())<br>apply(img, torchvision.transforms.RandomVerticalFlip())<br>shape_aug = torchvision.transforms.RandomResizedCrop(<br>    (<span class="hljs-number">200</span>, <span class="hljs-number">200</span>), scale=(<span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>), ratio=(<span class="hljs-number">0.5</span>, <span class="hljs-number">2</span>))<br>apply(img, shape_aug)<br><span class="hljs-comment"># 改变颜色</span><br>apply(img, torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0</span>, saturation=<span class="hljs-number">0</span>, hue=<span class="hljs-number">0</span>))<br>apply(img, torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0</span>, contrast=<span class="hljs-number">0</span>, saturation=<span class="hljs-number">0</span>, hue=<span class="hljs-number">0.5</span>))<br>color_aug = torchvision.transforms.ColorJitter(<br>    brightness=<span class="hljs-number">0.5</span>, contrast=<span class="hljs-number">0.5</span>, saturation=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>)<br>apply(img, color_aug)<br><span class="hljs-comment"># 结合多种图像增广方法</span><br>augs = torchvision.transforms.Compose([<br>    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])<br>apply(img, augs)<br></code></pre></td></tr></table></figure>

<h3 id="利用图像增广进行训练"><a href="#利用图像增广进行训练" class="headerlink" title="利用图像增广进行训练"></a>利用图像增广进行训练</h3><p>这里，我们使用CIFAR-10数据集，而不是我们之前使用的Fashion-MNIST数据集。 这是因为Fashion-MNIST数据集中对象的位置和大小已被规范化，而CIFAR-10数据集中对象的颜色和大小差异更明显。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">all_images = torchvision.datasets.CIFAR10(train=<span class="hljs-literal">True</span>, root=<span class="hljs-string">&quot;../data&quot;</span>, download=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 我们使用ToTensor实例将一批图像转换为深度学习框架所要求的格式，</span><br><span class="hljs-comment"># 即形状为（批量大小，通道数，高度，宽度）的32位浮点数，取值范围为0到1。</span><br>train_augs = torchvision.transforms.Compose([<br>     torchvision.transforms.RandomHorizontalFlip(),<br>     torchvision.transforms.ToTensor()])<br><br>test_augs = torchvision.transforms.Compose([<br>     torchvision.transforms.ToTensor()])<br><span class="hljs-comment"># 定义一个辅助函数，以便于读取图像和应用图像增广。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_cifar10</span>(<span class="hljs-params">is_train, augs, batch_size</span>):<br>    dataset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&quot;../data&quot;</span>, train=is_train,<br>                                           transform=augs, download=<span class="hljs-literal">True</span>)<br>    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,<br>                    shuffle=is_train, num_workers=d2l.get_dataloader_workers())<br>    <span class="hljs-keyword">return</span> dataloader<br><span class="hljs-comment"># 多GPU训练</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_batch_ch13</span>(<span class="hljs-params">net, X, y, loss, trainer, devices</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用多GPU进行小批量训练&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(X, <span class="hljs-built_in">list</span>):<br>        <span class="hljs-comment"># 微调BERT中所需（稍后讨论）</span><br>        X = [x.to(devices[<span class="hljs-number">0</span>]) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X]<br>    <span class="hljs-keyword">else</span>:<br>        X = X.to(devices[<span class="hljs-number">0</span>])<br>    y = y.to(devices[<span class="hljs-number">0</span>])<br>    net.train()<br>    trainer.zero_grad()<br>    pred = net(X)<br>    l = loss(pred, y)<br>    l.<span class="hljs-built_in">sum</span>().backward()<br>    trainer.step()<br>    train_loss_sum = l.<span class="hljs-built_in">sum</span>()<br>    train_acc_sum = d2l.accuracy(pred, y)<br>    <span class="hljs-keyword">return</span> train_loss_sum, train_acc_sum<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch13</span>(<span class="hljs-params">net, train_iter, test_iter, loss, trainer, num_epochs,</span><br><span class="hljs-params">               devices=d2l.try_all_gpus(<span class="hljs-params"></span>)</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用多GPU进行模型训练&quot;&quot;&quot;</span><br>    timer, num_batches = d2l.Timer(), <span class="hljs-built_in">len</span>(train_iter)<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs], ylim=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>                            legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    net = nn.DataParallel(net, device_ids=devices).to(devices[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-comment"># 4个维度：储存训练损失，训练准确度，实例数，特点数</span><br>        metric = d2l.Accumulator(<span class="hljs-number">4</span>)<br>        <span class="hljs-keyword">for</span> i, (features, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_iter):<br>            timer.start()<br>            l, acc = train_batch_ch13(<br>                net, features, labels, loss, trainer, devices)<br>            metric.add(l, acc, labels.shape[<span class="hljs-number">0</span>], labels.numel())<br>            timer.stop()<br>            <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % (num_batches // <span class="hljs-number">5</span>) == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> i == num_batches - <span class="hljs-number">1</span>:<br>                animator.add(epoch + (i + <span class="hljs-number">1</span>) / num_batches,<br>                             (metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>], metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">3</span>],<br>                              <span class="hljs-literal">None</span>))<br>        test_acc = d2l.evaluate_accuracy_gpu(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, (<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, test_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;loss <span class="hljs-subst">&#123;metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>]:<span class="hljs-number">.3</span>f&#125;</span>, train acc &#x27;</span><br>          <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">3</span>]:<span class="hljs-number">.3</span>f&#125;</span>, test acc <span class="hljs-subst">&#123;test_acc:<span class="hljs-number">.3</span>f&#125;</span>&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;metric[<span class="hljs-number">2</span>] * num_epochs / timer.<span class="hljs-built_in">sum</span>():<span class="hljs-number">.1</span>f&#125;</span> examples/sec on &#x27;</span><br>          <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(devices)&#125;</span>&#x27;</span>)<br><span class="hljs-comment"># 定义train_with_data_aug函数，使用图像增广来训练模型。</span><br><span class="hljs-comment"># 该函数获取所有的GPU，并使用Adam作为训练的优化算法，将图像增广应用于训练集，</span><br><span class="hljs-comment"># 最后调用刚刚定义的用于训练和评估模型的train_ch13函数。</span><br>batch_size, devices, net = <span class="hljs-number">256</span>, d2l.try_all_gpus(), d2l.resnet18(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) <span class="hljs-keyword">in</span> [nn.Linear, nn.Conv2d]:<br>        nn.init.xavier_uniform_(m.weight)<br><br>net.apply(init_weights)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_with_data_aug</span>(<span class="hljs-params">train_augs, test_augs, net, lr=<span class="hljs-number">0.001</span></span>):<br>    train_iter = load_cifar10(<span class="hljs-literal">True</span>, train_augs, batch_size)<br>    test_iter = load_cifar10(<span class="hljs-literal">False</span>, test_augs, batch_size)<br>    loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br>    trainer = torch.optim.Adam(net.parameters(), lr=lr)<br>    train_ch13(net, train_iter, test_iter, loss, trainer, <span class="hljs-number">10</span>, devices)<br><span class="hljs-comment"># 基于随机左右翻转的图像增广来训练模型。</span><br>train_with_data_aug(train_augs, test_augs, net)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.177, train acc 0.938, test acc 0.835</span><br><span class="hljs-comment"># 5616.3 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>

<h2 id="2-微调（重点技术）"><a href="#2-微调（重点技术）" class="headerlink" title="2.微调（重点技术）"></a>2.微调（重点技术）</h2><ul>
<li>微调通过使用在大数据集上得到的预训练好的模型来初始化模型权重来完成提升精度</li>
<li>预训练模型质量很重要</li>
<li>微调通常速度更快、精度更高</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment"># 获取数据集</span><br><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">&#x27;hotdog&#x27;</span>] = (d2l.DATA_URL + <span class="hljs-string">&#x27;hotdog.zip&#x27;</span>,    <span class="hljs-string">&#x27;fba480ffa8aa7e0febbb511d181409f899b9baa5&#x27;</span>)<br>data_dir = d2l.download_extract(<span class="hljs-string">&#x27;hotdog&#x27;</span>)<br><span class="hljs-comment"># 创建两个实例来分别读取训练和测试数据集中的所有图像文件。</span><br>train_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>))<br>test_imgs = torchvision.datasets.ImageFolder(os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>))<br><span class="hljs-comment"># 使用RGB通道的均值和标准差，以标准化每个通道</span><br>normalize = torchvision.transforms.Normalize(<br>    [<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>], [<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br><br>train_augs = torchvision.transforms.Compose([<br>    torchvision.transforms.RandomResizedCrop(<span class="hljs-number">224</span>),<br>    torchvision.transforms.RandomHorizontalFlip(),<br>    torchvision.transforms.ToTensor(),<br>    normalize])<br><br>test_augs = torchvision.transforms.Compose([<br>    torchvision.transforms.Resize(<span class="hljs-number">256</span>),<br>    torchvision.transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    torchvision.transforms.ToTensor(),<br>    normalize])<br><span class="hljs-comment"># 定义和初始化模型</span><br>pretrained_net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># print(pretrained_net.fc)</span><br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># Linear(in_features=512, out_features=1000, bias=True)</span><br>finetune_net = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br>finetune_net.fc = nn.Linear(finetune_net.fc.in_features, <span class="hljs-number">2</span>)<br>nn.init.xavier_uniform_(finetune_net.fc.weight)<br><span class="hljs-comment"># 微调模型</span><br><span class="hljs-comment"># 如果param_group=True，输出层中的模型参数将使用十倍的学习率</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_fine_tuning</span>(<span class="hljs-params">net, learning_rate, batch_size=<span class="hljs-number">128</span>, num_epochs=<span class="hljs-number">5</span>,</span><br><span class="hljs-params">                      param_group=<span class="hljs-literal">True</span></span>):<br>    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;train&#x27;</span>), transform=train_augs),<br>        batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(<br>        os.path.join(data_dir, <span class="hljs-string">&#x27;test&#x27;</span>), transform=test_augs),<br>        batch_size=batch_size)<br>    devices = d2l.try_all_gpus()<br>    loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&quot;none&quot;</span>)<br>    <span class="hljs-keyword">if</span> param_group:<br>        params_1x = [param <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net.named_parameters()<br>             <span class="hljs-keyword">if</span> name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;fc.weight&quot;</span>, <span class="hljs-string">&quot;fc.bias&quot;</span>]]<br>        trainer = torch.optim.SGD([&#123;<span class="hljs-string">&#x27;params&#x27;</span>: params_1x&#125;,<br>                                   &#123;<span class="hljs-string">&#x27;params&#x27;</span>: net.fc.parameters(),<br>                                    <span class="hljs-string">&#x27;lr&#x27;</span>: learning_rate * <span class="hljs-number">10</span>&#125;],<br>                                lr=learning_rate, weight_decay=<span class="hljs-number">0.001</span>)<br>    <span class="hljs-keyword">else</span>:<br>        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate,<br>                                  weight_decay=<span class="hljs-number">0.001</span>)<br>    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,<br>                   devices)<br>train_fine_tuning(finetune_net, <span class="hljs-number">5e-5</span>)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.191, train acc 0.931, test acc 0.949</span><br><span class="hljs-comment"># 1086.6 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>

<p>为了进行比较，我们定义了一个相同的模型，但是将其所有模型参数初始化为随机值。 由于整个模型需要从头开始训练，因此我们需要使用更大的学习率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">scratch_net = torchvision.models.resnet18()<br>scratch_net.fc = nn.Linear(scratch_net.fc.in_features, <span class="hljs-number">2</span>)<br>train_fine_tuning(scratch_net, <span class="hljs-number">5e-4</span>, param_group=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># loss 0.390, train acc 0.828, test acc 0.826</span><br><span class="hljs-comment"># 1610.3 examples/sec on [device(type=&#x27;cuda&#x27;, index=0), device(type=&#x27;cuda&#x27;, index=1)]</span><br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（16）物体检测和数据集</title>
    <url>/2022/11/08/DL_16/</url>
    <content><![CDATA[<p>物体检测识别图片里的多个物体的类别和位置，位置通常用边缘框表示</p>
<h2 id="边缘框实现"><a href="#边缘框实现" class="headerlink" title="边缘框实现"></a>边缘框实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>d2l.set_figsize()<br>img = d2l.plt.imread(<span class="hljs-string">&#x27;../img/catdog.jpg&#x27;</span>)<br>d2l.plt.imshow(img);<br><br><span class="hljs-comment"># box_corner_to_center从两角表示法转换为中心宽度表示法，</span><br><span class="hljs-comment"># 而box_center_to_corner反之亦然。 </span><br><span class="hljs-comment"># 输入参数boxes可以是长度为4的张量，</span><br><span class="hljs-comment"># 也可以是形状为（，4）的二维张量，其中是边界框的数量。</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">box_corner_to_center</span>(<span class="hljs-params">boxes</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;从（左上，右下）转换到（中间，宽度，高度）&quot;&quot;&quot;</span><br>    x1, y1, x2, y2 = boxes[:, <span class="hljs-number">0</span>], boxes[:, <span class="hljs-number">1</span>], boxes[:, <span class="hljs-number">2</span>], boxes[:, <span class="hljs-number">3</span>]<br>    cx = (x1 + x2) / <span class="hljs-number">2</span><br>    cy = (y1 + y2) / <span class="hljs-number">2</span><br>    w = x2 - x1<br>    h = y2 - y1<br>    boxes = torch.stack((cx, cy, w, h), axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> boxes<br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">box_center_to_corner</span>(<span class="hljs-params">boxes</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;从（中间，宽度，高度）转换到（左上，右下）&quot;&quot;&quot;</span><br>    cx, cy, w, h = boxes[:, <span class="hljs-number">0</span>], boxes[:, <span class="hljs-number">1</span>], boxes[:, <span class="hljs-number">2</span>], boxes[:, <span class="hljs-number">3</span>]<br>    x1 = cx - <span class="hljs-number">0.5</span> * w<br>    y1 = cy - <span class="hljs-number">0.5</span> * h<br>    x2 = cx + <span class="hljs-number">0.5</span> * w<br>    y2 = cy + <span class="hljs-number">0.5</span> * h<br>    boxes = torch.stack((x1, y1, x2, y2), axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> boxes<br><span class="hljs-comment"># bbox是边界框的英文缩写</span><br>dog_bbox, cat_bbox = [<span class="hljs-number">60.0</span>, <span class="hljs-number">45.0</span>, <span class="hljs-number">378.0</span>, <span class="hljs-number">516.0</span>], [<span class="hljs-number">400.0</span>, <span class="hljs-number">112.0</span>, <span class="hljs-number">655.0</span>, <span class="hljs-number">493.0</span>]<br><span class="hljs-comment"># 通过转换两次来验证边界框转换函数的正确性。</span><br>boxes = torch.tensor((dog_bbox, cat_bbox))<br>box_center_to_corner(box_corner_to_center(boxes)) == boxes<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># tensor([[True, True, True, True],</span><br><span class="hljs-comment">#         [True, True, True, True]])</span><br><span class="hljs-comment"># 画之前，我们定义一个辅助函数bbox_to_rect。 </span><br><span class="hljs-comment"># 它将边界框表示成matplotlib的边界框格式。</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">bbox_to_rect</span>(<span class="hljs-params">bbox, color</span>):<br>    <span class="hljs-comment"># 将边界框(左上x,左上y,右下x,右下y)格式转换成matplotlib格式：</span><br>    <span class="hljs-comment"># ((左上x,左上y),宽,高)</span><br>    <span class="hljs-keyword">return</span> d2l.plt.Rectangle(<br>        xy=(bbox[<span class="hljs-number">0</span>], bbox[<span class="hljs-number">1</span>]), width=bbox[<span class="hljs-number">2</span>]-bbox[<span class="hljs-number">0</span>], height=bbox[<span class="hljs-number">3</span>]-bbox[<span class="hljs-number">1</span>],<br>        fill=<span class="hljs-literal">False</span>, edgecolor=color, linewidth=<span class="hljs-number">2</span>)<br><br>fig = d2l.plt.imshow(img)<br>fig.axes.add_patch(bbox_to_rect(dog_bbox, <span class="hljs-string">&#x27;blue&#x27;</span>))<br>fig.axes.add_patch(bbox_to_rect(cat_bbox, <span class="hljs-string">&#x27;red&#x27;</span>));<br></code></pre></td></tr></table></figure>

<h2 id="目标检测数据集"><a href="#目标检测数据集" class="headerlink" title="目标检测数据集"></a>目标检测数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-comment">#@save</span><br>d2l.DATA_HUB[<span class="hljs-string">&#x27;banana-detection&#x27;</span>] = (<br>    d2l.DATA_URL + <span class="hljs-string">&#x27;banana-detection.zip&#x27;</span>,<br>    <span class="hljs-string">&#x27;5de26c8fce5ccdea9f91267273464dc968d20d72&#x27;</span>)<br><br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_data_bananas</span>(<span class="hljs-params">is_train=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;读取香蕉检测数据集中的图像和标签&quot;&quot;&quot;</span><br>    data_dir = d2l.download_extract(<span class="hljs-string">&#x27;banana-detection&#x27;</span>)<br>    csv_fname = os.path.join(data_dir, <span class="hljs-string">&#x27;bananas_train&#x27;</span> <span class="hljs-keyword">if</span> is_train<br>                             <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;bananas_val&#x27;</span>, <span class="hljs-string">&#x27;label.csv&#x27;</span>)<br>    csv_data = pd.read_csv(csv_fname)<br>    csv_data = csv_data.set_index(<span class="hljs-string">&#x27;img_name&#x27;</span>)<br>    images, targets = [], []<br>    <span class="hljs-keyword">for</span> img_name, target <span class="hljs-keyword">in</span> csv_data.iterrows():<br>        images.append(torchvision.io.read_image(<br>            os.path.join(data_dir, <span class="hljs-string">&#x27;bananas_train&#x27;</span> <span class="hljs-keyword">if</span> is_train <span class="hljs-keyword">else</span><br>                         <span class="hljs-string">&#x27;bananas_val&#x27;</span>, <span class="hljs-string">&#x27;images&#x27;</span>, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;img_name&#125;</span>&#x27;</span>)))<br>        <span class="hljs-comment"># 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），</span><br>        <span class="hljs-comment"># 其中所有图像都具有相同的香蕉类（索引为0）</span><br>        targets.append(<span class="hljs-built_in">list</span>(target))<br>    <span class="hljs-keyword">return</span> images, torch.tensor(targets).unsqueeze(<span class="hljs-number">1</span>) / <span class="hljs-number">256</span><br><br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BananasDataset</span>(torch.utils.data.Dataset):<br>    <span class="hljs-string">&quot;&quot;&quot;一个用于加载香蕉检测数据集的自定义数据集&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, is_train</span>):<br>        self.features, self.labels = read_data_bananas(is_train)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;read &#x27;</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">len</span>(self.features)) + (<span class="hljs-string">f&#x27; training examples&#x27;</span> <span class="hljs-keyword">if</span><br>              is_train <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27; validation examples&#x27;</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> (self.features[idx].<span class="hljs-built_in">float</span>(), self.labels[idx])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.features)<br><span class="hljs-comment">#@save</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_bananas</span>(<span class="hljs-params">batch_size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;加载香蕉检测数据集&quot;&quot;&quot;</span><br>    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=<span class="hljs-literal">True</span>),<br>                                             batch_size, shuffle=<span class="hljs-literal">True</span>)<br>    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=<span class="hljs-literal">False</span>),<br>                                           batch_size)<br>    <span class="hljs-keyword">return</span> train_iter, val_iter<br><br>batch_size, edge_size = <span class="hljs-number">32</span>, <span class="hljs-number">256</span><br>train_iter, _ = load_data_bananas(batch_size)<br>batch = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(train_iter))<br>batch[<span class="hljs-number">0</span>].shape, batch[<span class="hljs-number">1</span>].shape<br><span class="hljs-comment"># output</span><br><span class="hljs-comment"># read 1000 training examples</span><br><span class="hljs-comment">#read 100 validation examples</span><br>(torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>]), torch.Size([<span class="hljs-number">32</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>]))<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（18）物体检测算法：R-CNN，SSD，YOLO</title>
    <url>/2022/11/08/DL_18/</url>
    <content><![CDATA[<p>快速讲解一下目标检测的常用算法。</p>
<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><ul>
<li>使用启发式搜索算法来选择锚框</li>
<li>使用预训练模型来对每个锚框抽取特征</li>
<li>训练一个SVM来对类别分类</li>
<li>训练一个线性回归模型来预测边缘框偏移</li>
</ul>
<h3 id="兴趣区域（RoI）池化层"><a href="#兴趣区域（RoI）池化层" class="headerlink" title="兴趣区域（RoI）池化层"></a>兴趣区域（RoI）池化层</h3><ul>
<li>给定一个锚框，均匀分割成n x m块，输出每块里的最大值</li>
<li>不管锚框多大，总是输出nm个值</li>
</ul>
<h3 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h3><ul>
<li>使用CNN对图片抽取特征</li>
<li>使用RoI池化层对每个锚框生成固定长度特征</li>
</ul>
<h3 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h3><ul>
<li>使用一个区域提议网络来替代启发式搜索来获得更好的锚框</li>
</ul>
<h3 id="Mask-RCNN"><a href="#Mask-RCNN" class="headerlink" title="Mask RCNN"></a>Mask RCNN</h3><ul>
<li>如果有像素级别的标号，使用FCN来利用这些信息</li>
</ul>
<h2 id="单次多框检测（SSD）"><a href="#单次多框检测（SSD）" class="headerlink" title="单次多框检测（SSD）"></a>单次多框检测（SSD）</h2><ul>
<li>一个基础网络来抽取特征，然后多个卷积层块来减半高宽</li>
<li>在每段都生成锚框。底部段来拟合小物体，顶部段来拟合大物体</li>
<li>对每个锚框预测类别和边缘框</li>
</ul>
<h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><ul>
<li>SSD中锚框大量重叠，因此浪费了很多计算</li>
<li>YOLO将图片均匀分成S x S个锚框</li>
<li>每个锚框预测B个边缘框</li>
<li>后续版本（V2，V3，V4。。。）持续更新</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（2）简单的数学知识</title>
    <url>/2022/09/24/DL_2/</url>
    <content><![CDATA[<p>本节主要讲解线性代数，按特定轴求和，矩阵计算和自动求导相关内容</p>
<h2 id="1-线性代数"><a href="#1-线性代数" class="headerlink" title="1. 线性代数"></a>1. 线性代数</h2><p>矩阵的特征值和特征向量。</p>
<p>矩阵的转置。</p>
<h2 id="2-矩阵计算"><a href="#2-矩阵计算" class="headerlink" title="2. 矩阵计算"></a>2. 矩阵计算</h2><h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 按某个轴进行累加求和</span><br>A.cumsum(axis=<span class="hljs-number">0</span>)<br><span class="hljs-comment"># output</span><br>tensor([[ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">4</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">8</span>, <span class="hljs-number">10</span>],<br>        [<span class="hljs-number">12</span>, <span class="hljs-number">15</span>, <span class="hljs-number">18</span>, <span class="hljs-number">21</span>]])<br><span class="hljs-comment"># 点积运算</span><br>torch.dot(x, y)<br><span class="hljs-comment"># 叉乘运算</span><br>torch.mv(x, y) <span class="hljs-comment"># matrix-vector 矩阵-向量乘法</span><br>torch.mm(A, B) <span class="hljs-comment"># matrix-matrix 矩阵-矩阵乘法</span><br><br><span class="hljs-comment"># L2范数是向量元素平方和的平方根</span><br>torch.norm(u)<br><span class="hljs-comment"># L1范数是向量元素的绝对值之和</span><br>torch.<span class="hljs-built_in">abs</span>(u).<span class="hljs-built_in">sum</span>()<br><span class="hljs-comment"># 佛罗贝尼乌斯范数（Frobenius norm）是矩阵元素的平方和的平方根</span><br>torch.norm(A)<br></code></pre></td></tr></table></figure></div>



<h3 id="按特定轴求和"><a href="#按特定轴求和" class="headerlink" title="按特定轴求和"></a>按特定轴求和</h3><p>举例比较好理解，例如，对于2x3x4的矩阵：</p>
<ul>
<li>若axis&#x3D;0，求sum后矩阵变为二维矩阵，大小为3x4</li>
<li>若axis&#x3D;1，求sum后矩阵变为二维矩阵，大小为2x4</li>
<li>若axis&#x3D;2，求sum后矩阵变为二维矩阵，大小为2x3</li>
<li>若axis&#x3D;[0, 1]，求sum后矩阵变为一维矩阵，长度为4</li>
<li>若axis&#x3D;[0, 2]，求sum后矩阵变为一维矩阵，长度为3</li>
<li>若axis&#x3D;[1, 2]，求sum后矩阵变为一维矩阵，长度为2</li>
<li>若axis&#x3D;[0, 1, 2]，求sum后矩阵变为一个数</li>
</ul>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">A = torch.arange(<span class="hljs-number">24</span>).reshape((<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>))<br>A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>).shape, A.<span class="hljs-built_in">sum</span>(axis=[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>]).shape<br><span class="hljs-comment"># output</span><br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>]), torch.Size([<span class="hljs-number">3</span>])<br></code></pre></td></tr></table></figure></div>

<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/DL_2/3.png?raw=true"
                     
                ></p>
<h3 id="计算总和或均值时保持轴数不变"><a href="#计算总和或均值时保持轴数不变" class="headerlink" title="计算总和或均值时保持轴数不变"></a>计算总和或均值时保持轴数不变</h3><p>保持求和后的矩阵与求和前的矩阵形状相同。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">sum_A = A.<span class="hljs-built_in">sum</span>(axis=<span class="hljs-number">1</span>, keepdims=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># output</span><br>tensor([[ <span class="hljs-number">6.</span>],<br>		[<span class="hljs-number">22.</span>],<br>		[<span class="hljs-number">38.</span>],<br>		[<span class="hljs-number">54.</span>],<br>		[<span class="hljs-number">70.</span>]])<br></code></pre></td></tr></table></figure></div>

<p>应用：使得我们可以通过广播将<code>A</code>除以<code>sum_A</code></p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">A / sum_A <span class="hljs-comment"># 广播机制要求维度相同</span><br></code></pre></td></tr></table></figure></div>

<h2 id="3-自动求导"><a href="#3-自动求导" class="headerlink" title="3. 自动求导"></a>3. 自动求导</h2><p><a class="link"   href="https://zhuanlan.zhihu.com/p/263777564" >矩阵求导的本质与分子布局、分母布局的本质（矩阵求导——本质篇） <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>基本向量求导运算：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/DL_2/1.png?raw=true"
                     
                ></p>
<p>矩阵求导运算后的形状：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/DL_2/2.png?raw=true"
                     
                ></p>
<p>计算图：</p>
<ul>
<li>将代码分解为操作子</li>
<li>将计算表示成一个无环图</li>
</ul>
<h3 id="自动求导实现"><a href="#自动求导实现" class="headerlink" title="自动求导实现"></a>自动求导实现</h3><p>假设我们想对函数 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.628ex" height="3.009ex" style="vertical-align: -0.671ex;" viewBox="0 -1006.6 4145.2 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> y = 2 \mathbf{x} ^{T} \mathbf{x} </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
<path stroke-width="1" id="E1-MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="775" y="0"></use>
 <use xlink:href="#E1-MJMAIN-32" x="1831" y="0"></use>
<g transform="translate(2332,0)">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-54" x="859" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAINB-78" x="3537" y="0"></use>
</g>
</svg> 关于列向量 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.411ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 607.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> \mathbf{x} </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
</g>
</svg> 求导。在我们计算 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 497.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> y </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
</g>
</svg> 关于 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.411ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 607.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> \mathbf{x} </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
</g>
</svg> 的梯度之前，我们需要一个地方来存储梯度。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>x = torch.arange(<span class="hljs-number">4.0</span>)<br>x.requires_grad_(<span class="hljs-literal">True</span>) <span class="hljs-comment">#告知需要存储梯度</span><br><span class="hljs-comment">#等价于 x = torch.arange(4.0, requires_grad=True)</span><br>y = <span class="hljs-number">2</span> * torch.dot(x, x)<br></code></pre></td></tr></table></figure></div>

<p>调用反向传播函数来自动计算 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.155ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 497.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> y </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
</g>
</svg> 关于 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.411ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 607.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> \mathbf{x} </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
</g>
</svg> 每个分量的梯度。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">y.backward()<br>x.grad<br><span class="hljs-comment"># output: tensor([ 0., 4., 8., 12.])</span><br>x.grad == <span class="hljs-number">4</span> * x<br><span class="hljs-comment"># output: tensor([True, True, True, True])</span><br></code></pre></td></tr></table></figure></div>

<p>现在让我们计算 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.411ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 607.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> \mathbf{x} </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAINB-78" d="M227 0Q212 3 121 3Q40 3 28 0H21V62H117L245 213L109 382H26V444H34Q49 441 143 441Q247 441 265 444H274V382H246L281 339Q315 297 316 297Q320 297 354 341L389 382H352V444H360Q375 441 466 441Q547 441 559 444H566V382H471L355 246L504 63L545 62H586V0H578Q563 3 469 3Q365 3 347 0H338V62H366Q366 63 326 112T285 163L198 63L217 62H235V0H227Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAINB-78" x="0" y="0"></use>
</g>
</svg> 的另一个函数。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 在默认情况下，PyTorch会积累梯度，我们需要qin&#x27;chu之前的值</span><br>x.grad.zero_()<br>y = x.<span class="hljs-built_in">sum</span>()<br>y.backward()<br>x.grad<br><span class="hljs-comment"># output: tensor([1., 1., 1., 1.])</span><br></code></pre></td></tr></table></figure></div>

<p>深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 对非标量调用‘backward’需要传入一个‘gradient’参数，该参数指定微分函数</span><br>x.grad.zero_()<br>y = x * x<br>y.<span class="hljs-built_in">sum</span>().backward()<br><span class="hljs-comment"># 等价于y.backward(torch.ones(len(x)))</span><br>x.grad<br><span class="hljs-comment"># output: tensor([0., 2., 4., 6.])</span><br></code></pre></td></tr></table></figure></div>

<p>将某些计算移动到记录的计算图之外。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">x.grad.zero_()<br>y = x * x<br>u = y.detach() <span class="hljs-comment"># 将y视作常数存储在u之中， y仍旧是x的函数，但u不是。</span><br>z = u * x<br><br>z.<span class="hljs-built_in">sum</span>().backward()<br>x.grad == u<br><span class="hljs-comment"># output: tensor([True, True, True, True])</span><br></code></pre></td></tr></table></figure></div>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（4）Softmax回归</title>
    <url>/2022/09/27/DL_4/</url>
    <content><![CDATA[<p>就像我们从零开始实现线性回归一样，我们认为softmax回归也是重要的基础，因此也应该知道实现softmax回归的细节。</p>
<h2 id="1-回归和分类"><a href="#1-回归和分类" class="headerlink" title="1. 回归和分类"></a>1. 回归和分类</h2><ul>
<li><p>回归估计一个练习值</p>
</li>
<li><p>分类预测一个离散类别</p>
</li>
</ul>
<p>Softmax回归是一个多类分类模型，使用Softmax操作子得到每个类的预测置信度，使用交叉熵来衡量预测和标号的区别。</p>
<p>实现Softmax由三个步骤组成：</p>
<ol>
<li>对每个项求幂（使用exp）</li>
<li>对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数</li>
<li>将每一行除以其规范化常数，确保结果的和为1</li>
</ol>
<p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.652ex" height="6.509ex" style="vertical-align: -2.671ex;" viewBox="0 -1652.5 13197.4 2802.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">softmax(X)_{ij} = \frac{exp(X_{ij})}{ {\textstyle \sum_{k}^{}}exp(X_{ik}) }</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="469" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="955" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="1505" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="1867" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="2745" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="3275" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="3847" y="0"></use>
 <use xlink:href="#E1-MJMATHI-58" x="4237" y="0"></use>
<g transform="translate(5089,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
<g transform="translate(389,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="345" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="6392" y="0"></use>
<g transform="translate(7171,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="5508" height="60" x="0" y="220"></rect>
<g transform="translate(861,814)">
 <use xlink:href="#E1-MJMATHI-65" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="466" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="1039" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1542" y="0"></use>
<g transform="translate(1932,0)">
 <use xlink:href="#E1-MJMATHI-58" x="0" y="0"></use>
<g transform="translate(828,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="345" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3396" y="0"></use>
</g>
<g transform="translate(60,-771)">
 <use xlink:href="#E1-MJSZ1-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6B" x="1494" y="-405"></use>
 <use xlink:href="#E1-MJMATHI-65" x="1525" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="1991" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="2564" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="3067" y="0"></use>
<g transform="translate(3457,0)">
 <use xlink:href="#E1-MJMATHI-58" x="0" y="0"></use>
<g transform="translate(828,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6B" x="345" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="4998" y="0"></use>
</g>
</g>
</g>
</g>
</svg></p>
<p>分母或规范化常数，有时也称为配分函数（其对数称为对数-配分函数）。</p>
<h2 id="2-常见损失函数"><a href="#2-常见损失函数" class="headerlink" title="2. 常见损失函数"></a>2. 常见损失函数</h2><h3 id="L2-Loss"><a href="#L2-Loss" class="headerlink" title="L2 Loss"></a>L2 Loss</h3><p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.828ex" height="3.176ex" style="vertical-align: -0.838ex;" viewBox="0 -1006.6 9398 1367.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">l(y,{y}') = 1/ 2 (y - {y}')^{2}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="298" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="688" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1185" y="0"></use>
<g transform="translate(1630,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2425" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3092" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="4148" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="4649" y="0"></use>
 <use xlink:href="#E1-MJMAIN-32" x="5149" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="5650" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="6039" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="6759" y="0"></use>
<g transform="translate(7760,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="583"></use>
</g>
<g transform="translate(8554,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
</g>
</svg></p>
<p>梯度变化：离原点越远，梯度值越大；离原点越近，梯度值越小。</p>
<h3 id="L1-Loss"><a href="#L1-Loss" class="headerlink" title="L1 Loss"></a>L1 Loss</h3><p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.77ex" height="3.009ex" style="vertical-align: -0.838ex;" viewBox="0 -934.9 7220.6 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">l(y,{y}') = |y - {y}'|</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="298" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="688" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1185" y="0"></use>
<g transform="translate(1630,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2425" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3092" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="4148" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="4427" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="5146" y="0"></use>
<g transform="translate(6147,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="6942" y="0"></use>
</g>
</svg></p>
<p>梯度变化：大于零，梯度为常数1；小于零，梯度为常数-1；等于零，存在梯度不平滑性，会使优化末期梯度变化不稳定。</p>
<h3 id="Huber’s-Robust-Loss"><a href="#Huber’s-Robust-Loss" class="headerlink" title="Huber’s Robust Loss"></a>Huber’s Robust Loss</h3><p style="text-align:center"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="40.901ex" height="6.176ex" style="vertical-align: -2.505ex;" viewBox="0 -1580.7 17610.1 2659.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">l(y,{y}') = \begin{cases} |y-{y}'|-1/2
  &amp; \text{ if |y-{y}'|&gt;1}  \\ 1/ 2 (y - {y}')^{2}
  &amp; \text{ otherwise } 
\end{cases}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path>
<path stroke-width="1" id="E1-MJMAIN-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path>
<path stroke-width="1" id="E1-MJMAIN-79" d="M69 -66Q91 -66 104 -80T118 -116Q118 -134 109 -145T91 -160Q84 -163 97 -166Q104 -168 111 -168Q131 -168 148 -159T175 -138T197 -106T213 -75T225 -43L242 0L170 183Q150 233 125 297Q101 358 96 368T80 381Q79 382 78 382Q66 385 34 385H19V431H26L46 430Q65 430 88 429T122 428Q129 428 142 428T171 429T200 430T224 430L233 431H241V385H232Q183 385 185 366L286 112Q286 113 332 227L376 341V350Q376 365 366 373T348 383T334 385H331V431H337H344Q351 431 361 431T382 430T405 429T422 429Q477 429 503 431H508V385H497Q441 380 422 345Q420 343 378 235T289 9T227 -131Q180 -204 113 -204Q69 -204 44 -177T19 -116Q19 -89 35 -78T69 -66Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2D" d="M11 179V252H277V179H11Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7D" d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z"></path>
<path stroke-width="1" id="E1-MJMAIN-27" d="M78 634Q78 659 95 676T138 694Q166 694 189 668T212 579Q212 525 190 476T146 403T118 379Q114 379 105 388T95 401Q95 404 107 417T133 448T161 500T176 572Q176 584 175 584T170 581T157 576T139 573Q114 573 96 590T78 634Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path>
<path stroke-width="1" id="E1-MJMAIN-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path>
<path stroke-width="1" id="E1-MJMAIN-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path>
<path stroke-width="1" id="E1-MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path>
<path stroke-width="1" id="E1-MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path>
<path stroke-width="1" id="E1-MJMAIN-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path>
<path stroke-width="1" id="E1-MJMAIN-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path>
<path stroke-width="1" id="E1-MJSZ3-7B" d="M618 -943L612 -949H582L568 -943Q472 -903 411 -841T332 -703Q327 -682 327 -653T325 -350Q324 -28 323 -18Q317 24 301 61T264 124T221 171T179 205T147 225T132 234Q130 238 130 250Q130 255 130 258T131 264T132 267T134 269T139 272T144 275Q207 308 256 367Q310 436 323 519Q324 529 325 851Q326 1124 326 1154T332 1205Q369 1358 566 1443L582 1450H612L618 1444V1429Q618 1413 616 1411L608 1406Q599 1402 585 1393T552 1372T515 1343T479 1305T449 1257T429 1200Q425 1180 425 1152T423 851Q422 579 422 549T416 498Q407 459 388 424T346 364T297 318T250 284T214 264T197 254L188 251L205 242Q290 200 345 138T416 3Q421 -18 421 -48T423 -349Q423 -397 423 -472Q424 -677 428 -694Q429 -697 429 -699Q434 -722 443 -743T465 -782T491 -816T519 -845T548 -868T574 -886T595 -899T610 -908L616 -910Q618 -912 618 -928V-943Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="298" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="688" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1185" y="0"></use>
<g transform="translate(1630,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2425" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3092" y="0"></use>
<g transform="translate(4148,0)">
 <use xlink:href="#E1-MJSZ3-7B"></use>
<g transform="translate(917,0)">
<g transform="translate(-11,0)">
<g transform="translate(0,618)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="278" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="998" y="0"></use>
<g transform="translate(1998,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="513"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="2793" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="3294" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="4294" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="4795" y="0"></use>
 <use xlink:href="#E1-MJMAIN-32" x="5295" y="0"></use>
</g>
<g transform="translate(0,-668)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-32" x="1001" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1501" y="0"></use>
 <use xlink:href="#E1-MJMATHI-79" x="1891" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="2610" y="0"></use>
<g transform="translate(3611,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="513"></use>
</g>
<g transform="translate(4405,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="513"></use>
</g>
</g>
</g>
<g transform="translate(6785,0)">
<g transform="translate(0,618)">
 <use xlink:href="#E1-MJMAIN-69" x="250" y="0"></use>
 <use xlink:href="#E1-MJMAIN-66" x="528" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="1085" y="0"></use>
 <use xlink:href="#E1-MJMAIN-79" x="1363" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2D" x="1892" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7B" x="2225" y="0"></use>
 <use xlink:href="#E1-MJMAIN-79" x="2726" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7D" x="3254" y="0"></use>
 <use xlink:href="#E1-MJMAIN-27" x="3755" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="4033" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3E" x="4312" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="5090" y="0"></use>
</g>
<g transform="translate(0,-668)">
 <use xlink:href="#E1-MJMAIN-6F" x="250" y="0"></use>
 <use xlink:href="#E1-MJMAIN-74" x="750" y="0"></use>
 <use xlink:href="#E1-MJMAIN-68" x="1140" y="0"></use>
 <use xlink:href="#E1-MJMAIN-65" x="1696" y="0"></use>
 <use xlink:href="#E1-MJMAIN-72" x="2141" y="0"></use>
 <use xlink:href="#E1-MJMAIN-77" x="2533" y="0"></use>
 <use xlink:href="#E1-MJMAIN-69" x="3256" y="0"></use>
 <use xlink:href="#E1-MJMAIN-73" x="3534" y="0"></use>
 <use xlink:href="#E1-MJMAIN-65" x="3929" y="0"></use>
</g>
</g>
</g>
</g>
</g>
</svg></p>
<p>梯度变化：在（-1， 1）梯度变化符合L2 Loss的梯度变化；在其他区间符合L1 Loss的梯度变化。</p>
<h2 id="3-Softmax实现"><a href="#3-Softmax实现" class="headerlink" title="3. Softmax实现"></a>3. Softmax实现</h2><p>首先我们先了解一下如何读取多类分类数据集。</p>
<h3 id="图像分类数据集"><a href="#图像分类数据集" class="headerlink" title="图像分类数据集"></a>图像分类数据集</h3><p>MNIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。我们将使用类似但更复杂的Fashion-MNIST数据集。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision <span class="hljs-comment"># 计算机视觉模型库</span><br><span class="hljs-keyword">from</span> torch.utils <span class="hljs-keyword">import</span> data<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br>d2l.use_svg_display() <span class="hljs-comment"># 使用svg显示图片</span><br><br><span class="hljs-comment"># 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式</span><br><span class="hljs-comment"># 并除以255使得所有像素的数值均在0到1之间</span><br>trans = transform.ToTensor()<br>mnist_train = torchvision.datasets.FasionMNIST(<br>	root=<span class="hljs-string">&quot;../data&quot;</span>, train=<span class="hljs-literal">True</span>, transform=trans, dawnload=<span class="hljs-literal">True</span>)<br>mnist_test = torchvision.datasets.FashionMNIST(<br>	root=<span class="hljs-string">&quot;../data&quot;</span>, train=<span class="hljs-literal">False</span>, transform=trans, dawnload=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">len</span>(mnist_train), <span class="hljs-built_in">len</span>(mnist_test)<br></code></pre></td></tr></table></figure>

<p>两个可视化数据集的函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_fashion_mnist_labels</span>(<span class="hljs-params">labels</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签&quot;&quot;&quot;</span><br>    text_labels = [<span class="hljs-string">&#x27;t-shirt&#x27;</span>, <span class="hljs-string">&#x27;trouser&#x27;</span>, <span class="hljs-string">&#x27;pullover&#x27;</span>, <span class="hljs-string">&#x27;dress&#x27;</span>, <span class="hljs-string">&#x27;coat&#x27;</span>, <span class="hljs-string">&#x27;sandal&#x27;</span>, <span class="hljs-string">&#x27;shirt&#x27;</span>, <span class="hljs-string">&#x27;sneaker&#x27;</span>, <span class="hljs-string">&#x27;bag&#x27;</span>, <span class="hljs-string">&#x27;ankle boot&#x27;</span>]<br>    <span class="hljs-keyword">return</span> [text_labels[<span class="hljs-built_in">int</span>(i)] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">show_images</span>(<span class="hljs-params">imgs, num_rows, num_cols, titles=<span class="hljs-literal">None</span>, scale=<span class="hljs-number">1.5</span></span>): <br>    <span class="hljs-string">&quot;&quot;&quot;绘制图像列表&quot;&quot;&quot;</span><br>    figsize = (num_cols * scale, num_rows * scale)<br>    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)<br>    axes = axes.flatten()<br>    <span class="hljs-keyword">for</span> i, (ax, img) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(axes, imgs)):<br>        <span class="hljs-keyword">if</span> torch.is_tensor(img):<br>            <span class="hljs-comment"># 图片张量</span><br>            ax.imshow(img.numpy())<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># PIL图片</span><br>            ax.imshow(img)<br>        ax.axes.get_xaxis().set_visible(<span class="hljs-literal">False</span>)<br>        ax.axes.get_yaxis().set_visible(<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">if</span> titles:<br>            ax.set_title(titles[i])<br>    <span class="hljs-keyword">return</span> axes<br></code></pre></td></tr></table></figure>

<p>以下是训练数据集中前几个样本的图像及相应的标签</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">X, y = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(data.DataLoader(mnist_train, batch_size=<span class="hljs-number">18</span>)))<br>show_images(X.reshape(<span class="hljs-number">18</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>), <span class="hljs-number">2</span>, <span class="hljs-number">9</span>, 								titles=get_fashion_mnist_labels(y));<br></code></pre></td></tr></table></figure>

<p>读取一小批量数据，大小为batch_size</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">batch_size = <span class="hljs-number">256</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_dataloader_workers</span>():  <br>    <span class="hljs-string">&quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">4</span><br><br>train_iter = data.DataLoader(mnist_train, batch_size, shuffle=<span class="hljs-literal">True</span>,<br>                             num_workers=get_dataloader_workers())<br></code></pre></td></tr></table></figure>

<p>最后整合所有组件，定义一个函数，用于获取和读取Fashion-MNIST数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data_fashion_mnist</span>(<span class="hljs-params">batch_size, resize=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;</span><br>    trans = [transforms.ToTensor()]<br>    <span class="hljs-keyword">if</span> resize:<br>        trans.insert(<span class="hljs-number">0</span>, transforms.Resize(resize))<br>    trans = transforms.Compose(trans)<br>    mnist_train = torchvision.datasets.FashionMNIST(<br>        root=<span class="hljs-string">&quot;../data&quot;</span>, train=<span class="hljs-literal">True</span>, transform=trans, download=<span class="hljs-literal">True</span>)<br>    mnist_test = torchvision.datasets.FashionMNIST(<br>        root=<span class="hljs-string">&quot;../data&quot;</span>, train=<span class="hljs-literal">False</span>, transform=trans, download=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> (data.DataLoader(mnist_train, batch_size, shuffle=<span class="hljs-literal">True</span>,<br>                            num_workers=get_dataloader_workers()),<br>            data.DataLoader(mnist_test, batch_size, shuffle=<span class="hljs-literal">False</span>,<br>                            num_workers=get_dataloader_workers()))<br></code></pre></td></tr></table></figure>

<h3 id="从零开始实现Softmax"><a href="#从零开始实现Softmax" class="headerlink" title="从零开始实现Softmax"></a>从零开始实现Softmax</h3><p>就像从零开始线性回归一样，你应该知道Softmax的每一个细节。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> IPython <span class="hljs-keyword">import</span> display<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br></code></pre></td></tr></table></figure>

<p>展开每个图像，将他们视为长度为784的向量。因为我们的数据集有10个类别，所以网络输出维度为10。因此权重将构成一个784x10的矩阵，偏置构成一个1x10的行向量。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">num_inputs = <span class="hljs-number">784</span><br>num_outputs = <span class="hljs-number">10</span><br>w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(num_inputs, num_outputs), requires_grad=<span class="hljs-literal">True</span>)<span class="hljs-comment"># 用正态分布初始化我们的权重</span><br>b = torch.zeros(num_outputs, requires_grad=<span class="hljs-literal">True</span>)<span class="hljs-comment"># 偏置初始化为0</span><br><br><span class="hljs-comment"># 定义softmax操作</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">softmax</span>(<span class="hljs-params">X</span>):<br>    X_exp = torch.exp(X)<br>    partition = X_exp.<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> X_exp / partition <span class="hljs-comment"># 这里使用了广播机制</span><br><span class="hljs-comment"># 定义softmax模型</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">net</span>(<span class="hljs-params">X</span>):<br>    <span class="hljs-keyword">return</span> softmax(torch.matmul(X.reshape((-<span class="hljs-number">1</span>, W.shape[<span class="hljs-number">0</span>])), W) + b)<br><span class="hljs-comment"># 定义交叉熵损失函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-keyword">return</span> -torch.log(y_hat[<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(y_hat)), y])<br><span class="hljs-comment"># 将预测类别与真实y元素进行比较</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;计算预测正确的数量&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(y_hat.shape) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> y_hat.shape[<span class="hljs-number">1</span>] &gt; <span class="hljs-number">1</span>:<br>        y_hat = y_hat.argmax(axis=<span class="hljs-number">1</span>)<br>    cmp = y_hat.<span class="hljs-built_in">type</span>(y.dtype) == y<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(cmp.<span class="hljs-built_in">type</span>(y.dtype).<span class="hljs-built_in">sum</span>())<br><span class="hljs-comment"># 评估在任意模型net的精度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_accuracy</span>(<span class="hljs-params">net, data_iter</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;计算在指定数据集上模型的精度&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.<span class="hljs-built_in">eval</span>()<span class="hljs-comment"># 将模型设置为评估模式</span><br>    metric = Accumulator(<span class="hljs-number">2</span>)<span class="hljs-comment"># 正确预测数、总预测数</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>            metric.add(accuracy(net(X), y), y.munel())<br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">1</span>]<br><span class="hljs-comment"># Accumulator实例中创建了2个变量，分别用于存储正确预测的数量和预测的总数量</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Accumulator</span>:<br>    <span class="hljs-string">&#x27;&#x27;&#x27;在n个变量上累加&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, n</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * n<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, *args</span>):<br>        self.data = [a + <span class="hljs-built_in">float</span>(b) <span class="hljs-keyword">for</span> a, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.data, args)]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset</span>(<span class="hljs-params">self</span>):<br>        self.data = [<span class="hljs-number">0.0</span>] * <span class="hljs-built_in">len</span>(self.data)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>		<span class="hljs-keyword">return</span> self.data[idx]<br><br><span class="hljs-comment">#softmax回归的训练</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_epoch_ch3</span>(<span class="hljs-params">net, train_iter, loss, updater</span>):  <br>    <span class="hljs-string">&quot;&quot;&quot;训练模型一个迭代周期（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 将模型设置为训练模式</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(net, torch.nn.Module):<br>        net.train() <span class="hljs-comment"># 开启训练模式</span><br>    <span class="hljs-comment"># 训练损失总和、训练准确度总和、样本数</span><br>    metric = Accumulator(<span class="hljs-number">3</span>)<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>        <span class="hljs-comment"># 计算梯度并更新参数</span><br>        y_hat = net(X)<br>        l = loss(y_hat, y)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(updater, torch.optim.Optimizer):<br>            <span class="hljs-comment"># 使用PyTorch内置的优化器和损失函数</span><br>            updater.zero_grad()<br>            l.mean().backward()<br>            updater.step()<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-comment"># 使用定制的优化器和损失函数</span><br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            updater(X.shape[<span class="hljs-number">0</span>])<br>        metric.add(<span class="hljs-built_in">float</span>(l.<span class="hljs-built_in">sum</span>()), accuracy(y_hat, y), y.numel())<br>    <span class="hljs-comment"># 返回训练损失和训练精度</span><br>    <span class="hljs-keyword">return</span> metric[<span class="hljs-number">0</span>] / metric[<span class="hljs-number">2</span>], metric[<span class="hljs-number">1</span>] / metric[<span class="hljs-number">2</span>]<br><br><span class="hljs-comment"># 定义一个在动画中绘制数据的实用程序类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Animator</span>:  <br>    <span class="hljs-string">&quot;&quot;&quot;在动画中绘制数据&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, xlabel=<span class="hljs-literal">None</span>, ylabel=<span class="hljs-literal">None</span>, legend=<span class="hljs-literal">None</span>, xlim=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 ylim=<span class="hljs-literal">None</span>, xscale=<span class="hljs-string">&#x27;linear&#x27;</span>, yscale=<span class="hljs-string">&#x27;linear&#x27;</span>,</span><br><span class="hljs-params">                 fmts=(<span class="hljs-params"><span class="hljs-string">&#x27;-&#x27;</span>, <span class="hljs-string">&#x27;m--&#x27;</span>, <span class="hljs-string">&#x27;g-.&#x27;</span>, <span class="hljs-string">&#x27;r:&#x27;</span></span>), nrows=<span class="hljs-number">1</span>, ncols=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 figsize=(<span class="hljs-params"><span class="hljs-number">3.5</span>, <span class="hljs-number">2.5</span></span>)</span>):<br>        <span class="hljs-comment"># 增量地绘制多条线</span><br>        <span class="hljs-keyword">if</span> legend <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            legend = []<br>        d2l.use_svg_display()<br>        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)<br>        <span class="hljs-keyword">if</span> nrows * ncols == <span class="hljs-number">1</span>:<br>            self.axes = [self.axes, ]<br>        <span class="hljs-comment"># 使用lambda函数捕获参数</span><br>        self.config_axes = <span class="hljs-keyword">lambda</span>: d2l.set_axes(<br>            self.axes[<span class="hljs-number">0</span>], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)<br>        self.X, self.Y, self.fmts = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>, fmts<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-comment"># 向图表中添加多个数据点</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(y, <span class="hljs-string">&quot;__len__&quot;</span>):<br>            y = [y]<br>        n = <span class="hljs-built_in">len</span>(y)<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">hasattr</span>(x, <span class="hljs-string">&quot;__len__&quot;</span>):<br>            x = [x] * n<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.X:<br>            self.X = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.Y:<br>            self.Y = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">for</span> i, (a, b) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(x, y)):<br>            <span class="hljs-keyword">if</span> a <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> b <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                self.X[i].append(a)<br>                self.Y[i].append(b)<br>        self.axes[<span class="hljs-number">0</span>].cla()<br>        <span class="hljs-keyword">for</span> x, y, fmt <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.X, self.Y, self.fmts):<br>            self.axes[<span class="hljs-number">0</span>].plot(x, y, fmt)<br>        self.config_axes()<br>        display.display(self.fig)<br>        display.clear_output(wait=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 训练函数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_ch3</span>(<span class="hljs-params">net, train_iter, test_iter, loss, num_epochs, updater</span>): <br>    <span class="hljs-string">&quot;&quot;&quot;训练模型（定义见第3章）&quot;&quot;&quot;</span><br>    animator = Animator(xlabel=<span class="hljs-string">&#x27;epoch&#x27;</span>, xlim=[<span class="hljs-number">1</span>, num_epochs], ylim=[<span class="hljs-number">0.3</span>, <span class="hljs-number">0.9</span>],<br>                        legend=[<span class="hljs-string">&#x27;train loss&#x27;</span>, <span class="hljs-string">&#x27;train acc&#x27;</span>, <span class="hljs-string">&#x27;test acc&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)<br>        test_acc = evaluate_accuracy(net, test_iter)<br>        animator.add(epoch + <span class="hljs-number">1</span>, train_metrics + (test_acc,))<br>    train_loss, train_acc = train_metrics<br>    <span class="hljs-keyword">assert</span> train_loss &lt; <span class="hljs-number">0.5</span>, train_loss<br>    <span class="hljs-keyword">assert</span> train_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> train_acc &gt; <span class="hljs-number">0.7</span>, train_acc<br>    <span class="hljs-keyword">assert</span> test_acc &lt;= <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> test_acc &gt; <span class="hljs-number">0.7</span>, test_acc<br><span class="hljs-comment"># 小批量随机梯度下降优化模型的损失函数</span><br>lr = <span class="hljs-number">0.1</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">updater</span>(<span class="hljs-params">batch_size</span>):<br>    <span class="hljs-keyword">return</span> d2l.sgd([W, b], lr, batch_size)<br><span class="hljs-comment"># 训练模型10个迭代周期</span><br>num_epochs = <span class="hljs-number">10</span><br>train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)<br><span class="hljs-comment"># 对图像进行分类预测</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_ch3</span>(<span class="hljs-params">net, test_iter, n=<span class="hljs-number">6</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;预测标签（定义见第3章）&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> test_iter:<br>        <span class="hljs-keyword">break</span><br>    trues = d2l.get_fashion_mnist_labels(y)<br>    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=<span class="hljs-number">1</span>))<br>    titles = [true +<span class="hljs-string">&#x27;\n&#x27;</span> + pred <span class="hljs-keyword">for</span> true, pred <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(trues, preds)]<br>    d2l.show_images(<br>        X[<span class="hljs-number">0</span>:n].reshape((n, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>)), <span class="hljs-number">1</span>, n, titles=titles[<span class="hljs-number">0</span>:n])<br>predict_ch3(net, test_iter)<br></code></pre></td></tr></table></figure>

<h3 id="Softmax的简洁实现"><a href="#Softmax的简洁实现" class="headerlink" title="Softmax的简洁实现"></a>Softmax的简洁实现</h3><p>和上节相同，我们继续使用Fashion-MNIST数据集，并保持批量大小为256。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-comment"># 读取数据</span><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br><br><span class="hljs-comment"># 初始化模型参数</span><br><span class="hljs-comment"># softmax回归的输出层是一个全连接层</span><br><span class="hljs-comment"># PyTorch不会隐式地调整输入的形状。因此，我们在线性层前定义了展平层（flatten），来调整网络输入的形状</span><br>net = nn.Sequential(nn.Flatten(), nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">10</span>))<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br>net.apply(init_weights);<br><span class="hljs-comment"># 在交叉熵损失函数中传递未规范化的预测，并同时计算softmax及其对数</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><span class="hljs-comment"># 使用学习率为0.1的小批量随机梯度下降作为优化算法</span><br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.1</span>)<br><span class="hljs-comment"># 使用上一小节实现的train_ch3训练函数来训练模型</span><br>num_epochs = <span class="hljs-number">10</span><br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（3）简单的线性回归</title>
    <url>/2022/09/26/DL_3/</url>
    <content><![CDATA[<p>本节将学习一些线性回归基础知识和线性回归的简洁实现。</p>
<h2 id="1-线性回归"><a href="#1-线性回归" class="headerlink" title="1. 线性回归"></a>1. 线性回归</h2><p> 线性回归是最简单的模型，也是一个非常重要的基础模型。可以视作一个单层的神经网络。唯一有最优解的模型。</p>
<h3 id="基础优化方法：梯度下降"><a href="#基础优化方法：梯度下降" class="headerlink" title="基础优化方法：梯度下降"></a>基础优化方法：梯度下降</h3><p>梯度下降的学习率既不能太小，也不能太大。</p>
<p>一般不会直接采用梯度下降，而是采用<strong>小批量随机梯度下降</strong> 。当数据量过大时，我们可以随机采样b个样本（b是批量大小），用他们损失的<strong>平均值</strong>来近似损失。同样批量大小b不能太小也不能太大。<strong>小批量随机梯度下降是深度学习默认的求解算法。</strong></p>
<h2 id="2-线性回归从零开始实现"><a href="#2-线性回归从零开始实现" class="headerlink" title="2. 线性回归从零开始实现"></a>2. 线性回归从零开始实现</h2><p>我们将从零开始实现整个方法，包括数据流水线、模型、损失函数和小批量随机梯度下降优化器。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">synthetic_data</span>(<span class="hljs-params">w, b, num_examples</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;生成 y = Xw + b + 噪声&quot;&quot;&quot;</span><br>    X = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, (num_examples, <span class="hljs-built_in">len</span>(w)))<br>    <span class="hljs-comment">#生成X，均值为0，标准差为1的随机数。大小为num_examples x len(w)的矩阵。</span><br>    y = torch.matmul(X, w) + b<br>    y += torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, y.shape)<br>    <span class="hljs-comment">#给y加上噪音，噪音均值为0，标准差为0.01，与y形状相同。</span><br>    <span class="hljs-keyword">return</span> X, y.reshape((-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<span class="hljs-comment">#将y整理为一列的向量（虽然此处并不必要）</span><br><br>true_w = torch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br><span class="hljs-comment"># 生成训练样本features, labels</span><br>features, labels = synthetic_data(true_w, ture_b, <span class="hljs-number">1000</span>)<br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">deta_iter</span>(<span class="hljs-params">batch_size, features, labels</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;该函数接收批量大小等输入，生成大小为batch_size的小批量&#x27;&#x27;&#x27;</span><br>    num_examples = <span class="hljs-built_in">len</span>(features)<br>    indices = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(num_examples))<br>    <span class="hljs-comment"># 这些样本是随机读取的，没有特定的顺序</span><br>    random.shuffle(indices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, num_examples, batch_size):<br>        batch_indices = torch.tensor(indices[i:<span class="hljs-built_in">min</span>(i + batch_size, num_examples)])<br>        <span class="hljs-keyword">yield</span> features[batch_indices], labels[batch_indices]<br><br>batch_size = <span class="hljs-number">10</span><br>w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>, size=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)<br>b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">linreg</span>(<span class="hljs-params">X, w, b</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;线性回归模型&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">return</span> torch.matmul(X, w) + b<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">squared_loss</span>(<span class="hljs-params">y_hat, y</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;均方损失&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">return</span> (y_hat - y.reshape(y_hat.shape)) ** <span class="hljs-number">2</span> / <span class="hljs-number">2</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sgd</span>(<span class="hljs-params">params, lr, batch_size</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;小批量随机梯度下降&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># torch.no_grad()用于停止autograd模块的工作</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> params:<br>            param -= lr * param.grad / batch_size<br>            param.grad.zero_()<br></code></pre></td></tr></table></figure>

<p>训练过程</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">lr = <span class="hljs-number">0.03</span><br>num_epochs = <span class="hljs-number">3</span> <span class="hljs-comment">#整个数据扫3遍</span><br>net = linreg<br>loss = squared_loss<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter(batch_size, features, labels):<br>        l = loss(net(X, w, b), y)<br>        <span class="hljs-comment"># 因为l形状是（batch_size, 1）, 而不是一个标量。l中的所有元素被加到一起，</span><br>        <span class="hljs-comment"># 并以此计算[w, b]的梯度</span><br>        l.<span class="hljs-built_in">sum</span>().backward()<br>        sgd([w, b], lr, batch_size) <span class="hljs-comment"># 使用参数的梯度更新参数</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        train_l = loss(net(features, w, b), labels)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, loss <span class="hljs-subst">&#123;<span class="hljs-built_in">float</span>(train_l.mean()):f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>比较真实参数和通过训练学到的参数来评估训练的成功程度</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;w的估计误差: <span class="hljs-subst">&#123;true_w - w.reshape(true_w.shape)&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;b的估计误差: <span class="hljs-subst">&#123;true_b - b&#125;</span>&#x27;</span>)<br><span class="hljs-comment"># output:</span><br>w的估计误差: tensor([<span class="hljs-number">0.0004</span>, -<span class="hljs-number">0.0003</span>])<br>b的估计误差: tensor([<span class="hljs-number">0.0008</span>])<br></code></pre></td></tr></table></figure>

<h2 id="3-线性回归的简洁实现"><a href="#3-线性回归的简洁实现" class="headerlink" title="3. 线性回归的简洁实现"></a>3. 线性回归的简洁实现</h2><p>我们将介绍如何通过使用深度学习框架来简洁地实现上小节中的线性回归模型。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 生成数据集</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> troch<br><span class="hljs-keyword">from</span> troch.utils <span class="hljs-keyword">import</span> data<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>true_w = troch.tensor([<span class="hljs-number">2</span>, -<span class="hljs-number">3.4</span>])<br>true_b = <span class="hljs-number">4.2</span><br><span class="hljs-comment"># 人工数据生成函数生成features和labels</span><br>features, labels = d2l.synthetic_data(true_w, true_b, <span class="hljs-number">1000</span>)<br><br><span class="hljs-comment"># 调用框架现有的API来读取数据</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_array</span>(<span class="hljs-params">data_arrays, batch_size, is_train=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;构造一个PyTorch数据迭代器&#x27;&#x27;&#x27;</span><br>    dataset = data.TensorDataset(*data_arrays)<br>    <span class="hljs-keyword">return</span> data.DataLoader(dataset, batch_size, shuffle=is_train)<br><br>batch_size = <span class="hljs-number">10</span><br>data_iter = load_array((features, labels), batch_size)<br><span class="hljs-comment"># iter()生成迭代器函数，next()返回迭代器的下一个项目</span><br><span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(data_iter))<br><br><span class="hljs-comment"># 使用框架的预定义好的层</span><br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br>net = nn.Sequential(nn.Linear(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))<span class="hljs-comment">#输入维度2，输出维度1</span><br><span class="hljs-comment"># 初始化模型参数</span><br>net[<span class="hljs-number">0</span>].weight.data.normal_(<span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)<br>net[<span class="hljs-number">0</span>].bias.data.fill_(<span class="hljs-number">0</span>)<br><span class="hljs-comment"># 均方误差</span><br>loss = nn.MSELoss()<br><span class="hljs-comment"># 实例化SGD实例，net.parameters():拿出所有参数，lr:指定学习率0.03</span><br>trainer = torch.optim.SGD(net.parameters(), lr=<span class="hljs-number">0.03</span>)<br><br><span class="hljs-comment">#训练</span><br>num_epochs = <span class="hljs-number">3</span><br><span class="hljs-keyword">for</span> epochs <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> data_iter:<br>        l = loss(net(X), y)<br>        trainer.zero_grad()<br>        l.backward()<br>        trainer.step()<br>    l = loss(net(features), labels)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;epochs <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span>, loss <span class="hljs-subst">&#123;<span class="hljs-number">1</span>:&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（6）模型选择与欠拟合和过拟合</title>
    <url>/2022/10/28/DL_6/</url>
    <content><![CDATA[<p>我们如何才能确定模型是真正发现了一种泛化的模式， 而不是简单地记住了数据呢？ 我们的目标是发现某些模式， 这些模式捕捉到了我们训练集潜在总体的规律。 如果成功做到了这点，即使是对以前从未遇到过的个体， 模型也可以成功地评估风险。 如何发现可以泛化的模式是机器学习的根本问题。</p>
<p>误差：</p>
<ul>
<li>训练误差（training error）：模型在训练数据集上计算得到的误差</li>
<li>泛化误差（generalization error）：模型应用在同样从原始样本的分布中抽取的无限多数据样本时模型误差的期望。简单来说，是模型在新数据上的误差。</li>
</ul>
<p>数据集：（<em><strong>验证数据集一定不要和测试数据集混合在一起！</strong></em>）</p>
<ul>
<li>验证数据集：一个用来评估模型好坏的数据集</li>
<li>测试数据集：只用一次的数据集</li>
</ul>
<p>通常没有足够数据进行使用，所以常采用<strong>K折交叉验证</strong>，一般取5或10</p>
<h2 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h2><table>
<thead>
<tr>
<th></th>
<th>数据简单</th>
<th>数据复杂</th>
</tr>
</thead>
<tbody><tr>
<td>模型容量低</td>
<td>正常</td>
<td>欠拟合</td>
</tr>
<tr>
<td>模型容量高</td>
<td>过拟合</td>
<td>正常</td>
</tr>
</tbody></table>
<p>模型容量：拟合各种函数的能力</p>
<ul>
<li>低容量的模型难以拟合训练数据</li>
<li>高容量的模型可以记住所有的训练数据</li>
</ul>
<p>实际中一般靠观察训练误差和验证误差的差值，过小，欠拟合，过大，过拟合。</p>
<h2 id="一些正则化模型的技术"><a href="#一些正则化模型的技术" class="headerlink" title="一些正则化模型的技术"></a>一些正则化模型的技术</h2><h3 id="权重衰退（weight-decay）"><a href="#权重衰退（weight-decay）" class="headerlink" title="权重衰退（weight-decay）"></a>权重衰退（weight-decay）</h3><p>通过限制参数值的选择范围来控制模型容量，达到避免过拟合的效果<br>MATHJAX-SSR-23</p>
<ul>
<li>通常不限制偏移b</li>
<li>小的 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.09ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 469.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\theta</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
</g>
</svg> 意味着更强的正则项</li>
</ul>
<p>可以使用均方范数作为柔性限制。对于每个 MATHJAX-SSR-24，都可以找到 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.355ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 583.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\lambda</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3BB" x="0" y="0"></use>
</g>
</svg> 使得上面的目标函数等价于下面的公式<br>MATHJAX-SSR-25<br>超参数 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.355ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 583.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\lambda</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3BB" x="0" y="0"></use>
</g>
</svg> 控制了正则项的重要程度</p>
<ul>
<li><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.355ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 583.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\lambda</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3BB" x="0" y="0"></use>
</g>
</svg>  &#x3D; 0 ：无作用</li>
<li><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.355ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 583.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\lambda</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3BB" d="M166 673Q166 685 183 694H202Q292 691 316 644Q322 629 373 486T474 207T524 67Q531 47 537 34T546 15T551 6T555 2T556 -2T550 -11H482Q457 3 450 18T399 152L354 277L340 262Q327 246 293 207T236 141Q211 112 174 69Q123 9 111 -1T83 -12Q47 -12 47 20Q47 37 61 52T199 187Q229 216 266 252T321 306L338 322Q338 323 288 462T234 612Q214 657 183 657Q166 657 166 673Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3BB" x="0" y="0"></use>
</g>
</svg>  -&gt;  <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.324ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 1000.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\infty</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-221E" x="0" y="0"></use>
</g>
</svg> ， 最优解 -&gt; 0</li>
</ul>
<h4 id="从零实现"><a href="#从零实现" class="headerlink" title="从零实现"></a>从零实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-comment"># 生成数据</span><br>n_train, n_test, num_inputs, batch_size = <span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">200</span>, <span class="hljs-number">5</span><br>true_w, true_b = torch.ones((num_inputs, <span class="hljs-number">1</span>)) * <span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span><br>train_data = d2l.synthetic_data(true_w, true_b, n_train)<br>train_iter = d2l.load_array(train_data, batch_size)<br>test_data = d2l.synthetic_data(true_w, true_b, n_test)<br>test_iter = d2l.load_array(test_data, batch_size, is_train=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># 随机初始化模型参数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_params</span>():<br>    w = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, size=(num_inputs, <span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)<br>    b = torch.zeros(<span class="hljs-number">1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> [w, b]<br><span class="hljs-comment"># 定义L2范数惩罚</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">l2_penalty</span>(<span class="hljs-params">w</span>):<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">sum</span>(w.<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>)) / <span class="hljs-number">2</span><br><span class="hljs-comment"># 定义训练代码实现</span><br><span class="hljs-comment"># 线性网络和平方损失没有变化， 所以我们通过d2l.linreg和d2l.squared_loss导入它们</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">lambd</span>):<br>    w, b = init_params()<br>    net, loss = <span class="hljs-keyword">lambda</span> X: d2l.linreg(X, w, b), d2l.squared_loss<br>    num_epochs, lr = <span class="hljs-number">100</span>, <span class="hljs-number">0.003</span><br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epochs&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>,<br>                            xlim=[<span class="hljs-number">5</span>, num_epochs], legend=[<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            <span class="hljs-comment"># 增加了L2范数惩罚项，</span><br>            <span class="hljs-comment"># 广播机制使l2_penalty(w)成为一个长度为batch_size的向量</span><br>            l = loss(net(X), y) + lambd * l2_penalty(w)<br>            l.<span class="hljs-built_in">sum</span>().backward()<br>            d2l.sgd([w, b], lr, batch_size)<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">5</span> == <span class="hljs-number">0</span>:<br>            animator.add(epoch + <span class="hljs-number">1</span>, (d2l.evaluate_loss(net, train_iter, loss),<br>                                     d2l.evaluate_loss(net, test_iter, loss)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w的L2范数是：&#x27;</span>, torch.norm(w).item())<br><span class="hljs-comment"># 忽略正则化直接训练</span><br>train(<span class="hljs-keyword">lambda</span>=<span class="hljs-number">0</span>)<br><span class="hljs-comment"># 使用权重衰减</span><br>train(<span class="hljs-keyword">lambda</span>=<span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure>

<h4 id="简洁实现"><a href="#简洁实现" class="headerlink" title="简洁实现"></a>简洁实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_concise</span>(<span class="hljs-params">wd</span>):<br>    net = nn.Sequential(nn.Linear(num_inputs, <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> net.parameters():<br>        param.data.normal_()<br>    loss = nn.MSELoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>    num_epochs, lr = <span class="hljs-number">100</span>, <span class="hljs-number">0.003</span><br>    <span class="hljs-comment"># 偏置参数没有衰减</span><br>    trainer = torch.optim.SGD([<br>        &#123;<span class="hljs-string">&quot;params&quot;</span>:net[<span class="hljs-number">0</span>].weight,<span class="hljs-string">&#x27;weight_decay&#x27;</span>: wd&#125;,<br>        &#123;<span class="hljs-string">&quot;params&quot;</span>:net[<span class="hljs-number">0</span>].bias&#125;], lr=lr)<br>    animator = d2l.Animator(xlabel=<span class="hljs-string">&#x27;epochs&#x27;</span>, ylabel=<span class="hljs-string">&#x27;loss&#x27;</span>, yscale=<span class="hljs-string">&#x27;log&#x27;</span>,<br>                            xlim=[<span class="hljs-number">5</span>, num_epochs], legend=[<span class="hljs-string">&#x27;train&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>])<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        <span class="hljs-keyword">for</span> X, y <span class="hljs-keyword">in</span> train_iter:<br>            trainer.zero_grad()<br>            l = loss(net(X), y)<br>            l.mean().backward()<br>            trainer.step()<br>        <span class="hljs-keyword">if</span> (epoch + <span class="hljs-number">1</span>) % <span class="hljs-number">5</span> == <span class="hljs-number">0</span>:<br>            animator.add(epoch + <span class="hljs-number">1</span>,<br>                         (d2l.evaluate_loss(net, train_iter, loss),<br>                          d2l.evaluate_loss(net, test_iter, loss)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;w的L2范数：&#x27;</span>, net[<span class="hljs-number">0</span>].weight.norm().item())<br></code></pre></td></tr></table></figure>

<h3 id="丢弃法（dropout）"><a href="#丢弃法（dropout）" class="headerlink" title="丢弃法（dropout）"></a>丢弃法（dropout）</h3><p>丢弃法将一些输出项随机置0来控制模型复杂度，只用在训练过程中，预测过程会被去掉。</p>
<p>在数据中加入噪音，等价于一个正则。丢弃法是在全连接层间（后）加入噪音。通常将丢弃法作用在隐藏全连接层的输出上，即下一层的输入是上一层输出的进行dropout后的数据。<br>MATHJAX-SSR-26<br>根据此模型的设计，其期望值保持不变，即 <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.47ex" height="3.009ex" style="vertical-align: -0.838ex;" viewBox="0 -934.9 4077.4 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">𝐸[ℎ^′]=ℎ</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-45" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-45" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5B" x="738" y="0"></use>
<g transform="translate(1017,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="815" y="596"></use>
</g>
 <use xlink:href="#E1-MJMAIN-5D" x="1888" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2444" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="3500" y="0"></use>
</g>
</svg>。</p>
<h4 id="从零开始实现"><a href="#从零开始实现" class="headerlink" title="从零开始实现"></a>从零开始实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dropout_layer</span>(<span class="hljs-params">X, dropout</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;该函数以dropout的概率丢弃张量输入X中的元素&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= dropout &lt;= <span class="hljs-number">1</span><br>    <span class="hljs-comment"># 在本情况中，所有元素都被丢弃</span><br>    <span class="hljs-keyword">if</span> dropout == <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> torch.zeros_like(X)<br>    <span class="hljs-comment"># 在本情况中，所有元素都被保留</span><br>    <span class="hljs-keyword">if</span> dropout == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> X<br>    mask = (torch.rand(X.shape) &gt; dropout).<span class="hljs-built_in">float</span>()<br>    <span class="hljs-keyword">return</span> mask * X / (<span class="hljs-number">1.0</span> - dropout)<br><span class="hljs-comment"># 定义模型参数</span><br><span class="hljs-string">&#x27;&#x27;&#x27;定义具有两个隐藏层的多层感知机，每个隐藏层包含256个单元&#x27;&#x27;&#x27;</span><br>num_inputs, num_outputs, num_hiddens1, num_hiddens2 = <span class="hljs-number">784</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span><br><span class="hljs-comment"># 定义模型</span><br>dropout1, dropout2 = <span class="hljs-number">0.2</span>, <span class="hljs-number">0.5</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_inputs, num_outputs, num_hiddens1, num_hiddens2,</span><br><span class="hljs-params">                 is_training = <span class="hljs-literal">True</span></span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.num_inputs = num_inputs<br>        self.training = is_training<br>        self.lin1 = nn.Linear(num_inputs, num_hiddens1)<br>        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)<br>        self.lin3 = nn.Linear(num_hiddens2, num_outputs)<br>        self.relu = nn.ReLU()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        H1 = self.relu(self.lin1(X.reshape((-<span class="hljs-number">1</span>, self.num_inputs))))<br>        <span class="hljs-comment"># 只有在训练模型时才使用dropout</span><br>        <span class="hljs-keyword">if</span> self.training == <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 在第一个全连接层之后添加一个dropout层</span><br>            H1 = dropout_layer(H1, dropout1)<br>        H2 = self.relu(self.lin2(H1))<br>        <span class="hljs-keyword">if</span> self.training == <span class="hljs-literal">True</span>:<br>            <span class="hljs-comment"># 在第二个全连接层之后添加一个dropout层</span><br>            H2 = dropout_layer(H2, dropout2)<br>        out = self.lin3(H2)<br>        <span class="hljs-keyword">return</span> out<br><br><br>net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens2)<br><span class="hljs-comment"># 训练和测试</span><br>num_epochs, lr, batch_size = <span class="hljs-number">10</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">256</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>

<h4 id="简洁实现-1"><a href="#简洁实现-1" class="headerlink" title="简洁实现"></a>简洁实现</h4><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">net = nn.Sequential(nn.Flatten(),<br>        nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">256</span>),<br>        nn.ReLU(),<br>        <span class="hljs-comment"># 在第一个全连接层之后添加一个dropout层</span><br>        nn.Dropout(dropout1),<br>        nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>),<br>        nn.ReLU(),<br>        <span class="hljs-comment"># 在第二个全连接层之后添加一个dropout层</span><br>        nn.Dropout(dropout2),<br>        nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>))<br><span class="hljs-comment"># 权重</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights);<br><br><span class="hljs-comment"># 训练和测试</span><br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（5）感知机与多层感知机</title>
    <url>/2022/10/11/DL_5/</url>
    <content><![CDATA[<p>本文开始学习感知机以及多层感知机。</p>
<h2 id="多层感知机的从零开始实现"><a href="#多层感知机的从零开始实现" class="headerlink" title="多层感知机的从零开始实现"></a>多层感知机的从零开始实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>batch_size = <span class="hljs-number">256</span><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br><br><span class="hljs-string">&#x27;&#x27;&#x27;初始化模型参数&#x27;&#x27;&#x27;</span><br><span class="hljs-comment"># 每个图像由28*28=784个灰度像素值，所有图像共10个类别，</span><br><span class="hljs-comment"># 我们实现一个包含256个隐藏单元的单层多层感知机</span><br>num_inputs, num_outputs, num_hiddens = <span class="hljs-number">784</span>, <span class="hljs-number">10</span>, <span class="hljs-number">256</span><br><br>W1 = nn.Parameter(torch.randn(<br>    num_inputs, num_hiddens, requires_grad=<span class="hljs-literal">True</span>) * <span class="hljs-number">0.01</span>)<br>b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=<span class="hljs-literal">True</span>))<br>W2 = nn.Parameter(torch.randn(<br>    num_hiddens, num_outputs, requires_grad=<span class="hljs-literal">True</span>) * <span class="hljs-number">0.01</span>)<br>b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=<span class="hljs-literal">True</span>))<br><br>params = [W1, b1, W2, b2]<br><span class="hljs-string">&#x27;&#x27;&#x27;激活函数&#x27;&#x27;&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">relu</span>(<span class="hljs-params">X</span>):<br>    a = torch.zeros_like(X)<br>    <span class="hljs-keyword">return</span> torch.<span class="hljs-built_in">max</span>(X, a)<br><span class="hljs-string">&#x27;&#x27;&#x27;模型&#x27;&#x27;&#x27;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">net</span>(<span class="hljs-params">X</span>):<br>    X = X.reshape((-<span class="hljs-number">1</span>, num_inputs))<br>    H = relu(X@W1 + b1)  <span class="hljs-comment"># 这里“@”代表矩阵乘法</span><br>    <span class="hljs-keyword">return</span> (H@W2 + b2)<br><span class="hljs-string">&#x27;&#x27;&#x27;损失函数&#x27;&#x27;&#x27;</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br><span class="hljs-string">&#x27;&#x27;&#x27;训练&#x27;&#x27;&#x27;</span><br><span class="hljs-comment"># 多层感知机的训练过程与softmax回归的训练过程完全相同</span><br><span class="hljs-comment"># 可以直接调用d2l包的train_ch3函数（参见 :sec_softmax_scratch ）</span><br>num_epochs, lr = <span class="hljs-number">10</span>, <span class="hljs-number">0.1</span><br>updater = torch.optim.SGD(params, lr=lr)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)<br><span class="hljs-string">&#x27;&#x27;&#x27;在一些测试数据上应用这个模型&#x27;&#x27;&#x27;</span><br>d2l.predict_ch3(net, test_iter)<br></code></pre></td></tr></table></figure>

<h2 id="多层感知机简洁实现"><a href="#多层感知机简洁实现" class="headerlink" title="多层感知机简洁实现"></a>多层感知机简洁实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><span class="hljs-string">&#x27;&#x27;&#x27;唯一的区别是我们添加了2个全连接层&#x27;&#x27;&#x27;</span><br>net = nn.Sequential(nn.Flatten(),<br>                    nn.Linear(<span class="hljs-number">784</span>, <span class="hljs-number">256</span>),<br>                    nn.ReLU(),<br>                    nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>))<br><span class="hljs-string">&#x27;&#x27;&#x27;训练过程&#x27;&#x27;&#x27;</span><br><span class="hljs-comment"># 训练过程的实现与我们实现softmax回归时完全相同</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weights</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, std=<span class="hljs-number">0.01</span>)<br><br>net.apply(init_weights);<br><br>batch_size, lr, num_epochs = <span class="hljs-number">256</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">10</span><br>loss = nn.CrossEntropyLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)<br>trainer = torch.optim.SGD(net.parameters(), lr=lr)<br><br>train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)<br>d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（7）数值稳定性+模型初始化和激活函数</title>
    <url>/2022/10/29/DL_7/</url>
    <content><![CDATA[<p>本节中将讨论一些有用的启发式方法，来对模型选择合适的初始化参数，来避免梯度爆炸或者梯度消失。你会发现这些启发式方法在整个深度学习生涯中都很有用。</p>
<h2 id="梯度消失和梯度爆炸"><a href="#梯度消失和梯度爆炸" class="headerlink" title="梯度消失和梯度爆炸"></a>梯度消失和梯度爆炸</h2><p><strong>梯度消失</strong>（gradient vanishing）：参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。对底部层尤为严重：</p>
<ul>
<li>仅仅顶部层训练的较好</li>
<li>无法使神经网络更深</li>
</ul>
<p>通过下列代码的运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">%matplotlib inline<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> troch <span class="hljs-keyword">as</span> d2l<br>x = torch.arange(-<span class="hljs-number">8.0</span>, <span class="hljs-number">8.0</span>, <span class="hljs-number">0.1</span>, requires_grad=<span class="hljs-literal">True</span>)<br>y = torch.sigmoid(x)<br>y.backward(torch.ones_like(x))<br>d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad.numpy()],<br>        legend=[<span class="hljs-string">&#x27;sigmoid&#x27;</span>, <span class="hljs-string">&#x27;gradient&#x27;</span>], figsize=(<span class="hljs-number">4.5</span>, <span class="hljs-number">2.5</span>))<br></code></pre></td></tr></table></figure>

<p>当sigmoid函数的输入很大或者很小时，它的梯度都会消失。</p>
<p><strong>梯度爆炸</strong>（gradient exploding）：参数更新过大，破坏了模型的稳定收敛。</p>
<p>对学习率敏感：</p>
<ul>
<li>学习率过大-&gt;大参数值-&gt;更大的梯度</li>
<li>学习率过小-&gt;训练无进展</li>
</ul>
<p>为了更好地说明这一点，我们生成100个高斯随机矩阵，并将它们与某个初始矩阵相乘。 对于我们选择的尺度（方差<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.643ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 2860 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">σ^2=1</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="808" y="583"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1303" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="2359" y="0"></use>
</g>
</svg>），矩阵乘积发生爆炸。 当这种情况是由于深度网络的初始化所导致时，我们没有机会让梯度下降优化器收敛。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">M = torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, size=(<span class="hljs-number">4</span>,<span class="hljs-number">4</span>))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;一个矩阵 \n&#x27;</span>,M)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    M = torch.mm(M,torch.normal(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, size=(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)))<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;乘以100个矩阵后\n&#x27;</span>, M)<br><span class="hljs-comment"># output</span><br>一个矩阵<br> tensor([[ <span class="hljs-number">0.4382</span>, -<span class="hljs-number">0.7687</span>,  <span class="hljs-number">0.2731</span>, -<span class="hljs-number">0.2587</span>],<br>        [-<span class="hljs-number">0.1789</span>, -<span class="hljs-number">0.2395</span>,  <span class="hljs-number">1.4915</span>,  <span class="hljs-number">0.2634</span>],<br>        [-<span class="hljs-number">0.5272</span>,  <span class="hljs-number">0.2403</span>,  <span class="hljs-number">2.4397</span>, -<span class="hljs-number">0.7587</span>],<br>        [ <span class="hljs-number">0.9805</span>,  <span class="hljs-number">0.4166</span>, -<span class="hljs-number">0.1906</span>, -<span class="hljs-number">0.2581</span>]])<br>乘以<span class="hljs-number">100</span>个矩阵后<br> tensor([[ <span class="hljs-number">7.6616e+22</span>,  <span class="hljs-number">4.2587e+22</span>, -<span class="hljs-number">5.8065e+22</span>,  <span class="hljs-number">1.2980e+23</span>],<br>        [-<span class="hljs-number">2.3790e+21</span>, -<span class="hljs-number">1.3224e+21</span>,  <span class="hljs-number">1.8030e+21</span>, -<span class="hljs-number">4.0304e+21</span>],<br>        [-<span class="hljs-number">1.3796e+23</span>, -<span class="hljs-number">7.6687e+22</span>,  <span class="hljs-number">1.0456e+23</span>, -<span class="hljs-number">2.3373e+23</span>],<br>        [ <span class="hljs-number">8.5987e+20</span>,  <span class="hljs-number">4.7795e+20</span>, -<span class="hljs-number">6.5167e+20</span>,  <span class="hljs-number">1.4567e+21</span>]])<br></code></pre></td></tr></table></figure>

<h2 id="让训练更加稳定"><a href="#让训练更加稳定" class="headerlink" title="让训练更加稳定"></a>让训练更加稳定</h2><p>目标：让梯度值在合理的范围内</p>
<ul>
<li>乘法变加法：ResNet，LSTM</li>
<li>归一化：梯度归一化，梯度裁剪</li>
<li>合理的权重初始和使用合理的激活函数</li>
</ul>
<h3 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h3><ul>
<li>在合理值区间里随机初始化参数</li>
<li>训练开始的时候更容易由数值不稳定：靠近最优点平滑，远离最优点表面可能很复杂</li>
<li>使用N（0， 0.01）来初始化可能对小网络没问题，但不能保证深度神经网络</li>
</ul>
<p><strong>Xavier初始化</strong><br>MATHJAX-SSR-34</p>
<ul>
<li>正态分布  <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.91ex" height="4.843ex" style="vertical-align: -1.838ex;" viewBox="0 -1293.7 9433.2 2085" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">N(0,\sqrt{2/(n_{t-1}+n_t)})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJSZ2-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-4E" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="888" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1278" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1778" y="0"></use>
<g transform="translate(2223,0)">
 <use xlink:href="#E1-MJSZ2-221A" x="0" y="-24"></use>
<rect stroke="none" width="5819" height="60" x="1000" y="1067"></rect>
<g transform="translate(1000,0)">
 <use xlink:href="#E1-MJMAIN-32" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1001" y="0"></use>
<g transform="translate(1390,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
<g transform="translate(600,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="3473" y="0"></use>
<g transform="translate(4473,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="849" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5430" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9043" y="0"></use>
</g>
</svg></li>
<li>均匀分布  <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.114ex" height="4.843ex" style="vertical-align: -1.838ex;" viewBox="0 -1293.7 16410.3 2085" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">U(-\sqrt{6/(n_{t-1}+n_t)}, \sqrt{6/(n_{t-1}+n_t)})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-55" d="M107 637Q73 637 71 641Q70 643 70 649Q70 673 81 682Q83 683 98 683Q139 681 234 681Q268 681 297 681T342 682T362 682Q378 682 378 672Q378 670 376 658Q371 641 366 638H364Q362 638 359 638T352 638T343 637T334 637Q295 636 284 634T266 623Q265 621 238 518T184 302T154 169Q152 155 152 140Q152 86 183 55T269 24Q336 24 403 69T501 205L552 406Q599 598 599 606Q599 633 535 637Q511 637 511 648Q511 650 513 660Q517 676 519 679T529 683Q532 683 561 682T645 680Q696 680 723 681T752 682Q767 682 767 672Q767 650 759 642Q756 637 737 637Q666 633 648 597Q646 592 598 404Q557 235 548 205Q515 105 433 42T263 -22Q171 -22 116 34T60 167V183Q60 201 115 421Q164 622 164 628Q164 635 107 637Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJSZ2-221A" d="M1001 1150Q1017 1150 1020 1132Q1020 1127 741 244L460 -643Q453 -650 436 -650H424Q423 -647 423 -645T421 -640T419 -631T415 -617T408 -594T399 -560T385 -512T367 -448T343 -364T312 -259L203 119L138 41L111 67L212 188L264 248L472 -474L983 1140Q988 1150 1001 1150Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-55" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="767" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1157" y="0"></use>
<g transform="translate(1935,0)">
 <use xlink:href="#E1-MJSZ2-221A" x="0" y="-24"></use>
<rect stroke="none" width="5819" height="60" x="1000" y="1067"></rect>
<g transform="translate(1000,0)">
 <use xlink:href="#E1-MJMAIN-36" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1001" y="0"></use>
<g transform="translate(1390,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
<g transform="translate(600,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="3473" y="0"></use>
<g transform="translate(4473,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="849" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5430" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="8755" y="0"></use>
<g transform="translate(9200,0)">
 <use xlink:href="#E1-MJSZ2-221A" x="0" y="-24"></use>
<rect stroke="none" width="5819" height="60" x="1000" y="1067"></rect>
<g transform="translate(1000,0)">
 <use xlink:href="#E1-MJMAIN-36" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2F" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1001" y="0"></use>
<g transform="translate(1390,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
<g transform="translate(600,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="3473" y="0"></use>
<g transform="translate(4473,0)">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="849" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5430" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="16020" y="0"></use>
</g>
</svg></li>
</ul>
<h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>激活函数在0点附近应当与y&#x3D;x函数近似。</p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（9）使用和购买GPU</title>
    <url>/2022/10/30/DL_9/</url>
    <content><![CDATA[<p>首先查看设备时候具有GPU，在控制台输入</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">nvidia-smi<br></code></pre></td></tr></table></figure>

<p>如果显示显卡信息说明具有GPU。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-comment"># 查询可用gpu数量</span><br><span class="hljs-built_in">print</span>(torch.cuda.device_count())<br><span class="hljs-comment"># 访问cpu，gpu，某个gpu</span><br><span class="hljs-built_in">print</span>(torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span>), torch.device(<span class="hljs-string">&#x27;cuda:1&#x27;</span>))<br><span class="hljs-comment"># 这两个函数允许我们在请求的GPU不存在的情况下运行代码</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">try_gpu</span>(<span class="hljs-params">i=<span class="hljs-number">0</span></span>):  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;如果存在，则返回gpu(i)，否则返回cpu()&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.device_count() &gt;= i + <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">return</span> torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">try_all_gpus</span>():  <span class="hljs-comment">#@save</span><br>    <span class="hljs-string">&quot;&quot;&quot;返回所有可用的GPU，如果没有GPU，则返回[cpu(),]&quot;&quot;&quot;</span><br>    devices = [torch.device(<span class="hljs-string">f&#x27;cuda:<span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>)<br>             <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(torch.cuda.device_count())]<br>    <span class="hljs-keyword">return</span> devices <span class="hljs-keyword">if</span> devices <span class="hljs-keyword">else</span> [torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)]<br><br><span class="hljs-built_in">print</span>(try_gpu(), try_gpu(<span class="hljs-number">10</span>), try_all_gpus())<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN学习</title>
    <url>/2022/10/24/GAN-learning/</url>
    <content><![CDATA[<p>由于需要阅读的论文中用到了GAN，所以对GAN进行简单的学习。</p>
<p>学习资源:</p>
<ol>
<li><a href="https://www.bilibili.com/video/BV1Up411R7Lk?share_source=copy_web&vd_source=786c69a54fb9d0c9e82c3e889537b801">李宏毅对抗生成网络(GAN)国语教程(2018)</a></li>
<li><a href="https://aistudio.baidu.com/aistudio/education/lessonvideo/1009704">百度AI Studio课程</a></li>
<li><a href="https://www.bilibili.com/video/BV1oi4y1m7np/?spm_id_from=333.337.search-card.all.click&vd_source=f1e7eb1d150afc7b732a2b8c557e6d35">生成对抗网络GAN开山之作论文精读</a></li>
</ol>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h2><p>GAN动物园：<a href="https://github.com/hindupuravinash/the-gan-zoo">https://github.com/hindupuravinash/the-gan-zoo</a> 存放了GAN的全部种类。</p>
<p>GAN交互式可视化：<a href="https://poloclub.github.io/ganlab/">https://poloclub.github.io/ganlab/</a> 可视化GAN工作过程。</p>
<p>OpenMMLab开源GAN算法库MMGeneration <a href="https://github.com/open-mmlab/mmgeneration">https://github.com/open-mmlab/mmgeneration</a></p>
<h2 id="2-GAN简洁实现"><a href="#2-GAN简洁实现" class="headerlink" title="2.GAN简洁实现"></a>2.GAN简洁实现</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#!/usr/bin/env python3</span><br><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-comment"># File              : test_gan.py</span><br><span class="hljs-comment"># Author            : none &lt;none&gt;</span><br><span class="hljs-comment"># Date              : 14.04.2022</span><br><span class="hljs-comment"># Last Modified Date: 15.04.2022</span><br><span class="hljs-comment"># Last Modified By  : none &lt;none&gt;</span><br><span class="hljs-string">&quot;&quot;&quot; 基于MNIST 实现对抗生成网络 (GAN) &quot;&quot;&quot;</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>image_size = [<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>]<br><span class="hljs-comment">#随机变量的初始维度可以是任意的，这里设置为96</span><br>latent_dim = <span class="hljs-number">96</span><br>batch_size = <span class="hljs-number">64</span><br>use_gpu = torch.cuda.is_available()<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Generator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Generator, self).__init__()<br>        self.model = nn.Sequential(<br>            nn.Linear(latent_dim, <span class="hljs-number">128</span>),<br>            torch.nn.BatchNorm1d(<span class="hljs-number">128</span>),<br>            torch.nn.GELU(),<br><br>            nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>),<br>            torch.nn.BatchNorm1d(<span class="hljs-number">256</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>),<br>            torch.nn.BatchNorm1d(<span class="hljs-number">512</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">1024</span>),<br>            torch.nn.BatchNorm1d(<span class="hljs-number">1024</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">1024</span>, np.prod(image_size, dtype=np.int32)),<br>            <span class="hljs-comment">#  nn.Tanh(),</span><br>            nn.Sigmoid(),<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, z</span>):<br>        <span class="hljs-comment"># shape of z: [batchsize, latent_dim]</span><br><br>        output = self.model(z)<br>        image = output.reshape(z.shape[<span class="hljs-number">0</span>], *image_size)<br><br>        <span class="hljs-keyword">return</span> image<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Discriminator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Discriminator, self).__init__()<br><br>        self.model = nn.Sequential(<br>            nn.Linear(np.prod(image_size, dtype=np.int32), <span class="hljs-number">512</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">256</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">64</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">32</span>),<br>            torch.nn.GELU(),<br>            nn.Linear(<span class="hljs-number">32</span>, <span class="hljs-number">1</span>),<br>            nn.Sigmoid(),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, image</span>):<br>        <span class="hljs-comment"># shape of image: [batchsize, 1, 28, 28]</span><br><br>        prob = self.model(image.reshape(image.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>))<br><br>        <span class="hljs-keyword">return</span> prob<br><br><span class="hljs-comment"># Training</span><br>dataset = torchvision.datasets.MNIST(<span class="hljs-string">&quot;mnist_data&quot;</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,<br>                                     transform=torchvision.transforms.Compose( <span class="hljs-comment">#</span><br>                                         [<br>                                             torchvision.transforms.Resize(<span class="hljs-number">28</span>),<br>                                             torchvision.transforms.ToTensor(),<br>                                             <span class="hljs-comment">#torchvision.transforms.Normalize([0.5], [0.5]),</span><br>                                         ]<br>                                                                             )<br>                                     )<br><span class="hljs-comment">#将样本构成mini_batch,用于后续训练</span><br>dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>, drop_last=<span class="hljs-literal">True</span>)<br><br>generator = Generator()<br>discriminator = Discriminator()<br><br><span class="hljs-comment">#分别对生成器判别器参数进行优化</span><br>g_optimizer = torch.optim.Adam(generator.parameters(), lr=<span class="hljs-number">0.0003</span>, betas=(<span class="hljs-number">0.4</span>, <span class="hljs-number">0.8</span>), weight_decay=<span class="hljs-number">0.0001</span>)<br>d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=<span class="hljs-number">0.0003</span>, betas=(<span class="hljs-number">0.4</span>, <span class="hljs-number">0.8</span>), weight_decay=<span class="hljs-number">0.0001</span>)<br><span class="hljs-comment">#使用BCE损失函数（二分类交叉熵损失）</span><br>loss_fn = nn.BCELoss()<br>labels_one = torch.ones(batch_size, <span class="hljs-number">1</span>)<br>labels_zero = torch.zeros(batch_size, <span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">if</span> use_gpu:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;use gpu for training&quot;</span>)<br>    generator = generator.cuda()<br>    discriminator = discriminator.cuda()<br>    loss_fn = loss_fn.cuda()<br>    labels_one = labels_one.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br>    labels_zero = labels_zero.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br>num_epoch = <span class="hljs-number">200</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epoch):<br>    <span class="hljs-keyword">for</span> i, mini_batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(dataloader):<br>        gt_images, _ = mini_batch<br><br><br>        z = torch.randn(batch_size, latent_dim)<br><br>        <span class="hljs-keyword">if</span> use_gpu:<br>            gt_images = gt_images.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br>            z = z.to(<span class="hljs-string">&quot;cuda&quot;</span>)<br><br>        pred_images = generator(z)<br>        g_optimizer.zero_grad()<br><br>        recons_loss = torch.<span class="hljs-built_in">abs</span>(pred_images-gt_images).mean()<br><br>        g_loss = recons_loss*<span class="hljs-number">0.05</span> + loss_fn(discriminator(pred_images), labels_one)<br><br>        g_loss.backward() <span class="hljs-comment"># 求后向传播梯度</span><br>        g_optimizer.step() <span class="hljs-comment"># 对生成器参数进行优化</span><br><br>        d_optimizer.zero_grad()<br><br>        real_loss = loss_fn(discriminator(gt_images), labels_one)<br>        fake_loss = loss_fn(discriminator(pred_images.detach()), labels_zero)<br>        d_loss = (real_loss + fake_loss)<br><br>        <span class="hljs-comment"># 观察real_loss与fake_loss，同时下降同时达到最小值，并且差不多大，说明D已经稳定了</span><br><br>        d_loss.backward()<br>        d_optimizer.step()<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;step:<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(dataloader)*epoch+i&#125;</span>, recons_loss:<span class="hljs-subst">&#123;recons_loss.item()&#125;</span>, g_loss:<span class="hljs-subst">&#123;g_loss.item()&#125;</span>, d_loss:<span class="hljs-subst">&#123;d_loss.item()&#125;</span>, real_loss:<span class="hljs-subst">&#123;real_loss.item()&#125;</span>, fake_loss:<span class="hljs-subst">&#123;fake_loss.item()&#125;</span>&quot;</span>)<br><br>        <span class="hljs-keyword">if</span> i % <span class="hljs-number">200</span> == <span class="hljs-number">0</span>:<br>            image = pred_images[:<span class="hljs-number">16</span>].data<br>            torchvision.utils.save_image(image, <span class="hljs-string">f&quot;image_<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(dataloader)*epoch+i&#125;</span>.png&quot;</span>, nrow=<span class="hljs-number">4</span>)<br><br><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>DeepLearning</tag>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习相关期刊</title>
    <url>/2022/09/22/DL_periodical_conference/</url>
    <content><![CDATA[<p>收集深度学习常见期刊的分类以及简写等内容。</p>
<h2 id="常见期刊"><a href="#常见期刊" class="headerlink" title="常见期刊"></a>常见期刊</h2><ul>
<li><p>ECCV（European Conference on Computer Vision）</p>
<p>  <strong>欧洲计算机视觉国际会议。</strong>ECCV每年的论文接受率为25-30%左右，每次会议在全球范围会收录论文300篇左右，收录论文的主要来源是来自于美国、欧洲等顶级实验室及研究所，中国大陆的收录论文数量在10-20篇之间。</p>
</li>
<li><p>CVPR（Conference on Computer Vision and Pattern Recognition）</p>
<p>  <strong>国际计算机视觉模式识别会议。</strong>这个会议是由IEEE主办的一年一度的全球学术性顶级会议，会议的主要内容是计算机视觉与模式识别技术，每年CVPR都会有一个固定的研讨主题。会议一般在每年六月举行，大部分情况下会议都在美国西部地区举办，也会在美国中部和东部地区之间循环举办。</p>
</li>
<li><p>ICCV （International Conference on Computer Vision）</p>
<p>  <strong>国际计算机视觉大会。</strong>这个会议也是由IEEE主办的全球最高级别学术会议，每两年在世界范围内召开一次，在业内具有极高的评价。ICCV论文录用率非常低，是三大会议中公认级别最高的。与CVPR不同的是，CVPR会议每年都在美国地区举办，而ICCV会议自1987年起至今每两年都会在全世界不同的国家举办会议，2005年ICCV是在中国北京举办的会议。</p>
<p>  <strong>上述会议为计算机视觉三大顶级会议</strong></p>
</li>
</ul>
<h3 id="计算机视觉顶级会议"><a href="#计算机视觉顶级会议" class="headerlink" title="计算机视觉顶级会议"></a>计算机视觉顶级会议</h3><h4 id="A类"><a href="#A类" class="headerlink" title="A类"></a>A类</h4><ul>
<li>CVPR: International Conference on Computer Vision and Pattern Recognition</li>
<li>ICCV: International Conference on Computer Vision</li>
<li>ICML: International Conference on Machine Learning</li>
<li>NIPS: Annual Conference on Neural Information Processing Systems</li>
<li>AAAI: AAAI Conference on Artificial Intelligence</li>
<li>ACM MM: ACM International Conference on Multimedia</li>
<li>IJCAI: International Joint Conference on Artificial Intelligence</li>
</ul>
<h4 id="暂无评级"><a href="#暂无评级" class="headerlink" title="暂无评级"></a>暂无评级</h4><ul>
<li>ICLR: International Conference on Learning Representations</li>
</ul>
<h4 id="B类"><a href="#B类" class="headerlink" title="B类"></a>B类</h4><ul>
<li>ECCV: European Conference on Computer Vision</li>
</ul>
<h3 id="计算机视觉顶级期刊"><a href="#计算机视觉顶级期刊" class="headerlink" title="计算机视觉顶级期刊"></a>计算机视觉顶级期刊</h3><h4 id="A类-1"><a href="#A类-1" class="headerlink" title="A类"></a>A类</h4><ul>
<li>TPAMI: IEEE Trans on Pattern Analysis and Machine Intelligence</li>
<li>IJCV: International Journal of Computer Vision</li>
<li>TIP: IEEE Transactions on Image Processing</li>
</ul>
<h4 id="B类-1"><a href="#B类-1" class="headerlink" title="B类"></a>B类</h4><ul>
<li>TNNLS: IEEE Transactions on Neural Networks and learning systems</li>
<li>Pattern Recognition</li>
</ul>
<h3 id="SCI"><a href="#SCI" class="headerlink" title="SCI"></a>SCI</h3><p>SCI全称Science Citation Index，是美国科学信息研究所（Institute for Scientific Information， 简称ISI）出版的一部世界著名的期刊文献检索工具。</p>
]]></content>
      <categories>
        <category>DeepLearning期刊</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
        <tag>papers</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（8）深度学习计算</title>
    <url>/2022/10/29/DL_8/</url>
    <content><![CDATA[<p> 在本章中，我们将深入探索深度学习计算的关键组件， 即模型构建、参数访问与初始化、设计自定义层和块、将模型读写到磁盘， 以及利用GPU实现显著的加速。 这些知识将使你从深度学习“基础用户”变为“高级用户”。</p>
<h2 id="层和块"><a href="#层和块" class="headerlink" title="层和块"></a>层和块</h2><p>事实证明，研究讨论“比单个层大”但“比整个模型小”的组件更有价值。为了实现这些复杂的网络，我们引入了神经网络<em>块</em>的概念。 <em>块</em>（block）可以描述单个层、由多个层组成的组件或整个模型本身。</p>
<p>自定义块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-comment"># 用模型参数声明层。这里，我们声明两个全连接的层</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 调用MLP的父类Module的构造函数来执行必要的初始化。</span><br>        <span class="hljs-comment"># 这样，在类实例化时也可以指定其他函数参数，例如模型参数params（稍后将介绍）</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.hidden = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">256</span>)  <span class="hljs-comment"># 隐藏层</span><br>        self.out = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 输出层</span><br><br>    <span class="hljs-comment"># 定义模型的前向传播，即如何根据输入X返回所需的模型输出</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># 注意，这里我们使用ReLU的函数版本，其在nn.functional模块中定义。</span><br>        <span class="hljs-keyword">return</span> self.out(F.relu(self.hidden(X)))<br></code></pre></td></tr></table></figure>

<p>顺序块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MySequential</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *args</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">for</span> idx, module <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(args):<br>            <span class="hljs-comment"># 这里，module是Module子类的一个实例。我们把它保存在&#x27;Module&#x27;类的成员</span><br>            <span class="hljs-comment"># 变量_modules中。_module的类型是OrderedDict</span><br>            self._modules[<span class="hljs-built_in">str</span>(idx)] = module<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-comment"># OrderedDict保证了按照成员添加的顺序遍历它们</span><br>        <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> self._modules.values():<br>            X = block(X)<br>        <span class="hljs-keyword">return</span> X<br></code></pre></td></tr></table></figure>

<h2 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h2><p>之前的介绍中，我们只依靠深度学习框架来完成训练的工作， 而忽略了操作参数的具体细节。</p>
<h3 id="层"><a href="#层" class="headerlink" title="层"></a>层</h3><p>首先关注具有单隐藏层的多层感知机</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br>net = nn.Sequential(nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>), nn.ReLU(), nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>))<br>X = torch.rand(size=(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>))<br>net(X)<br></code></pre></td></tr></table></figure>

<p>每层的参数都在其属性中。如下所示，我们可以检查第二个全连接层的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].state_dict())<span class="hljs-comment"># 权重是层的状态</span><br><span class="hljs-comment"># output</span><br>OrderedDict([(<span class="hljs-string">&#x27;weight&#x27;</span>, tensor([[ <span class="hljs-number">0.0251</span>, -<span class="hljs-number">0.2952</span>, -<span class="hljs-number">0.1204</span>,  <span class="hljs-number">0.3436</span>, -<span class="hljs-number">0.3450</span>, -<span class="hljs-number">0.0372</span>,  <span class="hljs-number">0.0462</span>,  <span class="hljs-number">0.2307</span>]])), (<span class="hljs-string">&#x27;bias&#x27;</span>, tensor([<span class="hljs-number">0.2871</span>]))])<br></code></pre></td></tr></table></figure>

<p>从结果可以看出：首先，这个全连接层包含两个参数，分别是该层的权重和偏置。 两者都存储为单精度浮点数（float32）。 注意，参数名称允许唯一标识每个参数，即使在包含数百个层的网络中也是如此。</p>
<p>也可以查看每一层具体的参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(net[<span class="hljs-number">2</span>].bias))<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].bias)<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].bias.data)、<br><span class="hljs-comment"># output</span><br>&lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;torch.nn.parameter.Parameter&#x27;</span>&gt;<br>Parameter containing:<br>tensor([<span class="hljs-number">0.2871</span>], requires_grad=<span class="hljs-literal">True</span>)<br>tensor([<span class="hljs-number">0.2871</span>])<br><br><span class="hljs-comment"># 在上面这个网络中，由于我们还没有调用反向传播，</span><br><span class="hljs-comment"># 所以参数的梯度处于初始状态。</span><br>net[<span class="hljs-number">2</span>].weight.grad == <span class="hljs-literal">None</span><br><span class="hljs-comment"># output</span><br><span class="hljs-literal">True</span><br><br><span class="hljs-comment"># 一次性访问所有参数</span><br><span class="hljs-built_in">print</span>(*[(name, param.shape) <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net[<span class="hljs-number">0</span>].named_parameters()])<br><span class="hljs-built_in">print</span>(*[(name, param.shape) <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> net.named_parameters()])<br><span class="hljs-comment"># output</span><br>(<span class="hljs-string">&#x27;weight&#x27;</span>, torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">4</span>])) (<span class="hljs-string">&#x27;bias&#x27;</span>, torch.Size([<span class="hljs-number">8</span>]))<br>(<span class="hljs-string">&#x27;0.weight&#x27;</span>, torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">4</span>])) (<span class="hljs-string">&#x27;0.bias&#x27;</span>, torch.Size([<span class="hljs-number">8</span>])) (<span class="hljs-string">&#x27;2.weight&#x27;</span>, torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">8</span>])) (<span class="hljs-string">&#x27;2.bias&#x27;</span>, torch.Size([<span class="hljs-number">1</span>]))<br><br><span class="hljs-comment"># 这为我们提供了另一种访问网络参数的方式，通过名字访问</span><br>net.state_dict()[<span class="hljs-string">&#x27;2.bias&#x27;</span>].data<br><span class="hljs-comment"># output</span><br>tensor([<span class="hljs-number">0.2871</span>])<br></code></pre></td></tr></table></figure>

<h3 id="块"><a href="#块" class="headerlink" title="块"></a>块</h3><p>从嵌套块收集参数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">block1</span>():<br>    <span class="hljs-keyword">return</span> nn.Sequential(nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>), nn.ReLU(),<br>                         nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>), nn.ReLU())<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">block2</span>():<br>    net = nn.Sequential()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">4</span>):<br>        <span class="hljs-comment"># 在这里嵌套</span><br>        net.add_module(<span class="hljs-string">f&#x27;block <span class="hljs-subst">&#123;i&#125;</span>&#x27;</span>, block1())<br>    <span class="hljs-keyword">return</span> net<br><br>rgnet = nn.Sequential(block2(), nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>))<br>rgnet(X)<br></code></pre></td></tr></table></figure>

<p>查看信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(rgnet)<br><span class="hljs-comment"># output</span><br>Sequential(<br>  (<span class="hljs-number">0</span>): Sequential(<br>    (block <span class="hljs-number">0</span>): Sequential(<br>      (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">4</span>, out_features=<span class="hljs-number">8</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">1</span>): ReLU()<br>      (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">4</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">3</span>): ReLU()<br>    )<br>    (block <span class="hljs-number">1</span>): Sequential(<br>      (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">4</span>, out_features=<span class="hljs-number">8</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">1</span>): ReLU()<br>      (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">4</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">3</span>): ReLU()<br>    )<br>    (block <span class="hljs-number">2</span>): Sequential(<br>      (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">4</span>, out_features=<span class="hljs-number">8</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">1</span>): ReLU()<br>      (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">4</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">3</span>): ReLU()<br>    )<br>    (block <span class="hljs-number">3</span>): Sequential(<br>      (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">4</span>, out_features=<span class="hljs-number">8</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">1</span>): ReLU()<br>      (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">4</span>, bias=<span class="hljs-literal">True</span>)<br>      (<span class="hljs-number">3</span>): ReLU()<br>    )<br>  )<br>  (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">4</span>, out_features=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>)<br></code></pre></td></tr></table></figure>

<p>因为层是分层嵌套的，所以我们也可以像通过嵌套列表索引一样访问它们。 下面，我们访问第一个主要的块中、第二个子块的第一层的偏置项。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">rgnet[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>][<span class="hljs-number">0</span>].bias.data<br><span class="hljs-comment"># output</span><br>tensor([-<span class="hljs-number">0.0444</span>, -<span class="hljs-number">0.4451</span>, -<span class="hljs-number">0.4149</span>,  <span class="hljs-number">0.0549</span>, -<span class="hljs-number">0.0969</span>,  <span class="hljs-number">0.2053</span>, -<span class="hljs-number">0.2514</span>,  <span class="hljs-number">0.0220</span>])<br></code></pre></td></tr></table></figure>

<h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><p>默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵， 这个范围是根据输入和输出维度计算出的。 PyTorch的<code>nn.init</code>模块提供了多种预置初始化方法。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 内置初始化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_normal</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.normal_(m.weight, mean=<span class="hljs-number">0</span>, std=<span class="hljs-number">0.01</span>)<br>        nn.init.zeros_(m.bias)<br>net.apply(init_normal)<br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>], net[<span class="hljs-number">0</span>].bias.data[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># output</span><br>(tensor([-<span class="hljs-number">0.0145</span>,  <span class="hljs-number">0.0053</span>,  <span class="hljs-number">0.0055</span>, -<span class="hljs-number">0.0044</span>]), tensor(<span class="hljs-number">0.</span>))<br><br><span class="hljs-comment"># 初始化为给定常数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_constant</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>        nn.init.zeros_(m.bias)<br>net.apply(init_constant)<br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>], net[<span class="hljs-number">0</span>].bias.data[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># output</span><br>(tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]), tensor(<span class="hljs-number">0.</span>))<br><br><span class="hljs-comment"># 对不同块应用不同的初始化方法</span><br><span class="hljs-comment"># 使用Xavier初始化方法初始化第一个神经网络层， </span><br><span class="hljs-comment"># 然后将第三个神经网络层初始化为常量值42</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_xavier</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.xavier_uniform_(m.weight)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_42</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        nn.init.constant_(m.weight, <span class="hljs-number">42</span>)<br><br>net[<span class="hljs-number">0</span>].apply(init_xavier)<br>net[<span class="hljs-number">2</span>].apply(init_42)<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>])<br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].weight.data)<br><span class="hljs-comment"># output</span><br>tensor([-<span class="hljs-number">0.4792</span>,  <span class="hljs-number">0.4968</span>,  <span class="hljs-number">0.6094</span>,  <span class="hljs-number">0.3063</span>])<br>tensor([[<span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>, <span class="hljs-number">42.</span>]])<br><br><span class="hljs-comment"># 自定义初始化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_init</span>(<span class="hljs-params">m</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">type</span>(m) == nn.Linear:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Init&quot;</span>, *[(name, param.shape)<br>                        <span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> m.named_parameters()][<span class="hljs-number">0</span>])<br>        nn.init.uniform_(m.weight, -<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)<br>        m.weight.data *= m.weight.data.<span class="hljs-built_in">abs</span>() &gt;= <span class="hljs-number">5</span><br><br>net.apply(my_init)<br>net[<span class="hljs-number">0</span>].weight[:<span class="hljs-number">2</span>]<br><span class="hljs-comment"># output</span><br>Init weight torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">4</span>])<br>Init weight torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">8</span>])<br><br>tensor([[-<span class="hljs-number">6.9027</span>,  <span class="hljs-number">7.6638</span>, -<span class="hljs-number">0.0000</span>, -<span class="hljs-number">0.0000</span>],<br>        [-<span class="hljs-number">0.0000</span>,  <span class="hljs-number">5.5632</span>, -<span class="hljs-number">6.1899</span>,  <span class="hljs-number">0.0000</span>]], grad_fn=&lt;SliceBackward0&gt;)<br></code></pre></td></tr></table></figure>

<p>上面自定义初始化遵循以下分布<br>MATHJAX-SSR-38</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 也可以直接设置参数</span><br>net[<span class="hljs-number">0</span>].weight.data[:] += <span class="hljs-number">1</span><br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = <span class="hljs-number">42</span><br>net[<span class="hljs-number">0</span>].weight.data[<span class="hljs-number">0</span>]<br><span class="hljs-comment"># output</span><br>tensor([<span class="hljs-number">42.0000</span>,  <span class="hljs-number">8.6638</span>,  <span class="hljs-number">1.0000</span>,  <span class="hljs-number">1.0000</span>])<br></code></pre></td></tr></table></figure>

<h3 id="参数绑定"><a href="#参数绑定" class="headerlink" title="参数绑定"></a>参数绑定</h3><p>有时我们希望在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 我们需要给共享层一个名称，以便可以引用它的参数</span><br>shared = nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>)<br>net = nn.Sequential(nn.Linear(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>), nn.ReLU(),<br>                    shared, nn.ReLU(),<br>                    shared, nn.ReLU(),<br>                    nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>))<br>net(X)<br><span class="hljs-comment"># 检查参数是否相同</span><br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].weight.data[<span class="hljs-number">0</span>] == net[<span class="hljs-number">4</span>].weight.data[<span class="hljs-number">0</span>])<br>net[<span class="hljs-number">2</span>].weight.data[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] = <span class="hljs-number">100</span><br><span class="hljs-comment"># 确保它们实际上是同一个对象，而不只是有相同的值</span><br><span class="hljs-built_in">print</span>(net[<span class="hljs-number">2</span>].weight.data[<span class="hljs-number">0</span>] == net[<span class="hljs-number">4</span>].weight.data[<span class="hljs-number">0</span>])<br><span class="hljs-comment"># output</span><br>tensor([<span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>])<br>tensor([<span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>])<br></code></pre></td></tr></table></figure>

<p> 你可能会思考：当参数绑定时，梯度会发生什么情况？ 答案是由于模型参数包含梯度，因此在反向传播期间第二个隐藏层 （即第三个神经网络层）和第三个隐藏层（即第五个神经网络层）的梯度会加在一起。</p>
<h2 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h2><p>构造一个没有任何参数的自定义层</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">CenteredLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        <span class="hljs-keyword">return</span> X - X.mean()<br>layer = CenteredLayer()<br>layer(torch.FloatTensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]))<br><span class="hljs-comment"># output</span><br>tensor([-<span class="hljs-number">2.</span>, -<span class="hljs-number">1.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>,  <span class="hljs-number">2.</span>])<br><br><span class="hljs-comment"># 将层作为组件合并到构建更复杂的模型中</span><br>net = nn.Sequential(nn.Linear(<span class="hljs-number">8</span>, <span class="hljs-number">128</span>), CenteredLayer())<br>Y = net(torch.rand(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>))<br>Y.mean()<br><span class="hljs-comment"># output</span><br>tensor(<span class="hljs-number">0.</span>, grad_fn=&lt;MeanBackward0&gt;)<br><br><span class="hljs-comment"># 带参数的层</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyLinear</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_units, units</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.weight = nn.Parameter(torch.randn(in_units, units))<br>        self.bias = nn.Parameter(torch.randn(units,))<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, X</span>):<br>        linear = torch.matmul(X, self.weight.data) + self.bias.data<br>        <span class="hljs-keyword">return</span> F.relu(linear)<br><span class="hljs-comment"># 实例化</span><br>linear = MyLinear(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>)<br>linear.weight<br><span class="hljs-comment"># output</span><br>Parameter containing:<br>tensor([[-<span class="hljs-number">1.4779</span>, -<span class="hljs-number">0.6027</span>, -<span class="hljs-number">0.2225</span>],<br>        [ <span class="hljs-number">1.1270</span>, -<span class="hljs-number">0.6127</span>, -<span class="hljs-number">0.2008</span>],<br>        [-<span class="hljs-number">2.1864</span>, -<span class="hljs-number">1.0548</span>,  <span class="hljs-number">0.2558</span>],<br>        [ <span class="hljs-number">0.0225</span>,  <span class="hljs-number">0.0553</span>,  <span class="hljs-number">0.4876</span>],<br>        [ <span class="hljs-number">0.3558</span>,  <span class="hljs-number">1.1427</span>,  <span class="hljs-number">1.0245</span>]], requires_grad=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 使用自定义层执行前向传播运算</span><br>linear(torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>))<br><span class="hljs-comment"># output</span><br>tensor([[<span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">0.2187</span>],<br>        [<span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>, <span class="hljs-number">0.0000</span>]])<br><span class="hljs-comment"># 使用自定义层构建模型，就像使用内置的全连接层一样使用自定义层。</span><br>net = nn.Sequential(MyLinear(<span class="hljs-number">64</span>, <span class="hljs-number">8</span>), MyLinear(<span class="hljs-number">8</span>, <span class="hljs-number">1</span>))<br>net(torch.rand(<span class="hljs-number">2</span>, <span class="hljs-number">64</span>))<br><span class="hljs-comment"># output</span><br>tensor([[ <span class="hljs-number">7.4571</span>],<br>        [<span class="hljs-number">12.7505</span>]])<br></code></pre></td></tr></table></figure>

<h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p>加载和保存张量：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><br>x = torch.arange(<span class="hljs-number">4</span>)<br><span class="hljs-comment"># 保存</span><br>torch.save(x, <span class="hljs-string">&#x27;x-file&#x27;</span>)<br><span class="hljs-comment"># 读取</span><br>x2 = torch.load(<span class="hljs-string">&#x27;x-file&#x27;</span>)<br><span class="hljs-comment"># 存储一个张量，并读回内存</span><br>y = torch.zeros(<span class="hljs-number">4</span>)<br>torch.save([x, y],<span class="hljs-string">&#x27;x-files&#x27;</span>)<br>x2, y2 = torch.load(<span class="hljs-string">&#x27;x-files&#x27;</span>)<br><span class="hljs-comment"># 存储读取从字符串映射到张量的字典</span><br>mydict = &#123;<span class="hljs-string">&#x27;x&#x27;</span>: x, <span class="hljs-string">&#x27;y&#x27;</span>: y&#125;<br>torch.save(mydict, <span class="hljs-string">&#x27;mydict&#x27;</span>)<br>mydict2 = torch.load(<span class="hljs-string">&#x27;mydict&#x27;</span>)<br><br><span class="hljs-comment"># 加载和保存模型参数</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.hidden = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">256</span>)<br>        self.output = nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.output(F.relu(self.hidden(x)))<br>net = MLP()<br>X = torch.randn(size=(<span class="hljs-number">2</span>, <span class="hljs-number">20</span>))<br>Y = net(X)<br><span class="hljs-comment"># 将模型的参数存储在一个叫做“mlp.params”的文件中</span><br>torch.save(net.state_dict(), <span class="hljs-string">&#x27;mlp.params&#x27;</span>)<br><span class="hljs-comment"># 为了恢复模型，我们实例化了原始多层感知机模型的一个备份。 </span><br><span class="hljs-comment"># 这里我们不需要随机初始化模型参数，而是直接读取文件中存储的参数。</span><br>clone = MLP()<br>clone.load_state_dict(torch.load(<span class="hljs-string">&#x27;mlp.params&#x27;</span>))<br>clone.<span class="hljs-built_in">eval</span>()<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo+Github博客搭建指南</title>
    <url>/2022/06/27/Hexo_Github_blog_build_guide/</url>
    <content><![CDATA[<p>记录本博客搭建过程以及搭建过程中遇到的一些琐碎的问题。</p>
<h2 id="Start"><a href="#Start" class="headerlink" title="Start"></a>Start</h2><h3 id="详细搭建过程说明"><a href="#详细搭建过程说明" class="headerlink" title="详细搭建过程说明"></a>详细搭建过程说明</h3><p><a href="https://zhuanlan.zhihu.com/p/60578464">Hexo+Github搭建博客——知乎</a></p>
<h3 id="搭建过程中遇到的坑"><a href="#搭建过程中遇到的坑" class="headerlink" title="搭建过程中遇到的坑"></a>搭建过程中遇到的坑</h3><ol>
<li>验证连接步骤，如果无法连接到<a href="mailto:&#x67;&#x69;&#116;&#64;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#111;&#109;">&#x67;&#x69;&#116;&#64;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#111;&#109;</a>，<code>ssh: connect to host github.com port 22: Connection refused</code>可能是因为使用游戏加速器或者科学上网的原因，需要修改host文件，并且刷新DNS缓存。<ul>
<li>修改host文件：在<code>C:\Windows\System32\drivers\etc\</code>文件夹下，用文本编辑器打开host文件，在最后一行添加如下内容：<figure class="highlight accesslog"><table><tr><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">140.82.113.4</span> github.com<br></code></pre></td></tr></table></figure></li>
<li>DNS刷新：在控制台输入<figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">ipconfig /flushdns<br></code></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h3 id="主题选择"><a href="#主题选择" class="headerlink" title="主题选择"></a>主题选择</h3><p>在<a href="https://hexo.io/themes/">hexo主题</a>可以选择自己喜欢的主题进行部署，点击图片查看该主题的博客demo，点击名称进入该主题的github主页，按照说明部署即可，上面知乎文章里也有详细说明。</p>
<p>根据对应主题配置文档进行个性化配置。以题主采用的zhaoo主题为例，主题配置文档为<a href="https://www.izhaoo.com/2020/05/05/hexo-theme-zhaoo-doc/#%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F">zhaoo配置文档</a></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title>面经总结</title>
    <url>/2022/07/25/Interview_experience/</url>
    <content><![CDATA[<p>准备试找工作，故没事看些面经并进行总结。</p>
<p>大数据开发项目：<a href="https://www.nowcoder.com/discuss/945701?source_id=discuss_experience_nctrack&channel=-1">大数据开发项目_技术交流_牛客网 (nowcoder.com)</a></p>
<h2 id="1-复习"><a href="#1-复习" class="headerlink" title="1. 复习"></a>1. 复习</h2><p>看书，记笔记，形成健全的知识体系。大数据分：数据产品（算法）、数据平台（服务端开发）、数仓（业务）三个方向。</p>
<p>学习路线：</p>
<p>Java-Linux-MySQL-Zoo<a href="">keep</a>er-Hadoop(HDFS、MR、Yarn)-Hive-Flume-Sqoop-Azkaban-Redis-Kafka-HBase-Scala-Spark-Flink</p>
<ul>
<li>MySQL：《MySQL 技术内幕：InnoDB 存储引擎》、《高性能 MySQL》、《MySQL 实战 45 讲》、《从根儿上理解 MySQL》、《从零开始带你成为 MySQL 实战优化高手》</li>
<li>Kafka：半兽人博客、《Apache Kafka 实战》</li>
<li>Zookeeper：《从 Paxos 到 Zookeeper：分布式一致性原理与实践》</li>
<li>Spark</li>
<li>Flink</li>
<li>MapReduce</li>
<li>HiveSQL</li>
</ul>
<h2 id="2-算法"><a href="#2-算法" class="headerlink" title="2. 算法"></a>2. 算法</h2><p>Leetcode前200题反复刷</p>
<h2 id="3-自我介绍"><a href="#3-自我介绍" class="headerlink" title="3. 自我介绍"></a>3. 自我介绍</h2><p>自我介绍是简历的精简,举例：</p>
<figure class="highlight tap"><table><tr><td class="code"><pre><code class="hljs tap">面试官你好，我叫 CoderW，19 年毕业于哈佛大学。<br><br>从毕业到现在一直从事后台研发相关工作。<br><br>19 年-22 年在谷歌中间件团队，主要负责 xx 中间件的设计与开发，在这期间，完成了对 xxx 进行改造和优化，整体性能提升了 80%；<br><br>22 年去了微软电商团队，负责微软电商体系的设计，两年的时间，完成了微软电商从<span class="hljs-number"> 0 </span>到<span class="hljs-number"> 1 </span>的搭建过程。上线至今，日活量达到了<span class="hljs-number"> 10 </span>亿，系统平均 QPS 达到 1W。<br><br>这一次应聘的是贵公司中间件团队的资深专家岗位，在业务方向和技术栈方面，我个人认为我的匹配度还是比较高的，非常希望能够加入贵公司，一起打造 xx 系统。谢谢！<br></code></pre></td></tr></table></figure>

<h2 id="4-技术讨论"><a href="#4-技术讨论" class="headerlink" title="4. 技术讨论"></a>4. 技术讨论</h2><p>整个面试最重要的环节。</p>
<h3 id="4-1态度"><a href="#4-1态度" class="headerlink" title="4.1态度"></a>4.1态度</h3><ol>
<li><p><strong>不卑不亢。</strong>记住，这个环节是技术讨论环节，不是问答环节。一场好的技术讨论一定是有来有回，而不是单方面的你问我答。在尊重面试官的前提上，可以对面试官的一些结论提出质疑和探讨，在我看来，敢于提出自己的不同看法是一个加分项。如果遇到不尊重你，甚至侮辱你的面试官，我建议你直接把简历要回来，大家都是打工人，有什么好装的？</p>
</li>
<li><p><strong>真诚以待。</strong>有些面试官喜欢问一些比较冷门的知识来验证候选人的技术深度，这是一个很正常的事情，你也不需要太过于紧张，真诚一点，会就是会，不会就是不会，没什么关系。<strong>千万不要自作聪明强行去编造，真诚永远是第一要义！</strong></p>
</li>
<li><p><strong>深入发散。</strong>如果聊到你熟悉的一个知识点，你一定要好好把握，可以尝试着深入和发散，让面试官慢慢的进入你的节奏。举个例子，聊到 Kafka 零拷贝的时候。</p>
<ol>
<li><p>深入：你可以继续深入，聊一下 sendfile+DMA Scatter&#x2F;Gather。</p>
</li>
<li><p>发散：深入后再发散，聊一下为什么 RocketMQ 写日志用到了零拷贝，但是 Kafka 写日志的时候不用零拷贝。</p>
</li>
</ol>
<p> <strong>深入是展现你对技术的了解程度，发散是展示你的视野宽度。</strong></p>
</li>
</ol>
<p>回答完一个问题之后，可以小小的总结一下，这样不至于你一个人在那里讲的云里雾里，让面试官都找不到你想要表达的重点了。</p>
<h3 id="4-2常见问题"><a href="#4-2常见问题" class="headerlink" title="4.2常见问题"></a>4.2常见问题</h3><h4 id="4-2-1项目"><a href="#4-2-1项目" class="headerlink" title="4.2.1项目"></a>4.2.1项目</h4><ul>
<li>项目介绍</li>
<li>项目中遇到的困难</li>
<li>项目的详细细节</li>
<li>重新开始怎样优化项目（硬件设备、算法架构、人员配置、团队分工等方面）</li>
</ul>
<h4 id="4-2-2Hadoop"><a href="#4-2-2Hadoop" class="headerlink" title="4.2.2Hadoop"></a>4.2.2Hadoop</h4><ul>
<li><p>Hadoop的了解（简单介绍Hadoop，简述Hadoop的组成和定义）</p>
</li>
<li><p>Hadoop使用经验（介绍Hadoop的生态、组成、应用场景）</p>
</li>
<li><p>Hadoop能够高性能吞吐的依赖有那些（HDFS，MapReduce）</p>
</li>
<li><p>Hadoop的完整计算过程（包括Map、Reduce过程，任务调度等）</p>
</li>
<li><p>Hadoop使用中遇到的困难（从自身设备、内存分配、组件核心配置等方面入手，重点介绍数据倾斜）</p>
</li>
<li><p>什么是数据倾斜问题，场景有哪些？常见的解决方法是什么？</p>
</li>
<li><p>Hadoop数据倾斜的解决方案</p>
</li>
<li><p>Hadoop、Spark、MapReduce区别和优劣</p>
<hr>
</li>
<li><p>Spark常用算子，原理（RDD）</p>
</li>
<li><p>Spark数据倾斜及解决方案</p>
</li>
<li><p>Spark shuffle原理，hashshuffle 和 sortshuffle</p>
<hr>
</li>
<li><p>介绍MR原理（工作流程、Map-Shuffle-Reduce）</p>
<hr>
</li>
<li><p>介绍Hive（Hive的定义、架构）</p>
</li>
<li><p>HiveSQL数据倾斜及解决方案</p>
</li>
</ul>
<h4 id="4-2-3其他"><a href="#4-2-3其他" class="headerlink" title="4.2.3其他"></a>4.2.3其他</h4><ul>
<li>各个框架各自的优缺点和应用场景</li>
<li>数据分仓的理解</li>
<li>未来职业规划</li>
<li>工作中碰到特别复杂的问题怎么办</li>
</ul>
<h2 id="5-反问环节"><a href="#5-反问环节" class="headerlink" title="5. 反问环节"></a>5. 反问环节</h2><ol>
<li>我面试的这个岗位需要用到哪些技术栈？</li>
<li>我面试的这个岗位的最大挑战是什么？</li>
<li>请问面试官对我今后的技术学习有什么建议？</li>
<li>更看重应届生哪方面的素质？</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title>PR_noob_learning</title>
    <url>/2022/10/03/Pr_noob/</url>
    <content><![CDATA[<p>适当学习一些Pr知识，尝试剪辑一些视频。</p>
<h2 id="1-常用快捷键"><a href="#1-常用快捷键" class="headerlink" title="1.常用快捷键"></a>1.常用快捷键</h2><ul>
<li>空格键Space播放和暂停</li>
<li>Left Right键 ：向前向后一帧 （比较细致，可以一直按，这样速度快一点）</li>
<li>shift+Left Right键：向前向后五帧（这个比较快）</li>
<li>J 左穿梭&#x2F;倒放</li>
<li>K 停止穿梭</li>
<li>L 右穿梭&#x2F;正放</li>
<li>Shift + L 慢速右穿梭</li>
<li>Shift + J 慢速左穿梭</li>
<li>穿梭键如果连按，可以加速，K和Space都可以停止播放</li>
<li>时间线窗口中时间帧的管理</li>
<li>End 跳转到序列-素材结束点</li>
<li>Home 跳转到序列-素材开始点</li>
<li>Shift + End 跳转到所选素材结束点</li>
<li>Up 跳转上一个编辑点 </li>
<li>Down 跳转下一个编辑点</li>
<li>i , o:设出入点</li>
<li>Shift + I 跳转入店</li>
<li>Shift + O 跳转出点</li>
<li>‘    提取</li>
<li>， 插入</li>
<li>.    覆盖</li>
</ul>
<h2 id="2-剪辑多素材如何标记出入点"><a href="#2-剪辑多素材如何标记出入点" class="headerlink" title="2.剪辑多素材如何标记出入点"></a>2.剪辑多素材如何标记出入点</h2><table>
<thead>
<tr>
<th align="left">总体</th>
<th>细节</th>
</tr>
</thead>
<tbody><tr>
<td align="left">导入素材</td>
<td>1. 熟悉素材，选取合适的音乐<br />2. 将素材和音乐导入到pr素材窗口中</td>
</tr>
<tr>
<td align="left">简介流程</td>
<td>3. 反复感受音乐，对音乐做一个节奏和情绪上的区分<br />4. 选取偏努力和刻苦一类的素材，选择合适的段落<br />5. 前半段音乐节奏较快的地方，素材相应的要短一些<br />6. 选取成功，胜利一类的素材，放在音乐后半段<br />7. 反复感受音乐节奏，可以在音乐有大的节拍的地方，将剪辑点对齐<br />8. 反复预览视频，使剪辑点和音乐更加契合<br />9. 导出视频</td>
</tr>
</tbody></table>
<h2 id="3-使用卡点插件"><a href="#3-使用卡点插件" class="headerlink" title="3.使用卡点插件"></a>3.使用卡点插件</h2><ol>
<li>导入素材</li>
<li>窗口 -&gt; 扩展 -&gt; beat edit</li>
<li>load music -&gt; sequence markers -&gt; create makers -&gt; 根据节奏调整amounts</li>
<li>导出makers</li>
<li>选择视频或者图片素材，点击素材库下方<strong>自动匹配到序列</strong>按钮</li>
<li>顺序：选择顺序，防止：在未编号标记 -&gt; 确定</li>
</ol>
<h2 id="4-如何添加字幕"><a href="#4-如何添加字幕" class="headerlink" title="4.如何添加字幕"></a>4.如何添加字幕</h2><table>
<thead>
<tr>
<th align="left">名称</th>
<th>特点与流程</th>
</tr>
</thead>
<tbody><tr>
<td align="left">arctime pro 2.0</td>
<td>特点：根据字幕稿添加字幕功能，操作顺手<br />流程：导入视频和字幕稿，直接拖拽字幕，<br />快速添加字幕并调整后导出完整视频</td>
</tr>
<tr>
<td align="left">听见字幕</td>
<td>特点：0.48元&#x2F;分钟价格相对便宜，值得信赖<br />流程：上传音频，自动生成带时间线的字幕文件，<br />可以直接导入pr中编辑</td>
</tr>
<tr>
<td align="left">网易见外</td>
<td>特点：免费字幕文件生成工具，轻松白嫖<br />流程：操作步骤与听见字幕类似，支持字母生成、翻译等</td>
</tr>
</tbody></table>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h2><p>学了跟没学一样，还是啥都不会。</p>
]]></content>
      <categories>
        <category>PR学习</category>
      </categories>
      <tags>
        <tag>Pr</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex学习</title>
    <url>/2022/11/04/Latex/</url>
    <content><![CDATA[<p>研究生阶段要使用LaTex进行论文写作，所以现在进行简单的入门。</p>
<h2 id="1-模板下载"><a href="#1-模板下载" class="headerlink" title="1.模板下载"></a>1.模板下载</h2><ul>
<li>通用模板 <a href="https://www.overleaf.com/">https://www.overleaf.com/</a></li>
<li>通用模板 <a href="http://www.latextemplates.com/">http://www.latextemplates.com/</a></li>
<li>IEEE官方模板<a href="http://www.ieee.org/publications_standards/publications/authors/author_templates.html">http://www.ieee.org/publications_standards/publications/authors/author_templates.html</a></li>
<li>对应投稿期刊的官网</li>
</ul>
<h2 id="2-基本结构"><a href="#2-基本结构" class="headerlink" title="2.基本结构"></a>2.基本结构</h2><figure class="highlight latex"><table><tr><td class="code"><pre><code class="hljs Latex"><span class="hljs-keyword">\documentclass</span>[journal,10pt]&#123;IEEEtran&#125;<br><span class="hljs-comment">%文件类型</span><br><span class="hljs-keyword">\usepackage</span>&#123;宏包名&#125;<br><span class="hljs-keyword">\begin</span>&#123;document&#125; <span class="hljs-comment">%开始文件</span><br>正文<br><span class="hljs-keyword">\end</span>&#123;document&#125; <span class="hljs-comment">%结束文件</span><br></code></pre></td></tr></table></figure>

<h2 id="3-认识基本参数"><a href="#3-认识基本参数" class="headerlink" title="3.认识基本参数"></a>3.认识基本参数</h2><ul>
<li>左右图一一对应</li>
<li>主要在于尝试</li>
<li>英文编译方式选择pdfLaTex</li>
<li>中文编译方式选择XeLaTex</li>
<li>分段：加入一行空行即可</li>
</ul>
<h2 id="4-插入图片"><a href="#4-插入图片" class="headerlink" title="4.插入图片"></a>4.插入图片</h2><figure class="highlight latex"><table><tr><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\documentclass</span>[journal,10pt]&#123;IEEEtran&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;graphicx&#125; <br><span class="hljs-keyword">\begin</span>&#123;document&#125; <span class="hljs-comment">%开始文件</span><br>Text<br><span class="hljs-comment">% 图片支持png,pdf 推荐pdf</span><br>    <span class="hljs-keyword">\begin</span>&#123;figure&#125;[h] <span class="hljs-comment">%[h][t][p][htp]</span><br>        <span class="hljs-keyword">\centering</span> <span class="hljs-comment">%居中</span><br>        <span class="hljs-keyword">\includegraphics</span>[scale=1.1]&#123;Figure/fig2.ong&#125; <span class="hljs-comment">%[trim=15 20 0 0, clip, scale=0.6]</span><br>        <span class="hljs-keyword">\caption</span>&#123;abc&#125;<br>        <span class="hljs-keyword">\label</span>&#123;fig:2&#125; <span class="hljs-comment">% Give a unique label</span><br>    <span class="hljs-keyword">\end</span>&#123;figure&#125;<br><br><span class="hljs-keyword">\end</span>&#123;document&#125; <span class="hljs-comment">%结束文件</span><br></code></pre></td></tr></table></figure>

<p>插入公式、插入表格类似。</p>
<h2 id="5-插入算法"><a href="#5-插入算法" class="headerlink" title="5.插入算法"></a>5.插入算法</h2><figure class="highlight latex"><table><tr><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\documentclass</span>[journal,10pt]&#123;IEEEtran&#125;<br><span class="hljs-keyword">\usepackage</span>[ruled,linesnumbered]&#123;algorithm2e&#125;<br><span class="hljs-keyword">\begin</span>&#123;document&#125; <span class="hljs-comment">%开始文件</span><br>	Text<br>	<span class="hljs-keyword">\begin</span>&#123;algorithm&#125;[h]<br>		<span class="hljs-keyword">\caption</span>&#123;test&#125;<br>		<span class="hljs-keyword">\label</span>&#123;alg:alg4&#125;<br>		<span class="hljs-keyword">\KwIn</span>&#123;<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.261ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 1404.2 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">a,b</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-61" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="529" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="974" y="0"></use>
</g>
</svg>&#125;<br>		<span class="hljs-keyword">\KwOut</span>&#123;<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.007ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 433.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">c</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
</g>
</svg>&#125;<br>		<span class="hljs-keyword">\uIf</span>&#123;b=0&#125;&#123;<br>			<span class="hljs-keyword">\For</span>&#123;<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.954ex" height="2.509ex" style="vertical-align: -0.671ex; margin-left: -0.027ex;" viewBox="-11.5 -791.3 1702.3 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">j \leftarrow</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6A" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2190" x="690" y="0"></use>
</g>
</svg> 1 to <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.064ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 888.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">N</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-4E" x="0" y="0"></use>
</g>
</svg>&#125;&#123;<br>				<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.396ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 4045.5 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">a=a+b</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-61" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="807" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="1863" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2B" x="2615" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="3616" y="0"></use>
</g>
</svg>;<br>			&#125;<br>		&#125;<br>		<span class="hljs-keyword">\ElseIf</span>&#123;<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.519ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 4098.6 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">0&lt;b&lt;1</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-30" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3C" x="778" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="1834" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3C" x="2541" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="3598" y="0"></use>
</g>
</svg>&#125;&#123;<br>			<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.326ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 2293.1 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">a=b</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-61" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="807" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="1863" y="0"></use>
</g>
</svg><br>		&#125;<br>		<span class="hljs-keyword">\Return</span>&#123;<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.007ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 433.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">c</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-63" x="0" y="0"></use>
</g>
</svg>&#125;<br>	<span class="hljs-keyword">\end</span>&#123;algorithm&#125;<br><span class="hljs-keyword">\end</span>&#123;document&#125; <span class="hljs-comment">%结束文件</span><br></code></pre></td></tr></table></figure>

<h2 id="6-插入参考文献"><a href="#6-插入参考文献" class="headerlink" title="6.插入参考文献"></a>6.插入参考文献</h2><figure class="highlight latex"><table><tr><td class="code"><pre><code class="hljs latex"><span class="hljs-keyword">\documentclass</span>[journal,10pt]&#123;IEEEtran&#125;<br><span class="hljs-keyword">\usepackage</span>&#123;cite&#125;<br><span class="hljs-keyword">\begin</span>&#123;document&#125; <span class="hljs-comment">%开始文件</span><br>Text <span class="hljs-keyword">\cite</span>&#123;[1]&#125;<br><span class="hljs-keyword">\bibliographystyle</span>&#123;IEEEtran&#125;<br><span class="hljs-keyword">\bibliography</span>&#123;IEEEabrv, reference.bib&#125;<br><span class="hljs-keyword">\end</span>&#123;document&#125; <span class="hljs-comment">%结束文件</span><br></code></pre></td></tr></table></figure>

<h2 id="7-便于写公式、表格、符号的网站"><a href="#7-便于写公式、表格、符号的网站" class="headerlink" title="7.便于写公式、表格、符号的网站"></a>7.便于写公式、表格、符号的网站</h2><ul>
<li>手写公式转latex editor.codecogs.com&#x2F; </li>
<li>手写符号，转latex表达: detexify.kirelabs.org&#x2F;classify&#x2F;html </li>
<li>截图看公式 <a href="https://mathpix.com/">https://mathpix.com/</a> </li>
<li>手写表格，转latex表达 <a href="https://www.tablesgenerator.com/">https://www.tablesgenerator.com/</a></li>
</ul>
]]></content>
      <tags>
        <tag>LaTex</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（10）文件和异常</title>
    <url>/2022/10/02/Python_10/</url>
    <content><![CDATA[<p>在本章中，你将学习处理文件，让程序能够快速地分析大量的数据；你将学习错误处理，避免程序在面对意外情形时崩溃；你将学习异常 ，它们是Python创建的特殊对象，用于管理程序运行时出现的错误；你还将学习模块json，它让你能够保存用户数据，以免在程序停止运行后丢失。在本章学习的技能可提高程序的适用性、可用性和稳定性。</p>
<h2 id="1-从文件中读取数据"><a href="#1-从文件中读取数据" class="headerlink" title="1.从文件中读取数据"></a>1.从文件中读取数据</h2><p>要使用文本文件中的信息，首先需要将信息读取到内存中。为此，你可以一次性读取文件的全部内容，也可以以每次一行的方式逐步读取。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">filename = <span class="hljs-string">&#x27;pi_digits.txt&#x27;</span><br><span class="hljs-comment"># 读取整个文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> file_object:<br>    contents = file_object.read()<br>    <span class="hljs-built_in">print</span>(line.rstrip())<br><span class="hljs-comment"># 因为read() 到达文件末尾时返回一个空字符串，而将这个空字符串显示就是一个空行。</span><br><span class="hljs-comment"># 要删除多出来的空行，可在print语句中使用rstrip()。</span><br><br><span class="hljs-comment"># 逐行读取</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> file_object:<br>    <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> file_object:<br>        <span class="hljs-built_in">print</span>(line.rstrip())<br><span class="hljs-comment"># 创建一个包含文件各行内容的列表</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> file_object:<br>    lines = file_object.readlines()<br><span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines:<br>    <span class="hljs-built_in">print</span>(line.rstrip())    <br></code></pre></td></tr></table></figure>

<h2 id="2-写入文件"><a href="#2-写入文件" class="headerlink" title="2. 写入文件"></a>2. 写入文件</h2><p>保存数据的最简单的方式之一是将其写入到文件中。通过将输出写入文 件，即便关闭包含程序输出的终端窗口，这些输出也依然存在：你可以在程序结束运行后查看这些输出，可与别人分享输出文件，还可编写程序来 将这些输出读取到内存中并进行处理。</p>
<h3 id="2-1写入空文件"><a href="#2-1写入空文件" class="headerlink" title="2.1写入空文件"></a>2.1写入空文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">filename = <span class="hljs-string">&#x27;programming.txt&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> file_object:<br>    file_object.write(<span class="hljs-string">&quot;I love programming.&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>在这个示例中，调用<strong>open()</strong> 时提供了两个实参。第一个实参也是要打开的文件的名称；第二个实参（’w’ ）告诉Python，我们要以写入模式打开这个文件。打开文件时，可指定读取模式 （’r’ ）、写入模式 （’w’ ）、附加模式 （’a’ ）或让你能够读取和写入文件的模式（’r+’ ）。如果你省略了模式实参，Python将以<strong>默认的只读模式</strong>打开文件。</p>
<p> <strong>如果你要写入的文件不存在，函数open() 将自动创建它。</strong></p>
<p>以写入 （’w’ ）模式打开文件时千万要小心，因为如果指定的文件已经存在， Python将会先清空该文件，再将指定内容写入文件。</p>
<h3 id="2-2写入多行"><a href="#2-2写入多行" class="headerlink" title="2.2写入多行"></a>2.2写入多行</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">filename = <span class="hljs-string">&#x27;programming.txt&#x27;</span><br><span class="hljs-comment"># write()函数不会自动在文本末尾添加换行符，需要手动添加换行符</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> file_object:<br>    file_object.write(<span class="hljs-string">&quot;I love programming.\n&quot;</span>)<br>    file_object.write(<span class="hljs-string">&quot;I love creating new games.\n&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-3附加到文件"><a href="#2-3附加到文件" class="headerlink" title="2.3附加到文件"></a>2.3附加到文件</h3><p>我们打开文件时指定了实参（’a’） ，以便将内容附加到文件末尾， 而不是覆盖文件原来的内容。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">filename = <span class="hljs-string">&#x27;programming.txt&#x27;</span><br><span class="hljs-comment"># write()函数不会自动在文本末尾添加换行符，需要手动添加换行符</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> file_object:<br>    file_object.write(<span class="hljs-string">&quot;I also love finding meaning in large datasets.\n&quot;</span>)<br>    file_object.write(<span class="hljs-string">&quot;I love creating apps that can run in a browser.\n&quot;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-异常"><a href="#3-异常" class="headerlink" title="3.异常"></a>3.异常</h2><p>Python使用被称为异常 的特殊对象来管理程序执行期间发生的错误。每当 发生让Python不知所措的错误时，它都会创建一个异常对象。如果你编写 了处理该异常的代码，程序将继续运行；如果你未对异常进行处理，程序将停止，并显示一个traceback，其中包含有关异常的报告。</p>
<p>异常是使用 <code>try-except</code>代码块处理的。<code>try-except</code> 代码块让Python执 行指定的操作，同时告诉Python发生异常时怎么办。使用了<code>try-except</code> 代码块时，即便出现异常，程序也将继续运行：显示你编写的友好的错误 消息，而不是令用户迷惑的traceback。</p>
<h3 id="3-1使用try-except代码块"><a href="#3-1使用try-except代码块" class="headerlink" title="3.1使用try-except代码块"></a>3.1使用try-except代码块</h3><p>处理ZeroDivisionError异常的try-except代码块类似于下面这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">try</span>:<br>	<span class="hljs-built_in">print</span>(<span class="hljs-number">5</span>/<span class="hljs-number">0</span>)<br><span class="hljs-keyword">except</span> ZeroDivisionError:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;You can&#x27;t divide by zero!&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="3-2使用else代码块"><a href="#3-2使用else代码块" class="headerlink" title="3.2使用else代码块"></a>3.2使用else代码块</h3><p>通过将可能引发错误的代码放在<code>try-except</code>代码块中，可提高这个程序抵御错误的能力。这个示例还包含一个<code>else</code>代码块；依赖于<code>try</code> 代码块成功执行的代码都应放到else代码块中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Give me two numbers, and I&#x27;ll divide them.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Enter &#x27;q&#x27; to quit.&quot;</span>)<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    first_number = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;\nFirst number: &quot;</span>)<br>    <span class="hljs-keyword">if</span> first_number == <span class="hljs-string">&#x27;q&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    second_number = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Second number: &quot;</span>)<br>    <span class="hljs-keyword">if</span> second_number == <span class="hljs-string">&#x27;q&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">try</span>:<br>        answer = <span class="hljs-built_in">int</span>(first_number) / <span class="hljs-built_in">int</span>(second_number)<br>    <span class="hljs-keyword">except</span> ZeroDivisionError:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;You can&#x27;t divide by 0!&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(answer)<br></code></pre></td></tr></table></figure>

<h3 id="3-3使用多个文件"><a href="#3-3使用多个文件" class="headerlink" title="3.3使用多个文件"></a>3.3使用多个文件</h3><p>下面我们统计多本书中的单词数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">count_words</span>(<span class="hljs-params">filename</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Count the approximate number of words in a file.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">try</span>:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            contents = f.read()<br>    <span class="hljs-keyword">except</span> FileNotFoundError:<br>        <span class="hljs-comment"># 提示某本书文件不存在</span><br>        msg = <span class="hljs-string">&quot;Sorry, the file &quot;</span> + filename + <span class="hljs-string">&quot; does not exist.&quot;</span><br>        <span class="hljs-built_in">print</span>(msg)<br>    <span class="hljs-comment"># 失败时一声不吭</span><br>    <span class="hljs-comment"># except FileNotFoundEror:</span><br>    <span class="hljs-comment">#	  pass</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># 计算包含多少个单词</span><br>        words = contents.split()<br>        num_words = <span class="hljs-built_in">len</span>(words)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The file <span class="hljs-subst">&#123;filename&#125;</span> has about <span class="hljs-subst">&#123;num_words&#125;</span> words.&quot;</span>)<br><br>filenames = [<span class="hljs-string">&#x27;alice.txt&#x27;</span>, <span class="hljs-string">&#x27;siddhartha.txt&#x27;</span>, <span class="hljs-string">&#x27;moby_dick.txt&#x27;</span>, <span class="hljs-string">&#x27;little_women.txt&#x27;</span>]<br><span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> filenames:<br>    count_words(filename)<br></code></pre></td></tr></table></figure>

<h2 id="4-存储数据"><a href="#4-存储数据" class="headerlink" title="4.存储数据"></a>4.存储数据</h2><p>很多程序都要求用户输入某种信息，如让用户存储游戏首选项或提供要可 视化的数据。不管专注的是什么，程序都把用户提供的信息存储在列表和 字典等数据结构中。用户关闭程序时，你几乎总是要保存他们提供的信 息；一种简单的方式是使用模块json 来存储数据。</p>
<p>模块json 让你能够将简单的Python数据结构转储到文件中，并在程序再次 运行时加载该文件中的数据。你还可以使用json 在Python程序之间分享数 据。更重要的是，JSON数据格式并非Python专用的，这让你能够将以 JSON格式存储的数据与使用其他编程语言的人分享。这是一种轻便格式， 很有用，也易于学习。</p>
<h3 id="4-1使用json-dump-和json-load"><a href="#4-1使用json-dump-和json-load" class="headerlink" title="4.1使用json.dump()和json.load()"></a>4.1使用json.dump()和json.load()</h3><p>函数<code>json.dump()</code> 接受两个实参：<strong>要存储的数据</strong>以及可用于存储数据的<strong>文件对象</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br>numbers = [<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">11</span>, <span class="hljs-number">13</span>]<br>filename = <span class="hljs-string">&#x27;numbers.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(numbers, f)<br></code></pre></td></tr></table></figure>

<p>使用<code>json.load()</code> 将这个列表读取到内存中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br>filename = <span class="hljs-string">&#x27;numbers.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> f:<br>    numbers = json.load(f)<br><span class="hljs-built_in">print</span>(numbers)<br><span class="hljs-comment"># output: [2, 3, 5, 7, 11, 13]</span><br></code></pre></td></tr></table></figure>

<h3 id="4-2重构"><a href="#4-2重构" class="headerlink" title="4.2重构"></a>4.2重构</h3><p>你经常会遇到这样的情况：代码能够正确地运行，但可做进一步的改进——将代码划分为一系列完成具体工作的函数。这样的过程被称为重构。 重构让代码更清晰、更易于理解、更容易扩展。</p>
]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（1）环境配置</title>
    <url>/2022/06/30/Python_1/</url>
    <content><![CDATA[<p>之前一直在windows平台编程，这次从零开始，完全使用Ubuntu系统学习Python。</p>
<p>参考：<a href="https://muzing.top/posts/6c3096a1/">在 Ubuntu 22.04 上安装 Python 3.9 - muzing的杂货铺</a></p>
<h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><h3 id="更新系统软件"><a href="#更新系统软件" class="headerlink" title="更新系统软件"></a>更新系统软件</h3><figure class="highlight applescript"><table><tr><td class="code"><pre><code class="hljs applescript"><span class="hljs-comment"># 刷新软件包目录</span><br>sudo apt update<br><span class="hljs-comment"># 列出当前可用的更新</span><br>sudo apt <span class="hljs-built_in">list</span> <span class="hljs-comment">--upgradable</span><br><span class="hljs-comment"># 如上一步提示有可以更新的项目，则执行更新</span><br>sudo apt upgrade<br></code></pre></td></tr></table></figure>

<h3 id="安装GCC编译器"><a href="#安装GCC编译器" class="headerlink" title="安装GCC编译器"></a>安装GCC编译器</h3><figure class="highlight cmake"><table><tr><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># 安装 GCC 编译器</span><br>sudo apt <span class="hljs-keyword">install</span> gcc<br><span class="hljs-comment"># 检查安装是否成功</span><br>gcc -v<br><span class="hljs-comment"># 若显示出 GCC 版本则成功</span><br></code></pre></td></tr></table></figure>

<h3 id="安装其他依赖"><a href="#安装其他依赖" class="headerlink" title="安装其他依赖"></a>安装其他依赖</h3><figure class="highlight q"><table><tr><td class="code"><pre><code class="hljs q"># 刷新软件包目录<br>sudo apt <span class="hljs-keyword">update</span><br># 安装依赖<br>sudo apt install build-essential zlib1g-<span class="hljs-built_in">dev</span> libncurses5-<span class="hljs-built_in">dev</span> libgdbm-<span class="hljs-built_in">dev</span> libnss3-<span class="hljs-built_in">dev</span> libssl-<span class="hljs-built_in">dev</span> libreadline-<span class="hljs-built_in">dev</span> libffi-<span class="hljs-built_in">dev</span> libbz2-<span class="hljs-built_in">dev</span> liblzma-<span class="hljs-built_in">dev</span> sqlite3 libsqlite3-<span class="hljs-built_in">dev</span> tk-<span class="hljs-built_in">dev</span> uuid-<span class="hljs-built_in">dev</span> libgdbm-compat-<span class="hljs-built_in">dev</span><br></code></pre></td></tr></table></figure>

<h2 id="编译与安装"><a href="#编译与安装" class="headerlink" title="编译与安装"></a>编译与安装</h2><h3 id="下载源代码"><a href="#下载源代码" class="headerlink" title="下载源代码"></a>下载源代码</h3><p>在 <a href="https://www.python.org/downloads/source/">Python 官网下载界面</a>下载 Python 3.9 的源代码，此处使用目前最新的 3.9.13。</p>
<p>或者采用命令行下载</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 下载 Python 3.9.13</span><br><span class="hljs-attribute">sudo</span> wget https://www.python.org/ftp/python/<span class="hljs-number">3</span>.<span class="hljs-number">9</span>.<span class="hljs-number">13</span>/Python-<span class="hljs-number">3</span>.<span class="hljs-number">9</span>.<span class="hljs-number">13</span>.tar.xz<br><span class="hljs-comment"># 下载其他版本只需替换版本号数字</span><br><span class="hljs-comment"># 解压</span><br><span class="hljs-attribute">tar</span> -xf Python-<span class="hljs-number">3</span>.<span class="hljs-number">9</span>.<span class="hljs-number">13</span>.tar.xz<br><span class="hljs-comment"># 进入该目录</span><br><span class="hljs-attribute">cd</span> Python-<span class="hljs-number">3</span>.<span class="hljs-number">9</span>.<span class="hljs-number">13</span>/<br></code></pre></td></tr></table></figure>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight jboss-cli"><table><tr><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># 检查依赖与配置编译</span><br>sudo <span class="hljs-string">./configure</span> <span class="hljs-params">--enable-optimizations</span> <span class="hljs-params">--with-lto</span> <span class="hljs-params">--enable-shared</span><br></code></pre></td></tr></table></figure>

<p>此处使用了三个可选配置项，含义如下：</p>
<ul>
<li><code>--enable-optimizations</code>：用 <a href="https://docs.python.org/zh-cn/3/using/configure.html#envvar-PROFILE_TASK">PROFILE_TASK</a> 启用以配置文件主导的优化（PGO）</li>
<li><code>--with-lto</code>：在编译过程中启用链接时间优化（LTO）</li>
<li><code>--enable-shared</code>：启用共享 Python 库 <code>libpython</code> 的编译</li>
</ul>
<p>经过一系列检查无误之后，会自动生成 Makefile，即可进行下一步的编译了。</p>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>完成配置，生成 Makefile 后，就可以开始编译了。<strong>编译耗时较长</strong>（要耐心等待），可以使用 <code>-j</code> 选项指定参与编译的 CPU 核心数，例如此机器为 2核 CPU：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 编译，-j 后面的数字为参与编译的CPU核心数，根据个人机器配置调整</span><br><span class="hljs-attribute">sudo</span> make -j <span class="hljs-number">2</span><br></code></pre></td></tr></table></figure>

<p>编译结束后，注意仔细查看一下输出，检查可能存在的错误：</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># 一种可能出现的问题：</span><br>$ sudo make<br><span class="hljs-comment"># ......省略部分输出......</span><br>Python <span class="hljs-keyword">build </span>finished successfully!<br>The necessary <span class="hljs-keyword">bits </span>to <span class="hljs-keyword">build </span>these optional modules were not found:<br>_dbm                  _tkinter              _uuid              <br>To find the necessary <span class="hljs-keyword">bits, </span>look in setup.py in detect_modules() for the module<span class="hljs-string">&#x27;s name.</span><br></code></pre></td></tr></table></figure>

<p>如果出现类似如上的警告，说明编译时有部分软件包不可用，导致编译出的 Python 有部分可选模块不可用。检查上一节中提到的依赖是否都已安装，或求助于网络搜索引擎，安装对应软件包后再次编译即可。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight gauss"><table><tr><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># 安装二进制文件</span><br>sudo <span class="hljs-built_in">make</span> altinstall<br></code></pre></td></tr></table></figure>

<h3 id="链接动态库"><a href="#链接动态库" class="headerlink" title="链接动态库"></a>链接动态库</h3><p>由于[编译配置]中有 <code>--enable-shared</code> 的选项，故此时直接使用命令 <code>python3.9</code> 会提示无法找到 <code>libpython3.9.so.1.0</code> 的错误。只需找到该 <code>so</code> 文件，复制（或创建符号链接）到 <code>/usr/lib/</code> 目录下即可：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 找到 libpython 的位置</span><br>$ whereis libpython3.<span class="hljs-number">9</span>.so.<span class="hljs-number">1.0</span><br>libpython3.<span class="hljs-number">9</span>.so.<span class="hljs-number">1</span>: <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/lib/</span>libpython3.<span class="hljs-number">9</span>.so.<span class="hljs-number">1.0</span><br><span class="hljs-comment"># 在 /usr/lib/ 下创建 libpython 的符号链接</span><br>$ sudo ln -s <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/lib/</span>libpython3.<span class="hljs-number">9</span>.so.<span class="hljs-number">1.0</span> <span class="hljs-regexp">/usr/</span>lib/<br></code></pre></td></tr></table></figure>

<h2 id="使用Python3-9"><a href="#使用Python3-9" class="headerlink" title="使用Python3.9"></a>使用Python3.9</h2><h3 id="命令行使用"><a href="#命令行使用" class="headerlink" title="命令行使用"></a>命令行使用</h3><p>直接在命令行使用 <code>python3.9</code> 命令即可调用新安装的解释器：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 在命令行使用 Python 交互式解释器</span><br>$ python3.<span class="hljs-number">9</span><br>Python <span class="hljs-number">3.9</span>.<span class="hljs-number">13</span> (main, Jun <span class="hljs-number">30</span> <span class="hljs-number">2022</span>, <span class="hljs-number">00</span>:<span class="hljs-number">03</span>:<span class="hljs-number">51</span>) <br>[GCC <span class="hljs-number">9.4</span>.<span class="hljs-number">0</span>] on linux<br>Type <span class="hljs-string">&quot;help&quot;</span>, <span class="hljs-string">&quot;copyright&quot;</span>, <span class="hljs-string">&quot;credits&quot;</span> or <span class="hljs-string">&quot;license&quot;</span> <span class="hljs-keyword">for</span> more information.<br>&gt;&gt;&gt; <br><br><span class="hljs-comment"># 查看该命令所在位置</span><br>$ which python3.<span class="hljs-number">9</span><br><span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/bin/</span>python3.<span class="hljs-number">9</span><br></code></pre></td></tr></table></figure>

<p>类似的，使用 Python 3.9 的 <code>pip</code> 的命令为 <code>pip3.9</code></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 查看 pip3.9 版本</span><br>$ pip3.<span class="hljs-number">9</span> -V<br>pip <span class="hljs-number">22.0</span>.<span class="hljs-number">4</span> from <span class="hljs-regexp">/usr/</span>local<span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">9</span><span class="hljs-regexp">/site-packages/</span>pip (python <span class="hljs-number">3.9</span>)<br></code></pre></td></tr></table></figure>

<h3 id="PyCharm使用"><a href="#PyCharm使用" class="headerlink" title="PyCharm使用"></a>PyCharm使用</h3><p>在 PyCharm 中简单设置后，就可以使用新安装的解释器了。</p>
<ul>
<li><p>首先打开 PyCharm 设置，找到 “Python 解释器” 一项，点击下拉菜单——全部显示</p>
</li>
<li><p>点击左上角的 <code>+</code> ，添加新的解释器</p>
</li>
<li><p>选择添加 “系统解释器”，点击后面的 <code>...</code> 以浏览选择解释器路径</p>
</li>
<li><p>编译安装，解释器可执行文件默认路径为 <code>/usr/local/bin/python3.9</code>，或者可以返回[命令行使用]检查命令 <code>python3.9</code> 的位置。在此处将完整路径粘贴进编辑框即可</p>
</li>
<li><p>点击确定，即可正常使用新安装的解释器了</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（11）测试代码</title>
    <url>/2022/10/03/Python_11/</url>
    <content><![CDATA[<p>在本章中，你将学习如何使用Python模块<code>unittest</code> 中的工具来测试代码。你将学习编写测试用例，核实一系列输入都将得到预期的输出。你将看到测试通过了是什么样子，测试未通过又是什么样子，还将知道测试未通过如何有助于改进代码。你将学习如何测试函数和类，并将知道该为项目编写多少个测试。</p>
<h2 id="1-测试函数"><a href="#1-测试函数" class="headerlink" title="1.测试函数"></a>1.测试函数</h2><p>下面是一个简单的函数，它接收名和姓并返回整洁的姓名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># name_function.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_formatted_name</span>(<span class="hljs-params">first, last, middle=<span class="hljs-string">&#x27;&#x27;</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Generate a neatly formatted full name.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> middle:<br>        full_name = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;first&#125;</span> <span class="hljs-subst">&#123;middle&#125;</span> <span class="hljs-subst">&#123;last&#125;</span>&quot;</span><br>    <span class="hljs-keyword">else</span>:<br>        full_name = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;first&#125;</span> <span class="hljs-subst">&#123;last&#125;</span>&quot;</span><br>    <span class="hljs-keyword">return</span> full_name.title()<br></code></pre></td></tr></table></figure>

<p>为核实<code>get_formatted_name</code>像期望的那样工作，我们来编写一个使用这个函数的程序。程序names.py让用户输入名和姓，并显示整洁的全名。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># names.py</span><br><span class="hljs-keyword">from</span> name_function <span class="hljs-keyword">import</span> get_formatted_name<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Enter &#x27;q&#x27; at any time to quit.&quot;</span>)<br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    first = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;\nPlease give me a first name: &quot;</span>)<br>    <span class="hljs-keyword">if</span> first == <span class="hljs-string">&#x27;q&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    last = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Please give me a last name: &quot;</span>)<br>    <span class="hljs-keyword">if</span> last == <span class="hljs-string">&#x27;q&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    formatted_name = get_formatted_name(first, last)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\tNeatly formatted name: <span class="hljs-subst">&#123;formatted_name&#125;</span>.&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>每次都需要输入测试太过繁琐，所幸Python提供了 一种自动测试函数输出的高效方式。</p>
<h3 id="1-1测试单元和测试用例"><a href="#1-1测试单元和测试用例" class="headerlink" title="1.1测试单元和测试用例"></a>1.1测试单元和测试用例</h3><p>Python标准库中的模块<code>unittest</code> 提供了代码测试工具。<strong>单元测试</strong>用于核实函数的某个方面没有问题；<strong>测试用例</strong>是一组单元测试，这些单元测试一 起核实函数在各种情形下的行为都符合要求。良好的测试用例考虑到了函数可能收到的各种输入，包含针对所有这些情形的测试。<strong>全覆盖式测试用例</strong>包含一整套单元测试，涵盖了各种可能的函数使用方式。对于大型项 目，要实现全覆盖可能很难。通常，最初只要针对代码的重要行为编写测试即可，等项目被广泛使用时再考虑全覆盖。</p>
<h3 id="1-2可通过的测试"><a href="#1-2可通过的测试" class="headerlink" title="1.2可通过的测试"></a>1.2可通过的测试</h3><p>要为函数编写测试用例，可先导入模块<code>unittest</code>以及要测试的函数，再创建一个继承<code>unittest.TestCase</code>的类，并编写一系列方法对函数行为的不同方面进行测试。</p>
<p>下面是一个只包含一个方法的测试用例。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># test_name_function.py</span><br><span class="hljs-keyword">import</span> unittest<br><span class="hljs-keyword">from</span> name_function <span class="hljs-keyword">import</span> get_formatted_name<br><span class="hljs-comment"># 继承unittest.TestCase的自定义的测试类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NamesTestCase</span>(unittest.TestCase):<br>    <span class="hljs-string">&quot;&quot;&quot;测试 &#x27;name_function.py&#x27;.&quot;&quot;&quot;</span>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_first_last_name</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;能够正确地处理像Janis Joplin这样的姓名吗？&quot;&quot;&quot;</span><br>        formatted_name = get_formatted_name(<span class="hljs-string">&#x27;janis&#x27;</span>, <span class="hljs-string">&#x27;joplin&#x27;</span>)<br>        <span class="hljs-comment">#使用断言方法来核实得到的结果与期望的结果是否一致</span><br>        self.assertEqual(formatted_name, <span class="hljs-string">&#x27;Janis Joplin&#x27;</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_first_last_middle_name</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;能够正确地处理像Wolfgang Amadeus Mozart这样的姓名吗？&quot;&quot;&quot;</span><br>        formatted_name = get_formatted_name(<br>            <span class="hljs-string">&#x27;wolfgang&#x27;</span>, <span class="hljs-string">&#x27;mozart&#x27;</span>, <span class="hljs-string">&#x27;amadeus&#x27;</span>)<br>        self.assertEqual(formatted_name, <span class="hljs-string">&#x27;Wolfgang Amadeus Mozart&#x27;</span>)<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-comment"># 在运行时，所有以test打头的方法都将自动运行</span><br>    unittest.main()<br></code></pre></td></tr></table></figure>

<h2 id="2-测试类"><a href="#2-测试类" class="headerlink" title="2. 测试类"></a>2. 测试类</h2><p>下面来编写针对类的测试。很多程序中都会用到类，因此能够证明你的类能够正确地工作会大有裨益。如果针对类的测试通过了，你就能确信对类所做的改进没有意外地破坏其原有的行为。</p>
<h3 id="2-1各种断言方法"><a href="#2-1各种断言方法" class="headerlink" title="2.1各种断言方法"></a>2.1各种断言方法</h3><table>
<thead>
<tr>
<th>方法</th>
<th>用途</th>
</tr>
</thead>
<tbody><tr>
<td><code>assertEqual(a, b)</code></td>
<td>核实a &#x3D;&#x3D; b</td>
</tr>
<tr>
<td><code>assertNotEqual(a, b)</code></td>
<td>核实a !&#x3D; b</td>
</tr>
<tr>
<td><code>assertTrue(x)</code></td>
<td>核实x为True</td>
</tr>
<tr>
<td><code>assertFalse(x)</code></td>
<td>核实x为False</td>
</tr>
<tr>
<td><code>assertIn(item, list)</code></td>
<td>核实item在list中</td>
</tr>
<tr>
<td><code>assertNotIn(item, list)</code></td>
<td>核实item不在list中</td>
</tr>
</tbody></table>
<h3 id="2-2一个要测试的类"><a href="#2-2一个要测试的类" class="headerlink" title="2.2一个要测试的类"></a>2.2一个要测试的类</h3><p>下面来编写一个类进行测试。来看一个帮助管理匿名调查的类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># survey.py</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">AnonymousSurvey</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;收集匿名调查问卷的答案&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, question</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;存储一个问题，并为存储答案做准备&quot;&quot;&quot;</span><br>        self.question = question<br>        self.responses = []<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">show_question</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;显示调查问卷&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(self.question)        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">store_response</span>(<span class="hljs-params">self, new_response</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;存储单份调查答卷&quot;&quot;&quot;</span><br>        self.responses.append(new_response)        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">show_results</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;显示收集到的所有答卷&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Survey results:&quot;</span>)<br>        <span class="hljs-keyword">for</span> response <span class="hljs-keyword">in</span> self.responses:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;- <span class="hljs-subst">&#123;response&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="2-3测试AnonymousSurvey类"><a href="#2-3测试AnonymousSurvey类" class="headerlink" title="2.3测试AnonymousSurvey类"></a>2.3测试AnonymousSurvey类</h3><p>我们将在这个答案被存储后，使用方法<code>assertIn()</code> 来核实它包含在答案列表中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># test_survey.py</span><br><span class="hljs-keyword">import</span> unittest<br><span class="hljs-keyword">from</span> survey <span class="hljs-keyword">import</span> AnonymousSurvey<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestAnonymousSurvey</span>(unittest.TestCase):<br>    <span class="hljs-string">&quot;&quot;&quot;针对AnonymousSurvey类的测试&quot;&quot;&quot;</span>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setUp</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;创建一个调查对象和一组答案，供使用的测试方法使用&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 如果你在TestCase类包含方法setUp()，Python将先运行它，再运行各个以test_打头的方法。</span><br>        question = <span class="hljs-string">&quot;What language did you first learn to speak?&quot;</span><br>        self.my_survey = AnonymousSurvey(question)<br>        self.responses = [<span class="hljs-string">&#x27;English&#x27;</span>, <span class="hljs-string">&#x27;Spanish&#x27;</span>, <span class="hljs-string">&#x27;Mandarin&#x27;</span>]<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_store_single_response</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;测试单个答案会被妥善地存储&quot;&quot;&quot;</span><br>        self.my_survey.store_response(self.responses[<span class="hljs-number">0</span>])<br>        self.assertIn(self.responses[<span class="hljs-number">0</span>], self.my_survey.responses)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test_store_three_responses</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;测试三个答案会被妥善地存储&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">for</span> response <span class="hljs-keyword">in</span> self.responses:<br>            self.my_survey.store_response(response)<br>        <span class="hljs-keyword">for</span> response <span class="hljs-keyword">in</span> self.responses:<br>            self.assertIn(response, self.my_survey.responses)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    unittest.main()<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（13）下载数据【项目2 数据可视化】</title>
    <url>/2022/10/10/Python_13/</url>
    <content><![CDATA[<p>在本章中，你将从网上下载数据，并对这些数据进行可视化。</p>
<h2 id="1-CSV文件"><a href="#1-CSV文件" class="headerlink" title="1.CSV文件"></a>1.CSV文件</h2><p>要在文本文件中存储数据，最简单的方式是将数据作为一系列以逗号分隔 的值（CSV）写入文件。这样的文件称为CSV文件。下面是一行CSV格式的天气数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-string">&quot;USW00025333&quot;</span>,<span class="hljs-string">&quot;SITKA AIRPORT, AK US&quot;</span>,<span class="hljs-string">&quot;2018-01-01&quot;</span>,<span class="hljs-string">&quot;13.87&quot;</span>,<span class="hljs-string">&quot; 0023&quot;</span>,<span class="hljs-string">&quot;0.45&quot;</span>,,,<span class="hljs-string">&quot;48&quot;</span>,<span class="hljs-string">&quot;38&quot;</span>,<span class="hljs-string">&quot;  110&quot;</span>,<span class="hljs-string">&quot;  110&quot;</span>,<span class="hljs-string">&quot;31.1&quot;</span>,<span class="hljs-string">&quot;38.0&quot;</span>,<br></code></pre></td></tr></table></figure>

<h3 id="1-1读取csv文件"><a href="#1-1读取csv文件" class="headerlink" title="1.1读取csv文件"></a>1.1读取csv文件</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> csv<br>filename = <span class="hljs-string">&#x27;./data/sitka_weather_07-2018_simple.csv&#x27;</span><br><span class="hljs-comment">#读取文件头</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> f:<br>    reader = csv.reader(f)<span class="hljs-comment">#创建一个与该文件关联的阅读器（reader）对象</span><br>    header_row = <span class="hljs-built_in">next</span>(reader)<span class="hljs-comment">#next 返回文件中的下一行</span><br>    <span class="hljs-keyword">for</span> index, column_header <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(header_row):<br>        <span class="hljs-built_in">print</span>(index, column_header)<br><span class="hljs-comment">#output:</span><br><span class="hljs-number">0</span> STATION<br><span class="hljs-number">1</span> NAME<br><span class="hljs-number">2</span> DATE<br><span class="hljs-number">3</span> PRCP<br><span class="hljs-number">4</span> TAVG<br><span class="hljs-number">5</span> TMAX<br><span class="hljs-number">6</span> TMIN<br><span class="hljs-comment">#提取数据，最高温</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> f:<br>    reader = csv.reader(f)<br>    header_row = <span class="hljs-built_in">next</span>(reader)<br>    highs = []<br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>        highs.append(<span class="hljs-built_in">int</span>(row[<span class="hljs-number">5</span>]))<br>    <span class="hljs-built_in">print</span>(highs)<br><span class="hljs-comment">#output:</span><br>[<span class="hljs-number">62</span>, <span class="hljs-number">58</span>, <span class="hljs-number">70</span>, <span class="hljs-number">70</span>, <span class="hljs-number">67</span>, <span class="hljs-number">59</span>, <span class="hljs-number">58</span>, <span class="hljs-number">62</span>, <span class="hljs-number">66</span>, <span class="hljs-number">59</span>, <span class="hljs-number">56</span>, <span class="hljs-number">63</span>, <span class="hljs-number">65</span>, <span class="hljs-number">58</span>, <span class="hljs-number">56</span>, <span class="hljs-number">59</span>, <span class="hljs-number">64</span>, <span class="hljs-number">60</span>, <span class="hljs-number">60</span>, <span class="hljs-number">61</span>, <span class="hljs-number">65</span>, <span class="hljs-number">65</span>, <span class="hljs-number">63</span>, <span class="hljs-number">59</span>, <span class="hljs-number">64</span>, <span class="hljs-number">65</span>, <span class="hljs-number">68</span>, <span class="hljs-number">66</span>, <span class="hljs-number">64</span>, <span class="hljs-number">67</span>, <span class="hljs-number">65</span>]<br></code></pre></td></tr></table></figure>

<h3 id="1-2绘制气温图表"><a href="#1-2绘制气温图表" class="headerlink" title="1.2绘制气温图表"></a>1.2绘制气温图表</h3><p>为可视化这些气温数据，我们首先使用matplotlib创建一个显示每日最高气 温的简单图形。</p>
<table>
<thead>
<tr>
<th>实参</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>%A</td>
<td>星期的名称，如Monday</td>
</tr>
<tr>
<td>%B</td>
<td>月份名，如January</td>
</tr>
<tr>
<td>%m</td>
<td>用数字表示的月份（01~12）</td>
</tr>
<tr>
<td>%d</td>
<td>用数字表示月份中的一天（01~31）</td>
</tr>
<tr>
<td>%Y</td>
<td>四位的年份，如2015</td>
</tr>
<tr>
<td>%y</td>
<td>两位的年份，如15</td>
</tr>
<tr>
<td>%H</td>
<td>24小时制的小时数（00~23）</td>
</tr>
<tr>
<td>%I</td>
<td>12小时制的小时数（01~12）</td>
</tr>
<tr>
<td>%p</td>
<td>am或pm</td>
</tr>
<tr>
<td>%M</td>
<td>分钟数（00~59）</td>
</tr>
<tr>
<td>%S</td>
<td>秒数（00~61）</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> datetime <span class="hljs-keyword">import</span> datetime<br><span class="hljs-keyword">import</span> csv<br>filename = <span class="hljs-string">&#x27;./data/sitka_weather_2018_simple.csv&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> f:<br>    reader = csv.reader(f)<br>    header_row = <span class="hljs-built_in">next</span>(reader)<br>    dates, highs, lows = [], [], []<br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>        <span class="hljs-keyword">try</span>:<br>            <span class="hljs-comment">#如果有缺失数据，就会引发ValueError错误</span><br>            dates.append(datetime.strptime(row[<span class="hljs-number">2</span>], <span class="hljs-string">&quot;%Y-%m-%d&quot;</span>))<br>            highs.append(<span class="hljs-built_in">int</span>(row[<span class="hljs-number">5</span>]))<br>            lows.append(<span class="hljs-built_in">int</span>(row[<span class="hljs-number">6</span>]))<br>        <span class="hljs-keyword">except</span> ValueError:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;missing data&#x27;</span>)<br><span class="hljs-comment"># 根据数据绘制图形</span><br>fig = plt.figure(dpi=<span class="hljs-number">128</span>, figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br>plt.plot(dates, highs, c=<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.plot(dates, lows, c=<span class="hljs-string">&#x27;blue&#x27;</span>)<br><span class="hljs-comment"># 用阴影填充两条折线间的空间</span><br>plt.fill_between(dates, highs, lows, facecolor=<span class="hljs-string">&#x27;blue&#x27;</span>, alpha=<span class="hljs-number">0.1</span>)<br><span class="hljs-comment"># 设置图形的格式</span><br>plt.title(<span class="hljs-string">&quot;Daily high temperatures, July 2018&quot;</span>, fontsize=<span class="hljs-number">24</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;&#x27;</span>, fontsize=<span class="hljs-number">16</span>)<br>fig.autofmt_xdate()<span class="hljs-comment"># 绘制斜的日期标签</span><br>plt.ylabel(<span class="hljs-string">&#x27;Temperature(F)&#x27;</span>, fontsize=<span class="hljs-number">16</span>)<br>plt.tick_params(axis=<span class="hljs-string">&#x27;both&#x27;</span>, which=<span class="hljs-string">&#x27;major&#x27;</span>, labelsize=<span class="hljs-number">16</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<h3 id="1-3绘制世界人口地图：JSON格式"><a href="#1-3绘制世界人口地图：JSON格式" class="headerlink" title="1.3绘制世界人口地图：JSON格式"></a>1.3绘制世界人口地图：JSON格式</h3><p><code>plotly</code>提供了一个适合初学者使用的地图创建工具，你将使用它来对地震数据进行可视化，以探索地震的分布情况。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#提取数据</span><br><span class="hljs-keyword">import</span> json<br><span class="hljs-comment">#将数据加载到一个列表中</span><br>filename = <span class="hljs-string">&#x27;./global_data/eq_data_1_day_m1.json&#x27;</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filename) <span class="hljs-keyword">as</span> f:<br>    all_eq_data = json.load(f)<br>all_eq_dicts = all_eq_data[<span class="hljs-string">&#x27;features&#x27;</span>]<br><span class="hljs-comment">#打印震级，经度，纬度，标题</span><br>mags, lons, lats, hover_texts = [], [], [], []<br><span class="hljs-keyword">for</span> eq_dict <span class="hljs-keyword">in</span> all_eq_dicts:<br>    mag = eq_dict[<span class="hljs-string">&#x27;properties&#x27;</span>][<span class="hljs-string">&#x27;mag&#x27;</span>]<br>    lon = eq_dict[<span class="hljs-string">&#x27;geometry&#x27;</span>][<span class="hljs-string">&#x27;coordinates&#x27;</span>][<span class="hljs-number">0</span>]<br>    lat = eq_dict[<span class="hljs-string">&#x27;geometry&#x27;</span>][<span class="hljs-string">&#x27;coordinates&#x27;</span>][<span class="hljs-number">1</span>]<br>    title = eq_dict[<span class="hljs-string">&#x27;properties&#x27;</span>][<span class="hljs-string">&#x27;title&#x27;</span>]<br>    mags.append(mag)<br>    lons.append(lon)<br>    lats.append(lat)<br>    hover_texts.append(title)<br><span class="hljs-built_in">print</span>(mags[:<span class="hljs-number">10</span>])<br><span class="hljs-built_in">print</span>(lons[:<span class="hljs-number">5</span>])<br><span class="hljs-built_in">print</span>(lats[:<span class="hljs-number">5</span>])<br><span class="hljs-comment">#output:</span><br>[<span class="hljs-number">0.96</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">4.3</span>, <span class="hljs-number">3.6</span>, <span class="hljs-number">2.1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1.06</span>, <span class="hljs-number">2.3</span>, <span class="hljs-number">4.9</span>, <span class="hljs-number">1.8</span>]<br>[-<span class="hljs-number">116.7941667</span>, -<span class="hljs-number">148.9865</span>, -<span class="hljs-number">74.2343</span>, -<span class="hljs-number">161.6801</span>, -<span class="hljs-number">118.5316667</span>]<br>[<span class="hljs-number">33.4863333</span>, <span class="hljs-number">64.6673</span>, -<span class="hljs-number">12.1025</span>, <span class="hljs-number">54.2232</span>, <span class="hljs-number">35.3098333</span>]<br><span class="hljs-comment">#绘制地震地图</span><br><span class="hljs-keyword">from</span> plotly.graph_objs <span class="hljs-keyword">import</span> Scattergeo, Layout<br><span class="hljs-keyword">from</span> plotly <span class="hljs-keyword">import</span> offline<br>data = [&#123;<br>    <span class="hljs-string">&#x27;type&#x27;</span>: <span class="hljs-string">&#x27;scattergeo&#x27;</span>,<br>    <span class="hljs-string">&#x27;lon&#x27;</span>: lons,<br>    <span class="hljs-string">&#x27;lat&#x27;</span>: lats,<br>    <span class="hljs-string">&#x27;text&#x27;</span>: hover_texts,<br>    <span class="hljs-string">&#x27;marker&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;size&#x27;</span>: [<span class="hljs-number">5</span>*mag <span class="hljs-keyword">for</span> mag <span class="hljs-keyword">in</span> mags],<br>        <span class="hljs-string">&#x27;color&#x27;</span>: mags,<br>        <span class="hljs-string">&#x27;colorscale&#x27;</span>: <span class="hljs-string">&#x27;Viridis&#x27;</span>,<br>        <span class="hljs-string">&#x27;reversescale&#x27;</span>: <span class="hljs-literal">True</span>,<br>        <span class="hljs-string">&#x27;colorbar&#x27;</span>: &#123;<span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Magnitude&#x27;</span>&#125;,<br>    &#125;,<br>&#125;]<br>my_layout = Layout(title=<span class="hljs-string">&#x27;Global Earthquakes&#x27;</span>)<br>fig = &#123;<span class="hljs-string">&#x27;data&#x27;</span>: data, <span class="hljs-string">&#x27;layout&#x27;</span>: my_layout&#125;<br>offline.plot(fig, filename=<span class="hljs-string">&#x27;global_earthquakes.html&#x27;</span>)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（14）使用API【项目2 数据可视化】</title>
    <url>/2022/10/11/Python_14/</url>
    <content><![CDATA[<p>在本章中，你将学习如何编写一个独立的程序，并对其获取的数据进行可视化。</p>
<h2 id="1-使用Web-API"><a href="#1-使用Web-API" class="headerlink" title="1.使用Web API"></a>1.使用Web API</h2><p>本章的可视化将基于来自GitHub的信息，这是一个让程序员能够协作开发 项目的网站。我们将使用GitHub的API来请求有关该网站中Python项目的信 息，然后使用<code>Pygal</code>生成交互式可视化，以呈现这些项目的受欢迎程度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">https://api.github.com/search/repositories?q=language:python&amp;sort=stars<br>功能: 返回GitHub当前托管了多少个Python项目，还有有关最受欢迎的Python仓库的信息。<br>第一部分:<br>（https://api.github.com/ ）将请求发送到GitHub网站中响应API调用的部分<br>第二部分（search/repositories ）让API搜索GitHub上的所有仓库。<br>repositories 后面的问号指出我们要传递一个实参。<br>q表示查询，而等号让我们能够开始指定查询（q=）。<br>通过使用language:python ，我们指出只想获取主要语言为Python的仓库的信息。最后一部分<br>（&amp;sort=stars）指定将项目按其获得的星星数进行排序。<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-comment">#执行API调用并存储响应</span><br>url = <span class="hljs-string">&#x27;https://api.github.com/search/repositories?q=language:python&amp;sort=stars&#x27;</span><br>r = requests.get(url)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Status code: &quot;</span>, r.status_code)<br><span class="hljs-comment">#将API响应存储在一个变量中</span><br>response_dict = r.json()<br><span class="hljs-comment">#处理结果</span><br><span class="hljs-built_in">print</span>(response_dict.keys())<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Toral repositories:&quot;</span>, response_dict[<span class="hljs-string">&#x27;total_count&#x27;</span>])<br><span class="hljs-comment">#output:</span><br>Status code:  <span class="hljs-number">200</span><br>dict_keys([<span class="hljs-string">&#x27;total_count&#x27;</span>, <span class="hljs-string">&#x27;incomplete_results&#x27;</span>, <span class="hljs-string">&#x27;items&#x27;</span>])<br>Toral repositories: <span class="hljs-number">9020420</span><br></code></pre></td></tr></table></figure>

<p>仓库相关信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#探索有关仓库的信息</span><br>repo_dicts = response_dict[<span class="hljs-string">&#x27;items&#x27;</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Repositories returned: &quot;</span>, <span class="hljs-built_in">len</span>(repo_dicts))<br><span class="hljs-comment">#验究第一个仓库</span><br>repo_dict = repo_dicts[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nKeys: &quot;</span>, <span class="hljs-built_in">len</span>(repo_dict))<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(repo_dict.keys()):<br>    <span class="hljs-built_in">print</span>(key)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nSelected information about first repository:&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Name:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;name&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Owner:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;owner&#x27;</span>][<span class="hljs-string">&#x27;login&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Stars:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;stargazers_count&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Repository:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;html_url&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Created:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;created_at&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Updated:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;updated_at&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Description:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;description&#x27;</span>])<br><span class="hljs-comment">#output:</span><br>Repositories returned:  <span class="hljs-number">30</span><br><br>Keys:  <span class="hljs-number">79</span><br>allow_forking<br>archive_url<br>archived<br>assignees_url<br>blobs_url<br>branches_url<br>clone_url<br>collaborators_url<br>comments_url<br>commits_url<br>compare_url<br>...<br><br>Selected information about first repository:<br>Name: public-apis<br>Owner: public-apis<br>Stars: <span class="hljs-number">211850</span><br>Repository: https://github.com/public-apis/public-apis<br>Created: <span class="hljs-number">2016</span>-03-20T23:<span class="hljs-number">49</span>:42Z<br>Updated: <span class="hljs-number">2022</span>-<span class="hljs-number">10</span>-11T02:<span class="hljs-number">30</span>:33Z<br>Description: A collective <span class="hljs-built_in">list</span> of free APIs<br>    <br><span class="hljs-comment">#检视检视所有项目的信息</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nSelected information about each repository:&quot;</span>)<br><span class="hljs-keyword">for</span> repo_dict <span class="hljs-keyword">in</span> repo_dicts:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;\nName:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;name&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Owner:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;owner&#x27;</span>][<span class="hljs-string">&#x27;login&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Stars:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;stargazers_count&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Repository:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;html_url&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Description:&#x27;</span>, repo_dict[<span class="hljs-string">&#x27;description&#x27;</span>])<br><span class="hljs-comment">#output:</span><br>Selected information about each repository:<br><br>Name: public-apis<br>Owner: public-apis<br>Stars: <span class="hljs-number">211850</span><br>Repository: https://github.com/public-apis/public-apis<br>Description: A collective <span class="hljs-built_in">list</span> of free APIs<br><br>Name: system-design-primer<br>Owner: donnemartin<br>Stars: <span class="hljs-number">199433</span><br>Repository: https://github.com/donnemartin/system-design-primer<br>Description: Learn how to design large-scale systems. Prep <span class="hljs-keyword">for</span> the system design interview.  Includes Anki flashcards.<br><br>Name: awesome-python<br>Owner: vinta<br>Stars: <span class="hljs-number">144231</span><br>Repository: https://github.com/vinta/awesome-python<br>Description: A curated <span class="hljs-built_in">list</span> of awesome Python frameworks, libraries, software <span class="hljs-keyword">and</span> resources<br><br>Name: youtube-dl<br>Owner: ytdl-org<br>Stars: <span class="hljs-number">114026</span><br>Repository: https://github.com/ytdl-org/youtube-dl<br>Description: Command-line program to download videos <span class="hljs-keyword">from</span> YouTube.com <span class="hljs-keyword">and</span> other video sites<br><br>Name: thefuck<br>Owner: nvbn<br>Stars: <span class="hljs-number">73960</span><br>Repository: https://github.com/nvbn/thefuck<br>Description: Magnificent app which corrects your previous console command.<br>    <br>...<br></code></pre></td></tr></table></figure>

<h2 id="2-使用Pygal可视化仓库"><a href="#2-使用Pygal可视化仓库" class="headerlink" title="2.使用Pygal可视化仓库"></a>2.使用Pygal可视化仓库</h2><p>创建条形图表示项目获得了多少颗星星。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> pygal<br><span class="hljs-keyword">from</span> pygal.style <span class="hljs-keyword">import</span> LightColorizedStyle <span class="hljs-keyword">as</span> LCS, LightenStyle <span class="hljs-keyword">as</span> LS<br><span class="hljs-comment"># 执行API调用并存储响应</span><br>URL = <span class="hljs-string">&#x27;https://api.github.com/search/repositories?q=language:python&amp;sort=stars&#x27;</span><br>r = requests.get(URL)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Status code: &quot;</span>, r.status_code)<br><br><span class="hljs-comment">#将API响应存储在一个变量中</span><br>response_dict = r.json()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Total repositories: &quot;</span>, response_dict[<span class="hljs-string">&#x27;total_count&#x27;</span>])<br><span class="hljs-comment">#研究有关仓库的信息</span><br>repo_dicts = response_dict[<span class="hljs-string">&#x27;items&#x27;</span>]<br>names, plot_dicts = [], []<br><span class="hljs-keyword">for</span> repo_dict <span class="hljs-keyword">in</span> repo_dicts:<br>    names.append(repo_dict[<span class="hljs-string">&#x27;name&#x27;</span>])<br>    plot_dicts.append(&#123;<br>        <span class="hljs-string">&#x27;value&#x27;</span>: repo_dict[<span class="hljs-string">&#x27;stargazers_count&#x27;</span>],<br>        <span class="hljs-comment">#添加自定义工具提示</span><br>        <span class="hljs-string">&#x27;label&#x27;</span>: repo_dict[<span class="hljs-string">&#x27;description&#x27;</span>],<br>        <span class="hljs-comment">#将图表中的每个条形用作网站的链接</span><br>        <span class="hljs-string">&#x27;xlink&#x27;</span>: repo_dict[<span class="hljs-string">&#x27;html_url&#x27;</span>]<br>    &#125;)<br><span class="hljs-comment">#可视化</span><br>my_style = LS(<span class="hljs-string">&#x27;#333366&#x27;</span>, base_style=LCS)<br><span class="hljs-comment"># chart = pygal.Bar(style=my_style, x_label_rotation=45, show_legend=False)</span><br><span class="hljs-comment">#创建一个配置对象，包含传递给Bar()的所有定制</span><br>my_config = pygal.Config()<br>my_config.x_label_rotation = <span class="hljs-number">45</span><span class="hljs-comment">#倾斜45度</span><br>my_config.show_legend = <span class="hljs-literal">False</span><span class="hljs-comment">#不展示图例</span><br>my_config.title_font_size = <span class="hljs-number">24</span><br>my_config.label_font_size = <span class="hljs-number">14</span><br>my_config.major_label_font_size = <span class="hljs-number">18</span><br>my_config.truncate_label = <span class="hljs-number">15</span><span class="hljs-comment">#将较长的项目名缩短为15个字符</span><br>my_config.show_y_guides = <span class="hljs-literal">False</span><span class="hljs-comment">#隐藏图中的水平线</span><br>my_config.width = <span class="hljs-number">1000</span><br>chart = pygal.Bar(my_config, style=my_style)<br><br>chart.title = <span class="hljs-string">&#x27;Most-Starred Python Projects on Github&#x27;</span><br>chart.x_labels = names<br><br>chart.add(<span class="hljs-string">&#x27;&#x27;</span>, plot_dicts)<br>chart.render_to_file(<span class="hljs-string">&#x27;python_repos.svg&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="3-Hacker-News-API"><a href="#3-Hacker-News-API" class="headerlink" title="3.Hacker News API"></a>3.Hacker News API</h2><p>下面的调用返回本书编写时最热门的文章的信息</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">https://hacker-news.firebaseio.com/v0/item/<span class="hljs-number">9884165.j</span>son<br></code></pre></td></tr></table></figure>

<p>响应是一个字典，包含ID为9884165的文章的信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><code class="hljs js">&#123;<br>    <span class="hljs-string">&quot;by&quot;</span>:<span class="hljs-string">&quot;nns&quot;</span>,<br>    <span class="hljs-string">&quot;descendants&quot;</span>:<span class="hljs-number">297</span>,<br>    <span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-number">9884165</span>,<br>    <span class="hljs-string">&quot;kids&quot;</span>:[<span class="hljs-number">9885099</span>,<span class="hljs-number">9884723</span>,<span class="hljs-number">9885165</span>,<span class="hljs-number">9884789</span>,<span class="hljs-number">9885604</span>,<span class="hljs-number">9884137</span>,<span class="hljs-number">9886151</span>,<span class="hljs-number">9885220</span>,<span class="hljs-number">9885790</span>,<span class="hljs-number">9884661</span>,<span class="hljs-number">9885844</span>,<span class="hljs-number">9885029</span>,<span class="hljs-number">9884817</span>,<span class="hljs-number">9887342</span>,<span class="hljs-number">9884545</span>,<span class="hljs-number">9884372</span>,<span class="hljs-number">9884499</span>,<span class="hljs-number">9884881</span>,<span class="hljs-number">9884109</span>,<span class="hljs-number">9886496</span>,<span class="hljs-number">9884342</span>,<span class="hljs-number">9887832</span>,<span class="hljs-number">9885023</span>,<span class="hljs-number">9884334</span>,<span class="hljs-number">9884707</span>,<span class="hljs-number">9887008</span>,<span class="hljs-number">9885348</span>,<span class="hljs-number">9885131</span>,<span class="hljs-number">9887539</span>,<span class="hljs-number">9885880</span>,<span class="hljs-number">9884196</span>,<span class="hljs-number">9884640</span>,<span class="hljs-number">9886534</span>,<span class="hljs-number">9885152</span>],<br>    <span class="hljs-string">&quot;score&quot;</span>:<span class="hljs-number">558</span>,<br>    <span class="hljs-string">&quot;time&quot;</span>:<span class="hljs-number">1436875181</span>,<br>    <span class="hljs-string">&quot;title&quot;</span>:<span class="hljs-string">&quot;New Horizons: Nasa spacecraft speeds past Pluto&quot;</span>,<br>    <span class="hljs-string">&quot;type&quot;</span>:<span class="hljs-string">&quot;story&quot;</span>,<br>    <span class="hljs-string">&quot;url&quot;</span>:<span class="hljs-string">&quot;http://www.bbc.co.uk/news/science-environment-33524589&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure>

<p>执行一个API调用，返回Hacker News上当前热门文章的ID，再查看 每篇排名靠前的文章</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter<br><span class="hljs-comment">#执行API调用并存储响应</span><br>url =  <span class="hljs-string">&#x27;https://hacker-news.firebaseio.com/v0/topstories.json&#x27;</span><br>r = requests.get(url)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Status code: &quot;</span>, r.status_code)<br><span class="hljs-comment">#处理有关每篇文章的信息</span><br>submission_ids = r.json()<br>submission_dicts = []<br><span class="hljs-keyword">for</span> submission_id <span class="hljs-keyword">in</span> submission_ids[:<span class="hljs-number">30</span>]:<br>    <span class="hljs-comment">#对于每篇文章，都执行一个API调用</span><br>    url = (<span class="hljs-string">&#x27;https://hacker-news.firebaseio.com/v0/item/&#x27;</span> + <span class="hljs-built_in">str</span>(submission_id) + <span class="hljs-string">&#x27;.json&#x27;</span>)<br>    submission_r = requests.get(url)<br>    <span class="hljs-built_in">print</span>(submission_r.status_code)<br>    response_dict = submission_r.json()<br>    submission_dict = &#123;<br>        <span class="hljs-string">&#x27;title&#x27;</span>: response_dict[<span class="hljs-string">&#x27;title&#x27;</span>],<br>        <span class="hljs-string">&#x27;link&#x27;</span>: <span class="hljs-string">&#x27;http://news.ycombinator.com/item?id=&#x27;</span> + <span class="hljs-built_in">str</span>(submission_id),<br>        <span class="hljs-string">&#x27;comments&#x27;</span>: response_dict.get(<span class="hljs-string">&#x27;descendants&#x27;</span>, <span class="hljs-number">0</span>)<br>    &#125;<br>    submission_dicts.append(submission_dict)<br>submission_dicts = <span class="hljs-built_in">sorted</span>(submission_dicts, key=itemgetter(<span class="hljs-string">&#x27;comments&#x27;</span>), reverse=<span class="hljs-literal">True</span>)<br><span class="hljs-keyword">for</span> submission_dict <span class="hljs-keyword">in</span> submission_dicts:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nTitle:&quot;</span>, submission_dict[<span class="hljs-string">&#x27;title&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Discussion link:&quot;</span>, submission_dict[<span class="hljs-string">&#x27;link&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Comments:&quot;</span>, submission_dict[<span class="hljs-string">&#x27;comments&#x27;</span>])<br><span class="hljs-comment">#output:</span><br>Status code:  <span class="hljs-number">200</span><br><span class="hljs-number">200</span><br><span class="hljs-number">200</span><br><span class="hljs-number">200</span><br>...<br>Title: Improving Firefox Responsiveness on macOS<br>Discussion link: http://news.ycombinator.com/item?<span class="hljs-built_in">id</span>=<span class="hljs-number">33152472</span><br>Comments: <span class="hljs-number">319</span><br><br>Title: U.S. Army Chooses Google Workspace<br>Discussion link: http://news.ycombinator.com/item?<span class="hljs-built_in">id</span>=<span class="hljs-number">33157558</span><br>Comments: <span class="hljs-number">273</span><br><br>Title: Ask HN: How did you stop drinking?<br>Discussion link: http://news.ycombinator.com/item?<span class="hljs-built_in">id</span>=<span class="hljs-number">33158947</span><br>Comments: <span class="hljs-number">162</span><br><br>...<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（12）生成数据【项目2 数据可视化】</title>
    <url>/2022/10/09/Python_12/</url>
    <content><![CDATA[<p>数据可视化指的是通过可视化表示来探索数据，它与数据挖掘紧密相关，而数据挖掘指的是使用代码来探索数据集的规律和关联。数据集可以是用一行代码就能表示的小型数字列表，也可以是数以G字节的数据。</p>
<h2 id="1-绘制简单的折线图"><a href="#1-绘制简单的折线图" class="headerlink" title="1.绘制简单的折线图"></a>1.绘制简单的折线图</h2><p>下面来使用matplotlib绘制一个简单的折线图，再对其进行定制，以实现信息更丰富的数据可视化。查看使用matplotlib可制作的各种图表，请访问<a href="http://matplotlib.org/">http://matplotlib.org/</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>input_values = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>]<span class="hljs-comment">#输入值</span><br>squares = [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">9</span>, <span class="hljs-number">16</span>, <span class="hljs-number">25</span>]<span class="hljs-comment">#输出值</span><br><span class="hljs-comment">#plt.plot()这个函数尝试根据这些数字绘制出有意义的图形</span><br>plt.plot(input_values, squares, linewidth=<span class="hljs-number">5</span>)<span class="hljs-comment">#线条宽度5</span><br><span class="hljs-comment">#设置图表标题，并给坐标轴加上标签</span><br>plt.title(<span class="hljs-string">&quot;Square Numbers&quot;</span>, fontsize=<span class="hljs-number">24</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Value&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Square of Value&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br><span class="hljs-comment">#设置刻度标记的大小</span><br>plt.tick_params(axis=<span class="hljs-string">&#x27;both&#x27;</span>, labelsize=<span class="hljs-number">14</span>)<br><span class="hljs-comment">#plt.show()打开matplotlib查看器，并显示绘制的图形</span><br>plt.show()<br><span class="hljs-comment">#plt.scatter()这个函数根据数字绘制一系列点</span><br><span class="hljs-comment">#s设置点的大小,c设置点的颜色，edgecolor设置点的轮廓颜色</span><br><span class="hljs-comment">#c可以通过RGB来自定颜色 c=(0, 0, 0)</span><br>plt.scatter(input_values, squares, s=<span class="hljs-number">100</span>, c=<span class="hljs-string">&#x27;red&#x27;</span>, edgecolor=<span class="hljs-string">&#x27;none&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<h3 id="1-1自动计算数据"><a href="#1-1自动计算数据" class="headerlink" title="1.1自动计算数据"></a>1.1自动计算数据</h3><p>手工计算列表要包含的值可能效率低下，需要绘制的点很多时尤其如此。可以不必手工计算包含点坐标的列表，而让Python循环来替我们完成这种计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>x_values = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1001</span>))<br><span class="hljs-comment">#使用循环来帮我们从输入映射到输出</span><br>y_values = [x**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> x_values]<br>plt.scatter(x_values, y_values, s=<span class="hljs-number">10</span>, c=<span class="hljs-string">&#x27;red&#x27;</span>, edgecolor=<span class="hljs-string">&#x27;none&#x27;</span>)<br><br>plt.title(<span class="hljs-string">&quot;Square Numbers&quot;</span>, fontsize=<span class="hljs-number">24</span>)<br>plt.xlabel(<span class="hljs-string">&quot;Value&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br>plt.ylabel(<span class="hljs-string">&quot;Square of Value&quot;</span>, fontsize=<span class="hljs-number">14</span>)<br><span class="hljs-comment">#设置每个坐标轴的取值范围 [x_min, x_max, y_min, y_max]</span><br>plt.axis([<span class="hljs-number">0</span>, <span class="hljs-number">1100</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1100000</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>

<h3 id="1-2使用颜色映射"><a href="#1-2使用颜色映射" class="headerlink" title="1.2使用颜色映射"></a>1.2使用颜色映射</h3><p>颜色映射 （colormap）是一系列颜色，它们从起始颜色渐变到结束颜色。 在可视化中，颜色映射用于突出数据的规律，例如，你可能用较浅的颜色来显示较小的值，并使用较深的颜色来显示较大的值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>x_values = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">1001</span>))<br>y_values = [x**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> x_values]<br><span class="hljs-comment">#将参数c设置成了一个y值列表，并使用参数cmap告诉pyplot使用哪个颜色映射。</span><br><span class="hljs-comment">#代码将y值较小的点显示为浅蓝色，并将y值较大的点显示为深蓝色</span><br>plt.scatter(x_values, y_values, s=<span class="hljs-number">10</span>, c=y_values, cmap=plt.cm.Blues, edgecolor=<span class="hljs-string">&#x27;none&#x27;</span>)<br><span class="hljs-comment">#绘制图表</span><br>--snip--<br></code></pre></td></tr></table></figure>

<h3 id="1-3自动保存图表"><a href="#1-3自动保存图表" class="headerlink" title="1.3自动保存图表"></a>1.3自动保存图表</h3><p>要让程序自动将图表保存到文件中，可将对<code>plt.show()</code> 的调用替换为对 <code>plt.savefig()</code> 的调用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#第一个实参设置文件名</span><br><span class="hljs-comment">#第二个实参指定将图表多余的空白区域裁剪掉</span><br>plt.savefig(<span class="hljs-string">&#x27;squares_plot.png&#x27;</span>, bbox_inches=<span class="hljs-string">&#x27;tight&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="2-随机漫步"><a href="#2-随机漫步" class="headerlink" title="2.随机漫步"></a>2.随机漫步</h2><p>随机漫步是这样行走得到的路径：每次行走都完全是随机的，没有明确的方向，结果是由一系列随机决策决定的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> choice<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RandomWalk</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;一个生成随机漫步数据的类&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_points=<span class="hljs-number">5000</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化随机漫步的属性&quot;&quot;&quot;</span><br>        self.num_points = num_points<br>        <span class="hljs-comment">#所有随机漫步都始于(0, 0)</span><br>        self.x_values = [<span class="hljs-number">0</span>]<br>        self.y_values = [<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_walk</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;计算随机漫步包含的所有点&quot;&quot;&quot;</span><br>        <span class="hljs-comment">#不断漫步，直到列表达到指定的长度</span><br>        <span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(self.x_values) &lt; self.num_points:<br>            <span class="hljs-comment">#决定前进方向以及沿这个方向前进的距离</span><br>            x_direction = choice([<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>])<br>            x_distance = choice([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>            x_step = x_direction * x_distance<br>            <br>            y_direction = choice([<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>])<br>            y_distance = choice([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br>            y_step = y_direction * y_distance<br>            <span class="hljs-comment">#拒绝原地踏步</span><br>            <span class="hljs-keyword">if</span> x_step == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> y_step == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-comment">#计算下一个点的x和y值</span><br>            next_x = self.x_values[-<span class="hljs-number">1</span>] + x_step<br>            next_y = self.y_values[-<span class="hljs-number">1</span>] + y_step<br>            <br>            self.x_values.append(next_x)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment">#from random_walk import RandomWalk</span><br><br>rw = RandomWalk(<span class="hljs-number">50000</span>)<span class="hljs-comment">#设置点数为50000</span><br>rw.fill_walk()<br>point_numbers = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(rw.num_points))<span class="hljs-comment">#获取点数</span><br><span class="hljs-comment">#设置绘图窗口尺寸</span><br><span class="hljs-comment">#figure 用于指定图表的宽度、高度、分辨率和背景色</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br><span class="hljs-comment">#隐藏坐标轴,此段代码必须位于scatter之前，并且赋值一个变量</span><br>current_axes = plt.axes()<br>current_axes.get_xaxis().set_visible(<span class="hljs-literal">False</span>)<br>current_axes.get_yaxis().set_visible(<span class="hljs-literal">False</span>)<br><br>plt.scatter(rw.x_values, rw.y_values, c=point_numbers, cmap=plt.cm.Blues, edgecolor=<span class="hljs-string">&#x27;none&#x27;</span>, s=<span class="hljs-number">15</span>)<br><span class="hljs-comment">#突出显示起点，终点</span><br>plt.scatter(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, c=<span class="hljs-string">&#x27;green&#x27;</span>, edgecolors=<span class="hljs-string">&#x27;none&#x27;</span>, s=<span class="hljs-number">100</span>)<br>plt.scatter(rw.x_values[-<span class="hljs-number">1</span>], rw.y_values[-<span class="hljs-number">1</span>], c=<span class="hljs-string">&#x27;red&#x27;</span>, edgecolors=<span class="hljs-string">&#x27;none&#x27;</span>, s=<span class="hljs-number">100</span>)<br>plt.show()<br></code></pre></td></tr></table></figure>

<h2 id="3-使用Pygal模拟掷骰子"><a href="#3-使用Pygal模拟掷骰子" class="headerlink" title="3.使用Pygal模拟掷骰子"></a>3.使用Pygal模拟掷骰子</h2><p>使用Python可视化包<code>Pygal</code>来生成<strong>可缩放的矢量图形文件</strong>。对于需要在尺寸不同的屏幕上显示的图表，这很有用，因为它们将自动缩放，以适合观看者的屏幕。如果你打算以在线方式使用图表，请考虑使用<code>Pygal</code>来生成它们，这样它们在任何设备上显示时都会很美观。</p>
<p>要了解使用<code>Pygal</code>可创建什么样的图表，请查看图表类型画廊：访问 <a href="http://www.pygal.org/">http://www.pygal.org/</a> ，单击Documentation，再单击Chart types。</p>
<h3 id="3-1掷骰子"><a href="#3-1掷骰子" class="headerlink" title="3.1掷骰子"></a>3.1掷骰子</h3><p>下面的类模拟掷一个骰子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> randint<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Die</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;表示一个骰子的类&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_sides=<span class="hljs-number">6</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;骰子默认为6面&quot;&quot;&quot;</span><br>        self.num_sides = num_sides<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">roll</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;返回一个位于1和骰子面数之间的随机值&quot;&quot;&quot;</span><br>        <span class="hljs-keyword">return</span> randint(<span class="hljs-number">1</span>, self.num_sides)<br><span class="hljs-comment">#创建一个D6</span><br>die = Die()<br><span class="hljs-comment">#掷几次骰子，并将结果存储在一个列表中</span><br>results = []<br><span class="hljs-keyword">for</span> roll_num <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>):<br>    result = die.roll()<br>    results.append(result)<br><span class="hljs-built_in">print</span>(results)<br><span class="hljs-comment">#output:[3, 5, 5, 1, 1, 6, 3, 3, 2, 6, 1, 2, ...]</span><br>frequencies = []<br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, die.num_sides+<span class="hljs-number">1</span>):<br>    frequency = results.count(value)<br>    frequencies.append(frequency)<br><span class="hljs-built_in">print</span>(frequencies)<br><span class="hljs-comment">#output:[185, 175, 160, 172, 152, 156]</span><br><span class="hljs-keyword">import</span> pygal<br><span class="hljs-comment">#对结果可视化</span><br>hist = pygal.Bar()<span class="hljs-comment">#Bar 条形图</span><br>hist.title = <span class="hljs-string">&quot;Result of rolling one D6 1000 times.&quot;</span><br>hist.x_labels = [<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>, <span class="hljs-string">&#x27;6&#x27;</span>]<br>hist.x_title = <span class="hljs-string">&quot;Result&quot;</span><br>hist.y_title = <span class="hljs-string">&quot;Frequency of Result&quot;</span><br>hist.add(<span class="hljs-string">&#x27;D6&#x27;</span>, frequencies)<span class="hljs-comment">#添加数据</span><br>hist.render_to_file(<span class="hljs-string">&#x27;die_visual.svg&#x27;</span>)<span class="hljs-comment">#保存为svg文件，可用浏览器打开</span><br></code></pre></td></tr></table></figure>

<p>掷两个骰子：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pygal<br><span class="hljs-comment"># 创建两个骰子，一个D6一个D10</span><br>die_1 = Die()<br>die_2 = Die(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># 掷骰子多次，并将结果存储到一个列表中</span><br>results = []<br><span class="hljs-keyword">for</span> roll_num <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">50000</span>):<br>    result = die_1.roll() + die_2.roll()<br>    results.append(result)<br><span class="hljs-comment">#分析结果</span><br>frequencies = []<br>max_result = die_1.num_sides + die_2.num_sides<br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, max_result+<span class="hljs-number">1</span>):<br>    frequency = results.count(value)<br>    frequencies.append(frequency)<br><span class="hljs-comment">#可视化结果</span><br>hist = pygal.Bar()<br>hist.title = <span class="hljs-string">&quot;Result of rolling two D6 dice 1000 times.&quot;</span><br>hist.x_labels = [<span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>, <span class="hljs-string">&#x27;4&#x27;</span>, <span class="hljs-string">&#x27;5&#x27;</span>, <span class="hljs-string">&#x27;6&#x27;</span>, <span class="hljs-string">&#x27;7&#x27;</span>, <span class="hljs-string">&#x27;8&#x27;</span>, <span class="hljs-string">&#x27;9&#x27;</span>, <span class="hljs-string">&#x27;10&#x27;</span>, <span class="hljs-string">&#x27;11&#x27;</span>, <span class="hljs-string">&#x27;12&#x27;</span>, <span class="hljs-string">&#x27;13&#x27;</span>, <span class="hljs-string">&#x27;14&#x27;</span>, <span class="hljs-string">&#x27;15&#x27;</span>, <span class="hljs-string">&#x27;16&#x27;</span>]<br>hist.x_title = <span class="hljs-string">&quot;Result&quot;</span><br>hist.y_title = <span class="hljs-string">&quot;Frequency of Result&quot;</span><br>hist.add(<span class="hljs-string">&#x27;D6 + D10&#x27;</span>, frequencies)<br>hist.render_to_file(<span class="hljs-string">&#x27;die_visual.svg&#x27;</span>)<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（4）操作列表</title>
    <url>/2022/07/01/Python_4/</url>
    <content><![CDATA[<p>在本章中，你将学习如何遍历整个列表、使用列表的一部分、元组。</p>
<h1 id="操作列表"><a href="#操作列表" class="headerlink" title="操作列表"></a>操作列表</h1><h2 id="1-遍历整个列表"><a href="#1-遍历整个列表" class="headerlink" title="1.遍历整个列表"></a>1.遍历整个列表</h2><p>遍历列表元素时，选择描述单个列表元素的有意义的名称会是一个不错的选择。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">magicians = [<span class="hljs-string">&#x27;alice&#x27;</span>, <span class="hljs-string">&#x27;david&#x27;</span>, <span class="hljs-string">&#x27;carolina&#x27;</span>]<br><span class="hljs-keyword">for</span> magician <span class="hljs-keyword">in</span> magicians:<br>    <span class="hljs-built_in">print</span>(magician)<br><span class="hljs-comment"># output:</span><br>alice<br>david<br>carolina<br></code></pre></td></tr></table></figure>

<h2 id="2-创建数值列表"><a href="#2-创建数值列表" class="headerlink" title="2.创建数值列表"></a>2.创建数值列表</h2><h3 id="2-1使用函数range"><a href="#2-1使用函数range" class="headerlink" title="2.1使用函数range()"></a>2.1使用函数range()</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># range() 左闭右开</span><br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">5</span>):<br>    <span class="hljs-built_in">print</span>(value)<br><span class="hljs-comment"># output</span><br><span class="hljs-number">1</span><br><span class="hljs-number">2</span><br><span class="hljs-number">3</span><br><span class="hljs-number">4</span><br><span class="hljs-comment"># range() and list 利用range构建列表</span><br>numbers = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">6</span>))<br><span class="hljs-built_in">print</span>(numbers) <span class="hljs-comment"># [1, 2, 3, 4, 5]</span><br><span class="hljs-comment"># set pace 设置range步长</span><br>even_numbers = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>,<span class="hljs-number">11</span>,<span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(even_numbers) <span class="hljs-comment"># [2, 4, 6, 8, 10]</span><br></code></pre></td></tr></table></figure>

<h3 id="2-2对数字列表进行简单的统计计算"><a href="#2-2对数字列表进行简单的统计计算" class="headerlink" title="2.2对数字列表进行简单的统计计算"></a>2.2对数字列表进行简单的统计计算</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>digits = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">0</span>]<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">min</span>(digits) <span class="hljs-comment"># 返回最小值</span><br><span class="hljs-number">0</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">max</span>(digits) <span class="hljs-comment"># 返回最大值</span><br><span class="hljs-number">9</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">sum</span>(digits) <span class="hljs-comment"># 返回元素和</span><br><span class="hljs-number">45</span><br></code></pre></td></tr></table></figure>

<h3 id="2-3列表解析"><a href="#2-3列表解析" class="headerlink" title="2.3列表解析"></a>2.3列表解析</h3><p>列表解析将for循环和创建新元素的代码合并成一行，并自动附加新元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># list comprehension 列表解析</span><br>squares = [value**<span class="hljs-number">2</span> <span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">11</span>)]<br><span class="hljs-built_in">print</span>(squares) <span class="hljs-comment"># [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]</span><br></code></pre></td></tr></table></figure>

<h2 id="3-使用列表的一部分"><a href="#3-使用列表的一部分" class="headerlink" title="3.使用列表的一部分"></a>3.使用列表的一部分</h2><h3 id="3-1切片"><a href="#3-1切片" class="headerlink" title="3.1切片"></a>3.1切片</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># slice list 左闭又开，省略左从头开始，省略右末尾结束</span><br>players = [<span class="hljs-string">&#x27;charles&#x27;</span>, <span class="hljs-string">&#x27;martina&#x27;</span>, <span class="hljs-string">&#x27;michael&#x27;</span>, <span class="hljs-string">&#x27;florence&#x27;</span>, <span class="hljs-string">&#x27;eli&#x27;</span>]<br><span class="hljs-built_in">print</span>(players[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]) <span class="hljs-comment"># [&#x27;martina&#x27;, &#x27;michael&#x27;]</span><br><span class="hljs-built_in">print</span>(players[:<span class="hljs-number">4</span>]) <span class="hljs-comment"># [&#x27;charles&#x27;, &#x27;martina&#x27;, &#x27;michael&#x27;, &#x27;florence&#x27;]</span><br><span class="hljs-built_in">print</span>(players[<span class="hljs-number">2</span>:]) <span class="hljs-comment"># [&#x27;michael&#x27;, &#x27;florence&#x27;, &#x27;eli&#x27;]</span><br><span class="hljs-built_in">print</span>(players[-<span class="hljs-number">3</span>:]) <span class="hljs-comment"># [&#x27;michael&#x27;, &#x27;florence&#x27;, &#x27;eli&#x27;]</span><br><span class="hljs-comment"># 遍历切片</span><br><span class="hljs-keyword">for</span> player <span class="hljs-keyword">in</span> players[:<span class="hljs-number">3</span>]:<br>    <span class="hljs-built_in">print</span>(player.upper())<br><span class="hljs-comment"># output</span><br>CHARLES<br>MARTINA<br>MICHAEL<br></code></pre></td></tr></table></figure>



<h3 id="3-2复制"><a href="#3-2复制" class="headerlink" title="3.2复制"></a>3.2复制</h3><p>正确的复制：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># copy list</span><br>my_foods = [<span class="hljs-string">&#x27;pizza&#x27;</span>, <span class="hljs-string">&#x27;falafel&#x27;</span>, <span class="hljs-string">&#x27;carrot cake&#x27;</span>]<br>friend_foods = my_foods[:]<br>my_foods.append(<span class="hljs-string">&#x27;cannoli&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;my_foods: &quot;</span>, my_foods)<br><span class="hljs-comment"># my_foods:  [&#x27;pizza&#x27;, &#x27;falafel&#x27;, &#x27;carrot cake&#x27;, &#x27;cannoli&#x27;]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;friend_foods: &quot;</span>, friend_foods)<br><span class="hljs-comment"># friend_foods:  [&#x27;pizza&#x27;, &#x27;falafel&#x27;, &#x27;carrot cake&#x27;]</span><br></code></pre></td></tr></table></figure>

<p>错误的复制（并没有复制列表，而是引用了同一个列表）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># not copy list</span><br>my_foods = [<span class="hljs-string">&#x27;pizza&#x27;</span>, <span class="hljs-string">&#x27;falafel&#x27;</span>, <span class="hljs-string">&#x27;carrot cake&#x27;</span>]<br>friend_foods = my_foods<br>my_foods.append(<span class="hljs-string">&#x27;cannoli&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;my_foods: &quot;</span>, my_foods)<br><span class="hljs-comment"># my_foods:  [&#x27;pizza&#x27;, &#x27;falafel&#x27;, &#x27;carrot cake&#x27;, &#x27;cannoli&#x27;]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;friend_foods: &quot;</span>, friend_foods)<br><span class="hljs-comment"># friend_foods:  [&#x27;pizza&#x27;, &#x27;falafel&#x27;, &#x27;carrot cake&#x27;, &#x27;cannoli&#x27;]</span><br></code></pre></td></tr></table></figure>

<p>可以看到直接赋值，即使只是修改my_foods，friend_foods仍会跟my_foods保持一致。</p>
<h2 id="4-元组"><a href="#4-元组" class="headerlink" title="4.元组"></a>4.元组</h2><p>列表非常适合用于存储在程序运行期间可能变化的数据集。但有时候需要存储不能改变的元素，元组可以满足这种需求，不可变的列表称为元组。</p>
<ul>
<li>除了不支持修改，其他与列表相同</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># tuple 元组</span><br>dimensions = (<span class="hljs-number">200</span>, <span class="hljs-number">50</span>)<br><span class="hljs-built_in">print</span>(dimensions[<span class="hljs-number">0</span>]) <span class="hljs-comment"># 200</span><br><span class="hljs-built_in">print</span>(dimensions[<span class="hljs-number">1</span>]) <span class="hljs-comment"># 50</span><br><span class="hljs-comment"># dimensions[0] = 10 报错，元组不可变</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Original &quot;</span>, dimensions) <span class="hljs-comment"># Original  (200, 50)</span><br><span class="hljs-comment"># 可赋值</span><br>dimensions = (<span class="hljs-number">400</span>, <span class="hljs-number">100</span>, <span class="hljs-number">50</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Modified &quot;</span>, dimensions) <span class="hljs-comment"># Modified  (400, 100, 50)</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（3）列表简介</title>
    <url>/2022/06/30/Python_3/</url>
    <content><![CDATA[<p>本章和下一章，将学习列表是什么以及如何使用列表元素。列表让你能够在一个地方存储成组的信息。</p>
<h2 id="认识列表"><a href="#认识列表" class="headerlink" title="认识列表"></a>认识列表</h2><p>列表由一系列按特定顺序排列的元素组成。鉴于列表通常包含多个元素，给列表指定一个表示复数的名称是个不错的主意。</p>
<p>Python中，用 [ ] 来表示列表，用逗号分隔其中的元素。示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">bicycles = [<span class="hljs-string">&#x27;trek&#x27;</span>, <span class="hljs-string">&#x27;cannondale&#x27;</span>, <span class="hljs-string">&#x27;redline&#x27;</span>, <span class="hljs-string">&#x27;specialized&#x27;</span>]<br><span class="hljs-built_in">print</span>(bicycles) <span class="hljs-comment"># [&#x27;trek&#x27;, &#x27;cannondale&#x27;, &#x27;redline&#x27;, &#x27;specialized&#x27;]</span><br></code></pre></td></tr></table></figure>

<h3 id="1-访问列表元素"><a href="#1-访问列表元素" class="headerlink" title="1.访问列表元素"></a>1.访问列表元素</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">bicycles = [<span class="hljs-string">&#x27;trek&#x27;</span>, <span class="hljs-string">&#x27;cannondale&#x27;</span>, <span class="hljs-string">&#x27;redline&#x27;</span>, <span class="hljs-string">&#x27;specialized&#x27;</span>]<br><span class="hljs-comment"># access list element 访问第n个元素（从0开始）</span><br><span class="hljs-built_in">print</span>(bicycles[<span class="hljs-number">0</span>]) <span class="hljs-comment"># trek</span><br><span class="hljs-comment"># access the n element from bottom of the list 访问倒数第n个元素（从-1开始）</span><br><span class="hljs-built_in">print</span>(bicycles[-<span class="hljs-number">1</span>]) <span class="hljs-comment"># specialized</span><br></code></pre></td></tr></table></figure>

<h3 id="2-修改、添加和删除元素"><a href="#2-修改、添加和删除元素" class="headerlink" title="2.修改、添加和删除元素"></a>2.修改、添加和删除元素</h3><p>修改元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">motorcycles = [<span class="hljs-string">&#x27;honda&#x27;</span>, <span class="hljs-string">&#x27;yamaha&#x27;</span>, <span class="hljs-string">&#x27;suzuki&#x27;</span>]<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;honda&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;]</span><br><span class="hljs-comment"># change element 修改元素</span><br>motorcycles[<span class="hljs-number">0</span>] = <span class="hljs-string">&#x27;ducati&#x27;</span><br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;ducati&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;]</span><br></code></pre></td></tr></table></figure>
<p>添加元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add element at the end 在末尾添加元素</span><br>motorcycles.append(<span class="hljs-string">&#x27;honda&#x27;</span>)<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;ducati&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;, &#x27;honda&#x27;]</span><br><span class="hljs-comment"># insert element 在指定位置添加元素</span><br>motorcycles.insert(<span class="hljs-number">0</span>,<span class="hljs-string">&#x27;ducatipro&#x27;</span>)<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;ducatipro&#x27;, &#x27;ducati&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;, &#x27;honda&#x27;]</span><br></code></pre></td></tr></table></figure>
<p>删除元素：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># delete element 删除指定位置元素</span><br><span class="hljs-keyword">del</span> motorcycles[<span class="hljs-number">0</span>]<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;ducati&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;, &#x27;honda&#x27;]</span><br><span class="hljs-comment"># pop element 获取指定位置元素并在列表中删除（默认删除表尾元素）</span><br>poped_motorcycle = motorcycles.pop()<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;ducati&#x27;, &#x27;yamaha&#x27;, &#x27;suzuki&#x27;]</span><br><span class="hljs-built_in">print</span>(poped_motorcycle) <span class="hljs-comment"># honda</span><br>poped_motorcycle = motorcycles.pop(<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;yamaha&#x27;, &#x27;suzuki&#x27;]</span><br><span class="hljs-built_in">print</span>(poped_motorcycle) <span class="hljs-comment"># ducati</span><br><span class="hljs-comment"># delete accroding value 根据值删除元素</span><br><span class="hljs-comment"># notice: remove only delete the first same element 注意：remove只删除第一个相同的元素</span><br>too_expensive = <span class="hljs-string">&#x27;yamaha&#x27;</span><br>motorcycles.remove(too_expensive)<br><span class="hljs-built_in">print</span>(motorcycles) <span class="hljs-comment"># [&#x27;suzuki&#x27;]</span><br><span class="hljs-built_in">print</span>(too_expensive) <span class="hljs-comment"># yamaga</span><br></code></pre></td></tr></table></figure>

<h3 id="3-组织列表"><a href="#3-组织列表" class="headerlink" title="3.组织列表"></a>3.组织列表</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">cars = [<span class="hljs-string">&#x27;bmw&#x27;</span>, <span class="hljs-string">&#x27;audi&#x27;</span>, <span class="hljs-string">&#x27;toyota&#x27;</span>, <span class="hljs-string">&#x27;subaru&#x27;</span>]<br><span class="hljs-comment"># forever sort list 永久排序</span><br>cars.sort()<br><span class="hljs-built_in">print</span>(cars) <span class="hljs-comment"># [&#x27;audi&#x27;, &#x27;bmw&#x27;, &#x27;subaru&#x27;, &#x27;toyota&#x27;]</span><br><span class="hljs-comment"># reverse sort list 逆序排序</span><br>cars.sort(reverse=<span class="hljs-literal">True</span>)<br><span class="hljs-built_in">print</span>(cars) <span class="hljs-comment"># [&#x27;toyota&#x27;, &#x27;subaru&#x27;, &#x27;bmw&#x27;, &#x27;audi&#x27;]</span><br><span class="hljs-comment"># temporary sort list(reverse same) 临时排序（逆序同样适用）</span><br><span class="hljs-built_in">print</span>(cars) <span class="hljs-comment"># [&#x27;toyota&#x27;, &#x27;subaru&#x27;, &#x27;bmw&#x27;, &#x27;audi&#x27;]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(cars)) <span class="hljs-comment"># [&#x27;audi&#x27;, &#x27;bmw&#x27;, &#x27;subaru&#x27;, &#x27;toyota&#x27;]</span><br><span class="hljs-comment"># reverse list 列表反转</span><br>cars.reverse()<br><span class="hljs-built_in">print</span>(cars) <span class="hljs-comment"># [&#x27;audi&#x27;, &#x27;bmw&#x27;, &#x27;subaru&#x27;, &#x27;toyota&#x27;]</span><br><span class="hljs-comment"># get list&#x27;s length</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(cars)) <span class="hljs-comment"># 4</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（5）if 语句</title>
    <url>/2022/07/01/Python_5/</url>
    <content><![CDATA[<p>本章中，你将学习条件测试，学习简单的if语句，以及创建一系列复杂的if语句来确定当前到底处于什么情形。接下来将if应用于列表，以编写for循环。</p>
<h1 id="if语句"><a href="#if语句" class="headerlink" title="if语句"></a>if语句</h1><p>一个简单实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">cars = [<span class="hljs-string">&#x27;audi&#x27;</span>, <span class="hljs-string">&#x27;bmw&#x27;</span>, <span class="hljs-string">&#x27;subaru&#x27;</span>, <span class="hljs-string">&#x27;toyota&#x27;</span>]<br><span class="hljs-keyword">for</span> car <span class="hljs-keyword">in</span> cars:<br>    <span class="hljs-keyword">if</span> car == <span class="hljs-string">&#x27;bmw&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(car.upper())<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(car.title())<br><span class="hljs-comment">#output</span><br>Audi<br>BMW<br>Subaru<br>Toyota<br></code></pre></td></tr></table></figure>

<h2 id="1-条件测试"><a href="#1-条件测试" class="headerlink" title="1.条件测试"></a>1.条件测试</h2><ul>
<li>等于（&#x3D;&#x3D;），大于（&gt;），小于（&lt;）， 小于等于（&lt;&#x3D;），大于等于（&gt;&#x3D;）</li>
<li>and、or</li>
<li>检查特定值是否包含在列表中（in）、是否不包含在列表中（not in）</li>
<li>bool表达式（True、False）</li>
</ul>
<h2 id="2-使用if语句处理列表"><a href="#2-使用if语句处理列表" class="headerlink" title="2.使用if语句处理列表"></a>2.使用if语句处理列表</h2><p>以披萨店制作披萨为例，每添加一种配料都打印一条消息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># usr if check list</span><br>requested_toppings = [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]<br><span class="hljs-keyword">for</span> requested_topping <span class="hljs-keyword">in</span> requested_toppings:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Adding &quot;</span> + requested_topping + <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nFinished making your pizza!&quot;</span>)<br><span class="hljs-comment">#output</span><br>Adding mushrooms.<br>Adding green peppers.<br>Adding extra cheese.<br><br>Finished making your pizza!<br></code></pre></td></tr></table></figure>

<p>青椒用光了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">requested_toppings = [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]<br><span class="hljs-keyword">for</span> requested_topping <span class="hljs-keyword">in</span> requested_toppings:<br>    <span class="hljs-keyword">if</span> requested_topping == <span class="hljs-string">&#x27;green peppers&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sorry, we are out of green peppers right now.&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Adding &quot;</span> + requested_topping + <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nFinished making your pizza!&quot;</span>)<br><span class="hljs-comment">#output</span><br>Adding mushrooms.<br>Sorry, we are out of green peppers right now.<br>Adding extra cheese.<br><br>Finished making your pizza!<br></code></pre></td></tr></table></figure>

<p>判断顾客点的配料列表是否为空：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">requested_toppings = []<br><span class="hljs-keyword">if</span> requested_toppings:<br>    <span class="hljs-keyword">for</span> requested_topping <span class="hljs-keyword">in</span> requested_toppings:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Adding &quot;</span> + requested_topping + <span class="hljs-string">&quot;.&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nFinished making your pizza!&quot;</span>)<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Are you sure you want a plain pizza?&quot;</span>)<br><span class="hljs-comment">#output:</span><br>Are you sure you want a plain pizza?<br></code></pre></td></tr></table></figure>

<p>顾客的要求往往五花八门，下面定义两个列表。第一个包含披萨店供应的配料，第二个包含顾客点的配料。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">requested_toppings = [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;french fires&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]<br>available_toppings = [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;olives&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>,<br>                      <span class="hljs-string">&#x27;pepperoni&#x27;</span>, <span class="hljs-string">&#x27;pineapple&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]<br><span class="hljs-keyword">for</span> requested_topping <span class="hljs-keyword">in</span> requested_toppings:<br>    <span class="hljs-keyword">if</span> requested_topping <span class="hljs-keyword">in</span> available_toppings:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Adding &quot;</span> + requested_topping + <span class="hljs-string">&quot;.&quot;</span>)<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Sorry, we donot have &quot;</span> + requested_topping + <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nFinished making your pizza!&quot;</span>)<br><span class="hljs-comment">#output:</span><br>Adding mushrooms.<br>Sorry, we donot have french fires.<br>Adding extra cheese.<br><br>Finished making your pizza!<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（2）变量与简单的数据类型</title>
    <url>/2022/06/30/Python_2/</url>
    <content><![CDATA[<p>在本章中，主要学习Python中可使用的各种数据，以及如何存储、使用和访问这些数据。</p>
<h2 id="1-Hello-World"><a href="#1-Hello-World" class="headerlink" title="1.Hello-World"></a>1.Hello-World</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">message = <span class="hljs-string">&quot;Hello World!&quot;</span><br><span class="hljs-built_in">print</span>(message)<br></code></pre></td></tr></table></figure>

<h2 id="2-变量"><a href="#2-变量" class="headerlink" title="2.变量"></a>2.变量</h2><p>命名规则：</p>
<ul>
<li>变量名只能包含字母数字和下划线，且不能以数据打头。</li>
<li>变量名不能包含空格。</li>
<li>变量名不能与关键字或函数名相同。</li>
<li>变量名应简短且具有描述性</li>
<li>慎用小写字母 l 和大写字母 O，因为会被错认为数字1和0</li>
</ul>
<h2 id="3-字符串"><a href="#3-字符串" class="headerlink" title="3.字符串"></a>3.字符串</h2><p>Python中，单引号或双引号括起来的是字符串，这种灵活性可以使程序员在字符串中包含引号和撇号。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># var</span><br>message = <span class="hljs-string">&quot;Hello Python world!&quot;</span><br><span class="hljs-built_in">print</span>(message)<br><span class="hljs-comment"># change the case of string 改变大小写</span><br>name = <span class="hljs-string">&quot;ada lovelace&quot;</span><br><span class="hljs-built_in">print</span>(name.title()) <span class="hljs-comment"># Title 标题格式</span><br><span class="hljs-built_in">print</span>(name.upper()) <span class="hljs-comment"># upper case 大写</span><br><span class="hljs-built_in">print</span>(name.lower()) <span class="hljs-comment"># lower case 小写</span><br><span class="hljs-comment"># merge string 合并字符串</span><br>first_name = <span class="hljs-string">&quot;ada&quot;</span><br>last_name = <span class="hljs-string">&quot;lovelace&quot;</span><br>full_name = first_name + <span class="hljs-string">&quot; &quot;</span> + last_name<br><span class="hljs-built_in">print</span>(full_name)<br><span class="hljs-comment"># add whitespace \n \t 添加空白</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\tPython&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;languages:\n\tPython\n\tC\n\tJavaScript&quot;</span>)<br><span class="hljs-comment"># delete block 删除空白</span><br>language = <span class="hljs-string">&quot;  Python  &quot;</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> + language + <span class="hljs-string">&quot;-&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> + language.rstrip() + <span class="hljs-string">&quot;-&quot;</span>) <span class="hljs-comment"># delete the whitespace at the right</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> + language.lstrip() + <span class="hljs-string">&quot;-&quot;</span>)  <span class="hljs-comment"># delete the whitespace at the left</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> + language.strip() + <span class="hljs-string">&quot;-&quot;</span>)  <span class="hljs-comment"># delete the whitespace at the both</span><br></code></pre></td></tr></table></figure>

<p>Output:</p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><code class="hljs ldif">Hello Python world!<br>Ada Lovelace<br>ADA LOVELACE<br>ada lovelace<br>ada lovelace<br>	Python<br><span class="hljs-attribute">languages</span>:<br>	Python<br>	C<br>	JavaScript<br><span class="hljs-literal">-</span>  Python  -<br><span class="hljs-literal">-</span>  Python-<br><span class="hljs-literal">-</span>Python  -<br><span class="hljs-literal">-</span>Python-<br></code></pre></td></tr></table></figure>

<h2 id="4-数字"><a href="#4-数字" class="headerlink" title="4.数字"></a>4.数字</h2><h3 id="4-1整数"><a href="#4-1整数" class="headerlink" title="4.1整数"></a>4.1整数</h3><p>在Python中，整数可执行加（+）减（-）乘（*）除（&#x2F;）乘方（**）整除（&#x2F;&#x2F;）取模（%），并支持运算次序，并支持括号改变运算次序。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span> + <span class="hljs-number">3</span><br><span class="hljs-number">5</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span> - <span class="hljs-number">3</span><br>-<span class="hljs-number">1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span> * <span class="hljs-number">3</span><br><span class="hljs-number">6</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span> / <span class="hljs-number">3</span><br><span class="hljs-number">0.6666666666666666</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">3</span> // <span class="hljs-number">2</span><br><span class="hljs-number">1</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span> % <span class="hljs-number">3</span><br><span class="hljs-number">2</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">2</span>**<span class="hljs-number">3</span><br><span class="hljs-number">8</span><br></code></pre></td></tr></table></figure>

<h3 id="4-2浮点数"><a href="#4-2浮点数" class="headerlink" title="4.2浮点数"></a>4.2浮点数</h3><p>需要注意的是，运算结果包含的浮点数的小数位数可能是不确定的。后续会学习处理多余小数位的方式。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">0.2</span> + <span class="hljs-number">0.1</span><br><span class="hljs-number">0.30000000000000004</span><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-number">3</span> * <span class="hljs-number">0.1</span><br><span class="hljs-number">0.30000000000000004</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（6）字典</title>
    <url>/2022/07/01/Python_6/</url>
    <content><![CDATA[<p>本章中，你将学习如何访问和修改字典的信息。并且演示如何遍历字典中的数据。另外，还将学习存储字典的列表、存储列表的字典和存储字典的字典。</p>
<h2 id="1-一个简单的字典"><a href="#1-一个简单的字典" class="headerlink" title="1.一个简单的字典"></a>1.一个简单的字典</h2><p>在Python中，字典是一系列键值对。每个键都与一个值相关联，你可以使用键来访问与之相关联的值。事实上，可将任何Python对象用作字典中中的值。</p>
<p>字典用放在花括号 { } 中的一系列键值表示。</p>
<p>我们来设置一些外星人，设置一个简单的字典，存储特定外星人的信息：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">alien_0 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;points&#x27;</span>: <span class="hljs-number">5</span>&#125;<br><span class="hljs-built_in">print</span>(alien_0[<span class="hljs-string">&#x27;color&#x27;</span>]) <span class="hljs-comment"># green</span><br><span class="hljs-built_in">print</span>(alien_0[<span class="hljs-string">&#x27;points&#x27;</span>]) <span class="hljs-comment"># 5</span><br></code></pre></td></tr></table></figure>

<h2 id="2-使用字典"><a href="#2-使用字典" class="headerlink" title="2.使用字典"></a>2.使用字典</h2><h3 id="2-1添加键值对："><a href="#2-1添加键值对：" class="headerlink" title="2.1添加键值对："></a>2.1添加键值对：</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># add key-calue </span><br>alien_0 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;points&#x27;</span>: <span class="hljs-number">5</span>&#125;<br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;points&#x27;: 5&#125;</span><br>alien_0[<span class="hljs-string">&#x27;x_position&#x27;</span>] = <span class="hljs-number">0</span><br>alien_0[<span class="hljs-string">&#x27;y_position&#x27;</span>] = <span class="hljs-number">25</span><br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;points&#x27;: 5, &#x27;x_position&#x27;: 0, &#x27;y_position&#x27;: 25&#125;</span><br></code></pre></td></tr></table></figure>

<h3 id="2-2修改字典中的值"><a href="#2-2修改字典中的值" class="headerlink" title="2.2修改字典中的值"></a>2.2修改字典中的值</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># change value</span><br>alien_0 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;points&#x27;</span>: <span class="hljs-number">5</span>&#125;<br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;points&#x27;: 5&#125;</span><br>alien_0[<span class="hljs-string">&#x27;color&#x27;</span>] = <span class="hljs-string">&#x27;yellow&#x27;</span><br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;yellow&#x27;, &#x27;points&#x27;: 5&#125;</span><br></code></pre></td></tr></table></figure>

<h3 id="2-3删除键值对："><a href="#2-3删除键值对：" class="headerlink" title="2.3删除键值对："></a>2.3删除键值对：</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># delete key-value</span><br>alien_0 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;points&#x27;</span>: <span class="hljs-number">5</span>&#125;<br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;green&#x27;, &#x27;points&#x27;: 5&#125;</span><br><span class="hljs-keyword">del</span> alien_0[<span class="hljs-string">&#x27;points&#x27;</span>]<br><span class="hljs-built_in">print</span>(alien_0) <span class="hljs-comment"># &#123;&#x27;color&#x27;: &#x27;green&#x27;&#125;</span><br></code></pre></td></tr></table></figure>

<h2 id="3-遍历字典"><a href="#3-遍历字典" class="headerlink" title="3.遍历字典"></a>3.遍历字典</h2><h3 id="3-1遍历所有键值对"><a href="#3-1遍历所有键值对" class="headerlink" title="3.1遍历所有键值对"></a>3.1遍历所有键值对</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># for</span><br>user_0 = &#123;<br>    <span class="hljs-string">&#x27;username&#x27;</span>: <span class="hljs-string">&#x27;efermi&#x27;</span>,<br>    <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;enrico&#x27;</span>,<br>    <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;fermi&#x27;</span><br>&#125;<br><span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> user_0.items():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;key: &quot;</span> + key + <span class="hljs-string">&quot; | value: &quot;</span> + value)<br><span class="hljs-comment">#output:</span><br>key: username | value: efermi<br>key: first | value: enrico<br>key: last | value: fermi<br></code></pre></td></tr></table></figure>

<h3 id="3-2遍历所有键"><a href="#3-2遍历所有键" class="headerlink" title="3.2遍历所有键"></a>3.2遍历所有键</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">user_0 = &#123;<br>    <span class="hljs-string">&#x27;username&#x27;</span>: <span class="hljs-string">&#x27;efermi&#x27;</span>,<br>    <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;enrico&#x27;</span>,<br>    <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;fermi&#x27;</span><br>&#125;<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> user_0.keys():<br>    <span class="hljs-built_in">print</span>(key.title())<br><span class="hljs-comment">#output:</span><br>Username<br>First<br>Last<br></code></pre></td></tr></table></figure>

<h3 id="3-3按顺序遍历所有键"><a href="#3-3按顺序遍历所有键" class="headerlink" title="3.3按顺序遍历所有键"></a>3.3按顺序遍历所有键</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">user_0 = &#123;<br>    <span class="hljs-string">&#x27;username&#x27;</span>: <span class="hljs-string">&#x27;efermi&#x27;</span>,<br>    <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;enrico&#x27;</span>,<br>    <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;fermi&#x27;</span><br>&#125;<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> <span class="hljs-built_in">sorted</span>(user_0.keys()):<br>    <span class="hljs-built_in">print</span>(key.title())<br><span class="hljs-comment">#output:</span><br>First<br>Last<br>Username<br></code></pre></td></tr></table></figure>

<h3 id="3-4遍历所有值"><a href="#3-4遍历所有值" class="headerlink" title="3.4遍历所有值"></a>3.4遍历所有值</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">user_0 = &#123;<br>    <span class="hljs-string">&#x27;username&#x27;</span>: <span class="hljs-string">&#x27;efermi&#x27;</span>,<br>    <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;enrico&#x27;</span>,<br>    <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;fermi&#x27;</span><br>&#125;<br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> user_0.values():<br>    <span class="hljs-built_in">print</span>(value.title())<br><span class="hljs-comment">#output:</span><br>Efermi<br>Enrico<br>Fermi<br><span class="hljs-comment">#use set drop same value 删除重复元素</span><br>user_0[<span class="hljs-string">&#x27;middle&#x27;</span>] = <span class="hljs-string">&#x27;fermi&#x27;</span><br><span class="hljs-keyword">for</span> value <span class="hljs-keyword">in</span> <span class="hljs-built_in">set</span>(user_0.values()):<br>    <span class="hljs-built_in">print</span>(value.title())<br><span class="hljs-comment">#output:</span><br>Efermi<br>Enrico<br>Fermi<br></code></pre></td></tr></table></figure>

<h2 id="4-嵌套"><a href="#4-嵌套" class="headerlink" title="4.嵌套"></a>4.嵌套</h2><h3 id="4-1字典列表"><a href="#4-1字典列表" class="headerlink" title="4.1字典列表"></a>4.1字典列表</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># dictionary list</span><br>alien_0 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">5</span>&#125;<br>alien_1 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;yellow&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">10</span>&#125;<br>alien_2 = &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">15</span>&#125;<br><br>aliens = [alien_0, alien_1, alien_2]<br><span class="hljs-built_in">print</span>(aliens)<br><span class="hljs-comment">#output:</span><br>[&#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;green&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">5</span>&#125;, &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;yellow&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">10</span>&#125;, &#123;<span class="hljs-string">&#x27;color&#x27;</span>: <span class="hljs-string">&#x27;red&#x27;</span>, <span class="hljs-string">&#x27;point&#x27;</span>: <span class="hljs-number">15</span>&#125;]<br></code></pre></td></tr></table></figure>

<h3 id="4-2在字典中存储列表"><a href="#4-2在字典中存储列表" class="headerlink" title="4.2在字典中存储列表"></a>4.2在字典中存储列表</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># list in dictionary</span><br>pizza = &#123;<br>    <span class="hljs-string">&#x27;crust&#x27;</span>: <span class="hljs-string">&#x27;thick&#x27;</span>,<br>    <span class="hljs-string">&#x27;toppings&#x27;</span>: [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]<br>&#125;<br><span class="hljs-built_in">print</span>(pizza)<br><span class="hljs-comment">#output:</span><br>&#123;<span class="hljs-string">&#x27;crust&#x27;</span>: <span class="hljs-string">&#x27;thick&#x27;</span>, <span class="hljs-string">&#x27;toppings&#x27;</span>: [<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>]&#125;<br></code></pre></td></tr></table></figure>

<h3 id="4-3在字典中存储字典"><a href="#4-3在字典中存储字典" class="headerlink" title="4.3在字典中存储字典"></a>4.3在字典中存储字典</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># dictionary in dictionary</span><br>users = &#123;<br>    <span class="hljs-string">&#x27;aeinstein&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;albert&#x27;</span>,<br>        <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;einstein&#x27;</span>,<br>        <span class="hljs-string">&#x27;location&#x27;</span>: <span class="hljs-string">&#x27;princeton&#x27;</span><br>    &#125;,<br>    <span class="hljs-string">&#x27;mcurie&#x27;</span>: &#123;<br>        <span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;marie&#x27;</span>,<br>        <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;curie&#x27;</span>,<br>        <span class="hljs-string">&#x27;location&#x27;</span>: <span class="hljs-string">&#x27;paris&#x27;</span><br>    &#125;<br>&#125;<br><span class="hljs-keyword">for</span> username, user_info <span class="hljs-keyword">in</span> users.items():<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;username: &quot;</span> + username)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\tfullname: &quot;</span> + user_info[<span class="hljs-string">&#x27;first&#x27;</span>] + <span class="hljs-string">&quot; &quot;</span> + user_info[<span class="hljs-string">&#x27;last&#x27;</span>])<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\tlocation: &quot;</span> + user_info[<span class="hljs-string">&#x27;location&#x27;</span>])<br><span class="hljs-comment">#output:</span><br>username: aeinstein<br>	fullname: albert einstein<br>	location: princeton<br>username: mcurie<br>	fullname: marie curie<br>	location: paris<br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（8）函数</title>
    <url>/2022/07/03/Python_8/</url>
    <content><![CDATA[<p>在本章中，你将学习编写函数。函数是带名字的代码块，用于完成具体的工作。你还会学习向函数传递信息的方式，学习如何将函数存储在被称为模块的独立文件中，让主程序文件的组织更为有序。</p>
<h2 id="1-定义函数"><a href="#1-定义函数" class="headerlink" title="1.定义函数"></a>1.定义函数</h2><p>简单的示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet_user</span>():<br>    <span class="hljs-string">&#x27;&#x27;&#x27;say hello&#x27;&#x27;&#x27;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello!&quot;</span>)<br><span class="hljs-comment"># use function</span><br>greet_user()<br><span class="hljs-comment"># output:</span><br>Hello!<br></code></pre></td></tr></table></figure>

<h2 id="2-向函数传递信息"><a href="#2-向函数传递信息" class="headerlink" title="2.向函数传递信息"></a>2.向函数传递信息</h2><p>位置实参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet_user</span>(<span class="hljs-params">username</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;say hello&#x27;&#x27;&#x27;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello, &quot;</span> + username.title() + <span class="hljs-string">&quot;!&quot;</span>)<br><span class="hljs-comment"># use function</span><br>greet_user(<span class="hljs-string">&#x27;hesse&#x27;</span>)<br><span class="hljs-comment"># output:</span><br>Hello, Hesse!<br></code></pre></td></tr></table></figure>

<p>关键字实参：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet_user</span>(<span class="hljs-params">username</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;say hello&#x27;&#x27;&#x27;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello, &quot;</span> + username.title() + <span class="hljs-string">&quot;!&quot;</span>)<br><span class="hljs-comment"># use function</span><br>greet_user(username=<span class="hljs-string">&#x27;hesse&#x27;</span>)<br><span class="hljs-comment"># output:</span><br>Hello, Hesse!<br></code></pre></td></tr></table></figure>

<p>参数默认值：（若无默认值，则必须进行参数传递）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greet_user</span>(<span class="hljs-params">username=<span class="hljs-string">&#x27;tom&#x27;</span></span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;say hello&#x27;&#x27;&#x27;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Hello, &quot;</span> + username.title() + <span class="hljs-string">&quot;!&quot;</span>)<br><span class="hljs-comment"># use function</span><br>greet_user(username=<span class="hljs-string">&#x27;hesse&#x27;</span>)<br>greet_user()<br><span class="hljs-comment"># output:</span><br>Hello, Hesse!<br>Hello, Tom!<br></code></pre></td></tr></table></figure>

<h2 id="3-函数返回值"><a href="#3-函数返回值" class="headerlink" title="3.函数返回值"></a>3.函数返回值</h2><h3 id="3-1返回简单值"><a href="#3-1返回简单值" class="headerlink" title="3.1返回简单值"></a>3.1返回简单值</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_full_name</span>(<span class="hljs-params">first_name, last_name</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;return full name&#x27;&#x27;&#x27;</span><br>    full_name = first_name + <span class="hljs-string">&#x27; &#x27;</span> + last_name<br>    <span class="hljs-keyword">return</span> full_name.title()<br><span class="hljs-comment"># use function</span><br>musician = get_full_name(<span class="hljs-string">&#x27;jimi&#x27;</span>, <span class="hljs-string">&#x27;hendrix&#x27;</span>)<br><span class="hljs-built_in">print</span>(musician)<br><span class="hljs-comment"># output:</span><br>Jimi Hendrix<br></code></pre></td></tr></table></figure>

<h3 id="3-2返回字典"><a href="#3-2返回字典" class="headerlink" title="3.2返回字典"></a>3.2返回字典</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_person</span>(<span class="hljs-params">first_name, last_name</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;return a person dictionary&#x27;&#x27;&#x27;</span><br>    person = &#123;<span class="hljs-string">&#x27;first&#x27;</span>: first_name, <span class="hljs-string">&#x27;last&#x27;</span>: last_name&#125;<br>    <span class="hljs-keyword">return</span> person<br><span class="hljs-comment"># use function</span><br>musician = build_person(<span class="hljs-string">&#x27;jimi&#x27;</span>, <span class="hljs-string">&#x27;hendrix&#x27;</span>)<br><span class="hljs-built_in">print</span>(musician)<br><span class="hljs-comment"># output:</span><br>&#123;<span class="hljs-string">&#x27;first&#x27;</span>: <span class="hljs-string">&#x27;jimi&#x27;</span>, <span class="hljs-string">&#x27;last&#x27;</span>: <span class="hljs-string">&#x27;hendrix&#x27;</span>&#125;<br></code></pre></td></tr></table></figure>

<h2 id="4-传递列表"><a href="#4-传递列表" class="headerlink" title="4.传递列表"></a>4.传递列表</h2><p>你经常会发现，向函数传递列表很有用。</p>
<h3 id="4-1简单使用"><a href="#4-1简单使用" class="headerlink" title="4.1简单使用"></a>4.1简单使用</h3><p>将列表传递给函数后，函数就能直接访问其内容。假设有一个用户列表，我们要问候其中的每位用户。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">greer_users</span>(<span class="hljs-params">names</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;greet to everyone in names&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> names:<br>        msg = <span class="hljs-string">&quot;Hello, &quot;</span> + name.title() + <span class="hljs-string">&quot;!&quot;</span><br>        <span class="hljs-built_in">print</span>(msg)<br><span class="hljs-comment"># use function</span><br>usernames = [<span class="hljs-string">&#x27;hannah&#x27;</span>, <span class="hljs-string">&#x27;ty&#x27;</span>, <span class="hljs-string">&#x27;margot&#x27;</span>]<br>greer_users(usernames)<br><span class="hljs-comment"># output:</span><br>Hello, Hannah!<br>Hello, Ty!<br>Hello, Margot!<br></code></pre></td></tr></table></figure>

<h3 id="4-2在函数中修改列表"><a href="#4-2在函数中修改列表" class="headerlink" title="4.2在函数中修改列表"></a>4.2在函数中修改列表</h3><p>将列表传递给函数后，函数就可对其进行修改。在函数中对这个列表所做的任何修改都是永久性的，这让你能够高效的处理大量的数据。（形参命名只是引用，即使实参与形参的名称不同，但都是在同一个列表上操作）</p>
<p>当不想要函数操作后修改列表时，只需利用 list[ : ] 复制一份列表传递给函数即可。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># change list in function 在函数中修改列表</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">print_models</span>(<span class="hljs-params">un_designs, com_models</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    print every design in un_designs</span><br><span class="hljs-string">    then put it in com_models</span><br><span class="hljs-string">    打印所有未打印列表的设计，并将他们放到已完成列表</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">while</span> unprinted_designs:<br>        current_design = un_designs.pop()<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Printing model: &quot;</span> + current_design)<br>        com_models.append(current_design)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">show_completed_models</span>(<span class="hljs-params">com_models</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;show completed_models 显示已完成列表&#x27;&#x27;&#x27;</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;\nThe following models have been printed:&quot;</span>)<br>    <span class="hljs-keyword">for</span> completed_model <span class="hljs-keyword">in</span> completed_models:<br>        <span class="hljs-built_in">print</span>(completed_model)<br><span class="hljs-comment"># define list</span><br>unprinted_designs = [<span class="hljs-string">&#x27;iphone case&#x27;</span>, <span class="hljs-string">&#x27;robot pendant&#x27;</span>, <span class="hljs-string">&#x27;dodecahedron&#x27;</span>]<br>completed_models = []<br><span class="hljs-comment"># use function</span><br>print_models(unprinted_designs, completed_models)<br>show_completed_models(completed_models)<br><span class="hljs-comment"># output:</span><br>Printing model: dodecahedron<br>Printing model: robot pendant<br>Printing model: iphone case<br><br>The following models have been printed:<br>dodecahedron<br>robot pendant<br>iphone case<br></code></pre></td></tr></table></figure>

<h2 id="5-传递任意数量的实参"><a href="#5-传递任意数量的实参" class="headerlink" title="5.传递任意数量的实参"></a>5.传递任意数量的实参</h2><p>有时候，你预先不知道函数需要接受多少个实参，好在Python允许函数从调用语句中收集任意数量的实参。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_pizza</span>(<span class="hljs-params">*toopings</span>):<br>    <span class="hljs-built_in">print</span>(toopings)<br><span class="hljs-comment"># use function</span><br>make_pizza(<span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>make_pizza(<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br><span class="hljs-comment"># output:</span><br>(<span class="hljs-string">&#x27;pepperoni&#x27;</span>,)<br>(<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>形参名 *toppings 中的星号让Python创建一个名为toppings的空元组，并将收到的所有值都封装到这个元组中。（注意：Python将实参封装到一个元组中，即使函数只收到一个值也是如此）</p>
<h3 id="5-1结合使用位置实参和任意数量实参"><a href="#5-1结合使用位置实参和任意数量实参" class="headerlink" title="5.1结合使用位置实参和任意数量实参"></a>5.1结合使用位置实参和任意数量实参</h3><p>如果要让函数接收不同类型的实参，必须在函数定义中将接纳任意数量实参的形参放在最后。Python先匹配位置实参和关键字实参，再将余下的实参收集到最后一个形参中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_pizza</span>(<span class="hljs-params">size, *toopings</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;pizza size: &quot;</span>, size)<br>    <span class="hljs-built_in">print</span>(toopings)<br><span class="hljs-comment"># use function</span><br>make_pizza(<span class="hljs-number">16</span>, <span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>make_pizza(<span class="hljs-number">12</span>, <span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br><span class="hljs-comment"># output:</span><br>pizza size:  <span class="hljs-number">16</span><br>(<span class="hljs-string">&#x27;pepperoni&#x27;</span>,)<br>pizza size:  <span class="hljs-number">12</span><br>(<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h3 id="5-2使用任意数量的关键字实参"><a href="#5-2使用任意数量的关键字实参" class="headerlink" title="5.2使用任意数量的关键字实参"></a>5.2使用任意数量的关键字实参</h3><p>有时候，需要接受任意数量的实参，但预先不知道传递给函数的会是什么样的信息。在这种情况下，可将函数编写成能够接收任意数量的键值对——调用语句提供多少就接收多少。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># define function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_profile</span>(<span class="hljs-params">first, last, **user_info</span>):<br>    profile = &#123;&#125;<br>    profile[<span class="hljs-string">&#x27;first_name&#x27;</span>] = first<br>    profile[<span class="hljs-string">&#x27;last_name&#x27;</span>] = last<br>    <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> user_info.items():<br>        profile[key] = value<br>    <span class="hljs-keyword">return</span> profile<br><span class="hljs-comment"># use function</span><br>user_profile = build_profile(<span class="hljs-string">&#x27;albert&#x27;</span>, <span class="hljs-string">&#x27;einstein&#x27;</span>, location=<span class="hljs-string">&#x27;princeton&#x27;</span>, field=<span class="hljs-string">&#x27;physics&#x27;</span>)<br><span class="hljs-built_in">print</span>(user_profile)<br><span class="hljs-comment"># output:</span><br>&#123;<span class="hljs-string">&#x27;first_name&#x27;</span>: <span class="hljs-string">&#x27;albert&#x27;</span>, <span class="hljs-string">&#x27;last_name&#x27;</span>: <span class="hljs-string">&#x27;einstein&#x27;</span>, <span class="hljs-string">&#x27;location&#x27;</span>: <span class="hljs-string">&#x27;princeton&#x27;</span>, <span class="hljs-string">&#x27;field&#x27;</span>: <span class="hljs-string">&#x27;physics&#x27;</span>&#125;<br></code></pre></td></tr></table></figure>

<p>形参**user_info中的两个星号让Python创建一个名为user_info的空字典，并将收到的所有键值对（除了用户已经定义的）都封装在这个字典中。</p>
<h2 id="6-将函数存储在模块中"><a href="#6-将函数存储在模块中" class="headerlink" title="6.将函数存储在模块中"></a>6.将函数存储在模块中</h2><p>通过将函数存储在独立的文件中，可隐藏程序代码的细节，将重点放在程序的高层逻辑上。也可与其他程序员共享这些文件而不是整个程序。知道如何导入函数还能让你使用其他程序员编写的函数库。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># pizza.py</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_pizza</span>(<span class="hljs-params">size, *toopings</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;pizza size: &quot;</span>, size)<br>    <span class="hljs-built_in">print</span>(toopings)<br></code></pre></td></tr></table></figure>

<p>导入整个模块：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># import whole module</span><br><span class="hljs-keyword">import</span> pizza<br>pizza.make_pizza(<span class="hljs-number">16</span>, <span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>pizza.make_pizza(<span class="hljs-number">12</span>, <span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>导入模块中某个函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># import specific function</span><br><span class="hljs-keyword">from</span> pizza <span class="hljs-keyword">import</span> make_pizza<br>make_pizza(<span class="hljs-number">16</span>, <span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>make_pizza(<span class="hljs-number">12</span>, <span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>给导入的函数命名：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># use other name</span><br><span class="hljs-keyword">from</span> pizza <span class="hljs-keyword">import</span> make_pizza <span class="hljs-keyword">as</span> mp<br>mp(<span class="hljs-number">16</span>, <span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>mp(<span class="hljs-number">12</span>, <span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>导入模块中所有函数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># import all function in module</span><br><span class="hljs-keyword">from</span> pizza <span class="hljs-keyword">import</span> *<br>make_pizza(<span class="hljs-number">16</span>, <span class="hljs-string">&#x27;pepperoni&#x27;</span>)<br>make_pizza(<span class="hljs-number">12</span>, <span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>

<p>上述四种方法输出都是相同的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># output:</span><br>pizza size:  <span class="hljs-number">16</span><br>(<span class="hljs-string">&#x27;pepperoni&#x27;</span>,)<br>pizza size:  <span class="hljs-number">12</span><br>(<span class="hljs-string">&#x27;mushrooms&#x27;</span>, <span class="hljs-string">&#x27;green peppers&#x27;</span>, <span class="hljs-string">&#x27;extra cheese&#x27;</span>)<br></code></pre></td></tr></table></figure>







]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（9）类</title>
    <url>/2022/07/03/Python_9/</url>
    <content><![CDATA[<p>面向对象是最有效的软件编写方法之一。在本章中，你将编写一些类并创建其实例。你将指定可在实例中存储什么信息，定义可对这些实例执行哪些操作。你还将编写一些类来扩展既有类的功能，让相似的类能够高效地共享代码。你还将把自己编写的类存储在模块中，并在自己的程序文件中导入其他程序员编写的类。</p>
<h2 id="1-创建和使用类"><a href="#1-创建和使用类" class="headerlink" title="1. 创建和使用类"></a>1. 创建和使用类</h2><p>使用类几乎可以模拟任何东西。下面来编写一个表示小狗的简单类Dog。</p>
<h3 id="1-1创建Dog类"><a href="#1-1创建Dog类" class="headerlink" title="1.1创建Dog类"></a>1.1创建Dog类</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dog</span>():<br>    <span class="hljs-string">&#x27;&#x27;&#x27;dog class dog 类&#x27;&#x27;&#x27;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, name, age</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;init name, age 初始化name,age&#x27;&#x27;&#x27;</span><br>        self.name = name<br>        self.age = age<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">sit</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;sit when be ordered 被命令时蹲下&#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">print</span>(self.name.title() + <span class="hljs-string">&quot; is now sitting.&quot;</span>)<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">roll_over</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;roll_over when be ordered 被命令时蹲下&#x27;&#x27;&#x27;</span><br>        <span class="hljs-built_in">print</span>(self.name.title() + <span class="hljs-string">&quot; rolled over!&quot;</span>)<br></code></pre></td></tr></table></figure>

<p>方法_<em>init</em>_()是一个特殊的方法，每当你根据Dog类创建新实例时，Python会自动运行它。<strong>在这个方法的定义中，形参self必不可少，还必须位于其他形参的前面。</strong></p>
<h3 id="1-2根据类创建实例"><a href="#1-2根据类创建实例" class="headerlink" title="1.2根据类创建实例"></a>1.2根据类创建实例</h3><p>创建实例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">my_dog = Dog(<span class="hljs-string">&#x27;willie&#x27;</span>, <span class="hljs-number">6</span>)<br></code></pre></td></tr></table></figure>

<p>调用属性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;My dog&#x27;s name is &quot;</span> + my_dog.name.title() + <span class="hljs-string">&quot;.&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;My dog is &quot;</span> + <span class="hljs-built_in">str</span>(my_dog.age) + <span class="hljs-string">&quot; years old.&quot;</span>)<br><span class="hljs-comment"># output:</span><br>My dog’s name <span class="hljs-keyword">is</span> Willie.<br>My dog <span class="hljs-keyword">is</span> <span class="hljs-number">6</span> years old.<br></code></pre></td></tr></table></figure>

<p>调用方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">my_dog.sit()<br>my_dog.roll_over()<br><span class="hljs-comment"># output:</span><br>Willie <span class="hljs-keyword">is</span> now sitting.<br>Willie rolled over!<br></code></pre></td></tr></table></figure>

<h2 id="2-使用类和实例"><a href="#2-使用类和实例" class="headerlink" title="2. 使用类和实例"></a>2. 使用类和实例</h2><p>类编写好后，你的大部分时 间都将花在使用根据类创建的实例上。你需要执行的一个重要任务是修改 实例的属性。你可以直接修改实例的属性，也可以编写方法以特定的方式 进行修改。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Car</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;一次模拟汽车的简单尝试&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, make, model, year</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化描述汽车的属性&quot;&quot;&quot;</span><br>        self.make = make<br>        self.model = model<br>        self.year = year<br>        self.odometer_reading = <span class="hljs-number">10</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_descriptive_name</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;返回整洁的描性信息&quot;&quot;&quot;</span><br>        long_name = <span class="hljs-built_in">str</span>(self.year) + <span class="hljs-string">&#x27; &#x27;</span> + self.make + <span class="hljs-string">&#x27; &#x27;</span> + self.model<br>        <span class="hljs-keyword">return</span> long_name.title()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update_year</span>(<span class="hljs-params">self, year</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;将年份修为指定的值&quot;&quot;&quot;</span><br>        self.year = year<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">increment_odometer</span>(<span class="hljs-params">self, miles</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;将里程读数增加指定的量&quot;&quot;&quot;</span><br>        self.odometer_reading += miles<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_gas_tank</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;加满油箱&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;This car has been filled!&quot;</span>)<br>my_new_car = Car(<span class="hljs-string">&#x27;audi&#x27;</span>, <span class="hljs-string">&#x27;a4&#x27;</span>, <span class="hljs-number">2016</span>)<br><span class="hljs-built_in">print</span>(my_new_car.get_descriptive_name())<br><span class="hljs-comment"># output: 2016 Audi A4</span><br><span class="hljs-comment"># 1. 直接修改属性的值</span><br>my_new_car.year = <span class="hljs-number">2019</span><br><span class="hljs-built_in">print</span>(my_new_car.get_descriptive_name())<br><span class="hljs-comment"># output: 2019 Audi A4</span><br><span class="hljs-comment"># 2. 通过方法修改属性的值</span><br>my_new_car.update_year(<span class="hljs-number">2021</span>)<br><span class="hljs-built_in">print</span>(my_new_car.get_descriptive_name())<br><span class="hljs-comment"># output: 2021 Audi A4</span><br><span class="hljs-comment"># 3. 通过方法使属性的值进行递增</span><br>my_new_car.increment_odometer(<span class="hljs-number">100</span>)<br><span class="hljs-built_in">print</span>(my_new_car.odometer_reading)<br><span class="hljs-comment"># output: 110</span><br>my_new_car.fill_gas_tank()<br><span class="hljs-comment"># output: This car has been filled!</span><br></code></pre></td></tr></table></figure>

<h2 id="3-继承"><a href="#3-继承" class="headerlink" title="3. 继承"></a>3. 继承</h2><p>编写类时，并非总是要从空白开始。如果你要编写的类是另一个现成类的特殊版本，可使用继承。一个类继承另一个类时，它将自动获得另一个类的所有属性和方法；原有的类称为父类，而新类称为子类。子类继承了其父类的所有属性和方法，同时还可以定义自己的属性和方法。</p>
<h3 id="3-1子类的方法-init"><a href="#3-1子类的方法-init" class="headerlink" title="3.1子类的方法_init_()"></a>3.1子类的方法_<em>init</em>_()</h3><p>创建子类的实例时，Python首先需要完成的任务是给父类的所有属性赋值。为此，子类的方法<strong>_<em>init</em>_()</strong> 需要父类施以援手。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ElectricCar</span>(<span class="hljs-title class_ inherited__">Car</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;电动汽车的独特之处&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, make, model, year</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化父类的属性&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__(make, model, year)<br>        <span class="hljs-comment"># super使子类可以调用父类的方法，父类也称超类（superclass）</span><br>my_tesla = ElectricCar(<span class="hljs-string">&#x27;tesla&#x27;</span>, <span class="hljs-string">&#x27;model s&#x27;</span>, <span class="hljs-number">2016</span>)<br><span class="hljs-built_in">print</span>(my_tesla.get_descriptive_name())<br><span class="hljs-comment"># output: 2016 Tesla Model S</span><br></code></pre></td></tr></table></figure>

<h3 id="3-2重写父类的方法"><a href="#3-2重写父类的方法" class="headerlink" title="3.2重写父类的方法"></a>3.2重写父类的方法</h3><p>对于父类的方法，只要它不符合子类模拟的实物的行为，都可对其进行重写。为此，可在子类中定义一个这样的方法，即<strong>它与要重写的父类方法同名</strong>。这样，Python将不会考虑这个父类方法，而<strong>只关注你在子类中定义的相应方法</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ElectricCar</span>(<span class="hljs-title class_ inherited__">Car</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;电动汽车的独特之处&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, make, model, year</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化父类的属性&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__(make, model, year)<br>        <span class="hljs-comment"># super使子类可以调用父类的方法，父类也称超类（superclass）</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_gas_tank</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;电动汽车没有油箱&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;This car doesn&#x27;t need a gas tank!&quot;</span>)<br>my_tesla = ElectricCar(<span class="hljs-string">&#x27;tesla&#x27;</span>, <span class="hljs-string">&#x27;model s&#x27;</span>, <span class="hljs-number">2016</span>)<br>my_tesla.fill_gas_tank()<br><span class="hljs-comment"># output: This car doesn&#x27;t need a gas tank!</span><br></code></pre></td></tr></table></figure>

<h3 id="3-3将实例用作属性"><a href="#3-3将实例用作属性" class="headerlink" title="3.3将实例用作属性"></a>3.3将实例用作属性</h3><p>使用代码模拟实物时，你可能会发现自己给类添加的细节越来越多：属性和方法清单以及文件都越来越长。在这种情况下，可能需要将类的一部分作为一个独立的类提取出来。你可以将大型类拆分成多个协同工作的小类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Battery</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;一次模拟电动汽车电瓶的简单尝试&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, battery_size=<span class="hljs-number">70</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化电瓶的属性&quot;&quot;&quot;</span><br>        self.battery_size = battery_size<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">describe_battery</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;打印一条描述电瓶容量的消息&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;This car has a &quot;</span> + <span class="hljs-built_in">str</span>(self.battery_size) + <span class="hljs-string">&quot;-kWh battery.&quot;</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ElectricCar</span>(<span class="hljs-title class_ inherited__">Car</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;电动汽车的独特之处&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, make, model, year</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化父类的属性&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>().__init__(make, model, year)<br>        <span class="hljs-comment"># super使子类可以调用父类的方法，父类也称超类（superclass）</span><br>        self.battery = Battery()<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fill_gas_tank</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;电动汽车没有油箱&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;This car doesn&#x27;t need a gas tank!&quot;</span>)<br>my_tesla = ElectricCar(<span class="hljs-string">&#x27;tesla&#x27;</span>, <span class="hljs-string">&#x27;model s&#x27;</span>, <span class="hljs-number">2016</span>)<br>my_tesla.battery.describe_battery()<br><span class="hljs-comment"># output: This car has a 70-kWh battery.</span><br></code></pre></td></tr></table></figure>

<h2 id="4-导入类"><a href="#4-导入类" class="headerlink" title="4. 导入类"></a>4. 导入类</h2><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入单个类</span><br><span class="hljs-keyword">from</span> car <span class="hljs-keyword">import</span> Car<br><span class="hljs-comment"># 从一个模块导入多个类</span><br><span class="hljs-keyword">from</span> car <span class="hljs-keyword">import</span> Car, ElectricCar<br><span class="hljs-comment"># 导入整个模块</span><br><span class="hljs-keyword">import</span> car<br><span class="hljs-comment"># 导入模块中的所有类</span><br><span class="hljs-keyword">from</span> car <span class="hljs-keyword">import</span> *<br></code></pre></td></tr></table></figure>

<h2 id="5-Python标准库"><a href="#5-Python标准库" class="headerlink" title="5. Python标准库"></a>5. Python标准库</h2><p>Python标准库 是一组模块，安装的Python都包含它。你现在对类的工作原 理已有大致的了解，可以开始使用其他程序员编写好的模块了。可使用标准库中的任何函数和类，为此只需在程序开头包含一条简单的import语句。</p>
]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（7）用户输入和while循环</title>
    <url>/2022/07/01/Python_7/</url>
    <content><![CDATA[<p>在本章中，你将学习如何接收用户输入，让程序能够对其进行处理。你还将学习如何让程序不断地运行，直到指定的条件不满足为止。</p>
<h2 id="1-函数input"><a href="#1-函数input" class="headerlink" title="1.函数input()"></a>1.函数input()</h2><p>input()让程序暂停运行，等待用户输入一些文本，再将这些文本呈现给用户。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># input 函数</span><br>message = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Tell me something, and I will repeat it back to you: &quot;</span>)<br><span class="hljs-built_in">print</span>(message)<br><span class="hljs-comment"># output：</span><br><span class="hljs-comment"># Tell me something, and I will repeat it back to you: Hello!</span><br><span class="hljs-comment"># Hello!</span><br></code></pre></td></tr></table></figure>
<p>函数input()接受一个参数：即要向用户显示的提示或说明，让用户知道该怎么做。</p>
<h2 id="2-while循环"><a href="#2-while循环" class="headerlink" title="2.while循环"></a>2.while循环</h2><h3 id="2-1使用while循环"><a href="#2-1使用while循环" class="headerlink" title="2.1使用while循环"></a>2.1使用while循环</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># while</span><br>current_number = <span class="hljs-number">1</span><br><span class="hljs-keyword">while</span> current_number &lt;= <span class="hljs-number">5</span>:<br>    <span class="hljs-built_in">print</span>(current_number)<br>    current_number += <span class="hljs-number">1</span><br><span class="hljs-comment"># output:</span><br><span class="hljs-comment"># 1</span><br><span class="hljs-comment"># 2</span><br><span class="hljs-comment"># 3</span><br><span class="hljs-comment"># 4</span><br><span class="hljs-comment"># 5</span><br></code></pre></td></tr></table></figure>

<h3 id="2-2让用户选择何时退出"><a href="#2-2让用户选择何时退出" class="headerlink" title="2.2让用户选择何时退出"></a>2.2让用户选择何时退出</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># select when to exit</span><br>prompt = <span class="hljs-string">&quot;Tell me something, and I will repeat it back to you:&quot;</span><br>prompt += <span class="hljs-string">&quot;\nEnter &#x27;quit&#x27; to end the program. input:&quot;</span><br>message = <span class="hljs-string">&quot;&quot;</span><br><span class="hljs-keyword">while</span> message != <span class="hljs-string">&#x27;quit&#x27;</span>:<br>    message = <span class="hljs-built_in">input</span>(prompt)<br>    <span class="hljs-keyword">if</span> message != <span class="hljs-string">&#x27;quit&#x27;</span>:<br>        <span class="hljs-built_in">print</span>(message)<br><span class="hljs-comment"># output</span><br>Tell me something, <span class="hljs-keyword">and</span> I will repeat it back to you:<br>Enter <span class="hljs-string">&#x27;quit&#x27;</span> to end the program. <span class="hljs-built_in">input</span>:Hello<br>Hello<br>Tell me something, <span class="hljs-keyword">and</span> I will repeat it back to you:<br>Enter <span class="hljs-string">&#x27;quit&#x27;</span> to end the program. <span class="hljs-built_in">input</span>:Hello again<br>Hello again<br>Tell me something, <span class="hljs-keyword">and</span> I will repeat it back to you:<br>Enter <span class="hljs-string">&#x27;quit&#x27;</span> to end the program. <span class="hljs-built_in">input</span>:quit<br></code></pre></td></tr></table></figure>
<h3 id="2-3使用break退出循环"><a href="#2-3使用break退出循环" class="headerlink" title="2.3使用break退出循环"></a>2.3使用break退出循环</h3><figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">prompt = <span class="hljs-string">&quot;Tell me something, and I will repeat it back to you:&quot;</span><br>prompt += <span class="hljs-string">&quot;\nEnter &#x27;quit&#x27; to end the program. input:&quot;</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    city = <span class="hljs-built_in">input</span>(prompt)<br>    <span class="hljs-keyword">if</span> city == <span class="hljs-string">&#x27;quit&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-built_in">print</span>(city.title())<br><span class="hljs-comment">#output</span><br>Tell me something, <span class="hljs-keyword">and</span> I will repeat it back to you:<br>Enter <span class="hljs-string">&#x27;quit&#x27;</span> to end the program. <span class="hljs-built_in">input</span>:Hello<br>Hello<br>Tell me something, <span class="hljs-keyword">and</span> I will repeat it back to you:<br>Enter <span class="hljs-string">&#x27;quit&#x27;</span> to end the program. <span class="hljs-built_in">input</span>:quit<br></code></pre></td></tr></table></figure>

<h3 id="2-4在循环中使用continue"><a href="#2-4在循环中使用continue" class="headerlink" title="2.4在循环中使用continue"></a>2.4在循环中使用continue</h3><p>continue，跳过后面的语句直接执行下一次循环。</p>
<h2 id="3-使用while处理字典列表"><a href="#3-使用while处理字典列表" class="headerlink" title="3.使用while处理字典列表"></a>3.使用while处理字典列表</h2><h3 id="3-1在列表之间移动元素"><a href="#3-1在列表之间移动元素" class="headerlink" title="3.1在列表之间移动元素"></a>3.1在列表之间移动元素</h3><p>使用while循环在验证用户的同时将其从未验证用户列表中提取出来，再加入到另一个已验证的用户列表中。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># use while</span><br>unconfirmed_users = [<span class="hljs-string">&#x27;alice&#x27;</span>, <span class="hljs-string">&#x27;brian&#x27;</span>, <span class="hljs-string">&#x27;candace&#x27;</span>]<br>confirmed_users = []<br><br><span class="hljs-keyword">while</span> unconfirmed_users:<br>    current_user = unconfirmed_users.pop()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Verifying user: &quot;</span> + current_user.title())<br>    confirmed_users.append(current_user)<br><span class="hljs-comment">#output:</span><br>Verifying user: Candace<br>Verifying user: Brian<br>Verifying user: Alice<br></code></pre></td></tr></table></figure>

<h3 id="3-2删除包含特定值的所有列表元素"><a href="#3-2删除包含特定值的所有列表元素" class="headerlink" title="3.2删除包含特定值的所有列表元素"></a>3.2删除包含特定值的所有列表元素</h3><p>使用while删除列表中所有 ‘cat’ 元素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pets = [<span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;dog&#x27;</span>, <span class="hljs-string">&#x27;goldfish&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>, <span class="hljs-string">&#x27;rabbit&#x27;</span>, <span class="hljs-string">&#x27;cat&#x27;</span>]<br><span class="hljs-built_in">print</span>(pets) <span class="hljs-comment"># [&#x27;dog&#x27;, &#x27;cat&#x27;, &#x27;dog&#x27;, &#x27;goldfish&#x27;, &#x27;cat&#x27;, &#x27;rabbit&#x27;, &#x27;cat&#x27;]</span><br><span class="hljs-keyword">while</span> <span class="hljs-string">&#x27;cat&#x27;</span> <span class="hljs-keyword">in</span> pets:<br>    pets.remove(<span class="hljs-string">&#x27;cat&#x27;</span>)<br><span class="hljs-built_in">print</span>(pets) <span class="hljs-comment"># [&#x27;dog&#x27;, &#x27;dog&#x27;, &#x27;goldfish&#x27;, &#x27;rabbit&#x27;]</span><br></code></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/06/26/helloworld/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
<h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><figure class="highlight bash"><table><tr><td class="code"><pre><code class="hljs bash">hexo new <span class="hljs-string">&quot;name&quot;</span>       <span class="hljs-comment"># 新建文章</span><br>hexo new page <span class="hljs-string">&quot;name&quot;</span>  <span class="hljs-comment"># 新建页面</span><br>hexo g                <span class="hljs-comment"># 生成页面</span><br>hexo d                <span class="hljs-comment"># 部署</span><br>hexo g -d             <span class="hljs-comment"># 生成页面并部署</span><br>hexo s                <span class="hljs-comment"># 本地预览</span><br>hexo clean            <span class="hljs-comment"># 清除缓存和已生成的静态文件</span><br>hexo <span class="hljs-built_in">help</span>             <span class="hljs-comment"># 帮助</span><br></code></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Hello-World</tag>
      </tags>
  </entry>
  <entry>
    <title>英文论文阅读方法</title>
    <url>/2022/10/14/paper-read-method/</url>
    <content><![CDATA[<p>学习基本的英文文献阅读方法，以便阅读论文时有章可循。</p>
<h2 id="1-阅读顺序"><a href="#1-阅读顺序" class="headerlink" title="1.阅读顺序"></a>1.阅读顺序</h2><ol>
<li>题目优先（Topic）。了解作者要研究的问题。</li>
<li>关键词（Keywords）。反应文章的核心内容。</li>
<li>摘要（Abstract）。体显文章的主要思想，对内容有基本掌握。</li>
</ol>
<p>此时要尝试回答三个问题：</p>
<ul>
<li>作者的目的是什么？</li>
<li>作者用了什么样的方法？</li>
<li>作者的结论是什么？</li>
</ul>
<ol start="4">
<li>讨论（Discussion）。了解作者在研究过程中遇到的问题，他们又是如何解决的，以及对于争议性部分的观点。</li>
<li>图表和数字。这部分能很大程度上避免冗长的表达。</li>
<li>引言（Introduction）。了解作者的研究背景。</li>
<li>对上述不了解的部分进行重新阅读。</li>
<li>方法（Methods）</li>
</ol>
<h2 id="2-阅读方法"><a href="#2-阅读方法" class="headerlink" title="2.阅读方法"></a>2.阅读方法</h2><p>批判性的阅读方法（Critical Thinking），多对自己提问题。</p>
<h2 id="Courses"><a href="#Courses" class="headerlink" title="#Courses"></a>#Courses</h2><ul>
<li><p>动手学深度学习(李沐)</p>
<ul>
<li><a href="https://zh.d2l.ai/">https://zh.d2l.ai/</a></li>
</ul>
</li>
<li><p>学术规范与论文写作(南开)</p>
<ul>
<li><a href="https://mmcheng.net/writing/">https://mmcheng.net/writing/</a></li>
</ul>
</li>
<li><p>Deep Learning for Computer Vision(CS231n, Stanford)、</p>
<ul>
<li><a href="http://cs231n.stanford.edu/">http://cs231n.stanford.edu/</a></li>
</ul>
</li>
</ul>
<h2 id="Conferences"><a href="#Conferences" class="headerlink" title="#Conferences"></a>#Conferences</h2><p>• CVPR (每年下半年) &amp; ICCV (奇数年上半年)<br>• <a href="https://openaccess.thecvf.com/">https://openaccess.thecvf.com</a><br>• ECCV （偶数年上半年）<br>• <a href="https://www.ecva.net/papers.php">https://www.ecva.net/papers.php</a><br>• SIGGRAPH (每年上半年) &amp; SIGGRAPH Asia (每年下半年)<br>• <a href="https://kesen.realtimerendering.com/">https://kesen.realtimerendering.com/</a><br>• VALSE (计算机视觉领域国内学术组织，每年开)<br>• <a href="http://valser.org/">http://valser.org/</a><br>• GAMES (计算机图形学领域国内学术组织，每年开)<br>• <a href="https://games-cn.org/">https://games-cn.org/</a></p>
]]></content>
      <categories>
        <category>DeepLearning期刊</category>
      </categories>
      <tags>
        <tag>papers</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（19）多尺度锚框和SSD实现</title>
    <url>/2022/11/09/DL_19/</url>
    <content><![CDATA[<p>当使用较小的锚框检测较小的物体时，我们可以采样更多的区域，而对于较大的物体，我们可以采样较少的区域。</p>
<h2 id="多尺度锚框"><a href="#多尺度锚框" class="headerlink" title="多尺度锚框"></a>多尺度锚框</h2><p>为了演示如何在多个尺度下生成锚框，让我们先读取一张图像。 它的高度和宽度分别为561和728像素。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> d2l <span class="hljs-keyword">import</span> torch <span class="hljs-keyword">as</span> d2l<br><br>img = d2l.plt.imread(<span class="hljs-string">&#x27;../img/catdog.jpg&#x27;</span>)<br>h, w = img.shape[:<span class="hljs-number">2</span>]<br></code></pre></td></tr></table></figure>

<p>给定特征图的宽度和高度<code>fmap_w</code>和<code>fmap_h</code>，以下函数将<em>均匀地</em>对任何输入图像中<code>fmap_h</code>行和<code>fmap_w</code>列中的像素进行采样。 以这些均匀采样的像素为中心，将会生成大小为<code>s</code>（假设列表<code>s</code>的长度为1）且宽高比（<code>ratios</code>）不同的锚框。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">display_anchors</span>(<span class="hljs-params">fmap_w, fmap_h, s</span>):<br>    d2l.set_figsize()<br>    <span class="hljs-comment"># 前两个维度上的值不影响输出</span><br>    fmap = torch.zeros((<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, fmap_h, fmap_w))<br>    anchors = d2l.multibox_prior(fmap, sizes=s, ratios=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0.5</span>])<br>    bbox_scale = torch.tensor((w, h, w, h))<br>    d2l.show_bboxes(d2l.plt.imshow(img).axes,<br>                    anchors[<span class="hljs-number">0</span>] * bbox_scale)<br>display_anchors(fmap_w=<span class="hljs-number">4</span>, fmap_h=<span class="hljs-number">4</span>, s=[<span class="hljs-number">0.15</span>])<br></code></pre></td></tr></table></figure>

<p>然后，我们将特征图的高度和宽度减小一半，然后使用较大的锚框来检测较大的目标。 当尺度设置为0.4时，一些锚框将彼此重叠。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">display_anchors(fmap_w=<span class="hljs-number">2</span>, fmap_h=<span class="hljs-number">2</span>, s=[<span class="hljs-number">0.4</span>])<br></code></pre></td></tr></table></figure>

<p>最后，我们进一步将特征图的高度和宽度减小一半，然后将锚框的尺度增加到0.8。 此时，锚框的中心即是图像的中心。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">display_anchors(fmap_w=<span class="hljs-number">1</span>, fmap_h=<span class="hljs-number">1</span>, s=[<span class="hljs-number">0.8</span>])<br></code></pre></td></tr></table></figure>

<h2 id="单次多框检测SSD的实现"><a href="#单次多框检测SSD的实现" class="headerlink" title="单次多框检测SSD的实现"></a>单次多框检测SSD的实现</h2><p>略</p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN</title>
    <url>/2022/11/21/GNN/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>动手学习深度学习（20）语义分割和转置卷积</title>
    <url>/2022/11/24/DL_20/</url>
    <content><![CDATA[<h2 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h2><p><em>语义分割</em>（semantic segmentation）问题，它重点关注于如何将图像分割成属于不同语义类别的区域。 与目标检测不同，语义分割可以识别并理解图像中每一个像素的内容：其语义区域的标注和预测是像素级的。常见应用：背景虚化，无人车场景下的路面分割。</p>
<p>最重要的语义分割数据集之一是Pascal VOC2012，数据集的图片采用VOC格式</p>
<h2 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h2><ul>
<li>转置卷积可以用来做增大高宽</li>
</ul>
<p>输入矩阵的每一个元素分别乘以卷积核，然后拼接起来<br>MATHJAX-SSR-0</p>
<h2 id="FCD全连接卷积神经网络"><a href="#FCD全连接卷积神经网络" class="headerlink" title="FCD全连接卷积神经网络"></a>FCD全连接卷积神经网络</h2><h2 id="样式迁移"><a href="#样式迁移" class="headerlink" title="样式迁移"></a>样式迁移</h2><p>将样式图片中的样式迁移到内容图片上，得到合成图片</p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（15）查看及修改pip源和conda源</title>
    <url>/2022/11/27/Python_15/</url>
    <content><![CDATA[<p>总结修改查看源的方法，免得每次都得重新找。</p>
<p>高算中心指定源：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#conda </span><br>https://mirrors.tuna.tsinghua.edu.cn/ <br>http://mirrors.ustc.edu.cn/ <br>http://mirrors.aliyun.com/ <br><br><span class="hljs-comment">#pip </span><br>https://pypi.tuna.tsinghua.edu.cn/ <br>http://pypi.mirrors.ustc.edu.cn/ <br>https://pypi.mirrors.ustc.edu.cn/<br></code></pre></td></tr></table></figure>

<h2 id="pip源"><a href="#pip源" class="headerlink" title="pip源"></a>pip源</h2><p>pip更换默认源（以西电源为示例）</p>
<p>临时使用</p>
<figure class="highlight bat"><table><tr><td class="code"><pre><code class="hljs bat">pip install -i http://linux.xidian.edu.cn/mirrors/pypi/simple --user<br>some-package<br></code></pre></td></tr></table></figure>

<p>设为默认源</p>
<figure class="highlight bat"><table><tr><td class="code"><pre><code class="hljs bat">pip config <span class="hljs-built_in">set</span> global.index-url <br><span class="hljs-function">http://<span class="hljs-title">linux.xidian.edu.cn</span>/<span class="hljs-title">mirrors</span>/<span class="hljs-title">pypi</span>/<span class="hljs-title">simple</span></span><br></code></pre></td></tr></table></figure>

<p>查看当前源</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">pip config <span class="hljs-built_in">list</span><br></code></pre></td></tr></table></figure>



<h2 id="conda源"><a href="#conda源" class="headerlink" title="conda源"></a>conda源</h2><p>conda 更换默认源（以清华源为示例） </p>
<p>使用下列命令生成<code>.condarc</code> 配置文件，位于用户家目录下</p>
<figure class="highlight bat"><table><tr><td class="code"><pre><code class="hljs bat">conda config --<span class="hljs-built_in">set</span> show_channel_urls yes<br></code></pre></td></tr></table></figure>

<p>编辑<code>.condarc</code>文件，清空原先内容，写入以下内容</p>
<figure class="highlight python"><table><tr><td class="code"><pre><code class="hljs python">channels:<br> - defaults<br>show_channel_urls: true<br>default_channels:<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2<br>custom_channels:<br> conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br> msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br> bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br> menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br> pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br> simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud<br></code></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（21）序列模型</title>
    <url>/2022/12/13/DL_21/</url>
    <content><![CDATA[<p>时序结构的数据就是一种序列数据，音乐、语言、文本和视频都是连续的。</p>
<p>在时间<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
</g>
</svg>观察到<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 928.1 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
</svg>，那么得到<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.636ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 704.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">T</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-54" x="0" y="0"></use>
</g>
</svg>个不独立的随机变量<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.937ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 6861.7 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(x_1,...x_T)~p(x)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1415" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1861" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="2306" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="2751" y="0"></use>
<g transform="translate(3196,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-54" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="4367" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="5006" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="5510" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="5899" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="6472" y="0"></use>
</g>
</svg></p>
<p>使用条件概率展开<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="32.417ex" height="2.843ex" style="vertical-align: -0.838ex; margin-left: -0.089ex;" viewBox="-38.5 -863.1 13957.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">p(a,b) = p(a)p(b|a)=p(b)p(a|b)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="503" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="893" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1422" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="1867" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2297" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2964" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="4020" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="4524" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="4913" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="5443" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="5832" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="6336" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="6725" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="7155" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="7433" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="7963" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="8630" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="9686" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="10190" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="10579" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="11009" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="11398" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="11902" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="12291" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="12821" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="13099" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="13529" y="0"></use>
</g>
</svg></p>
<h2 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h2><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="57.854ex" height="2.843ex" style="vertical-align: -0.838ex; margin-left: -0.089ex;" viewBox="-38.5 -863.1 24909.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">p(x) = p(x_1) \cdot p(x_2|x_1) \cdot p(x_3|x_1,x_2) \cdot ...p(x_T | x_1,...x_{T-1})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="503" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="893" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1465" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2132" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="3189" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="3692" y="0"></use>
<g transform="translate(4082,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5108" y="0"></use>
 <use xlink:href="#E1-MJMAIN-22C5" x="5720" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="6220" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="6724" y="0"></use>
<g transform="translate(7113,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="8140" y="0"></use>
<g transform="translate(8418,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9445" y="0"></use>
 <use xlink:href="#E1-MJMAIN-22C5" x="10056" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="10557" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="11061" y="0"></use>
<g transform="translate(11450,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="12477" y="0"></use>
<g transform="translate(12755,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="13781" y="0"></use>
<g transform="translate(14227,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="15253" y="0"></use>
 <use xlink:href="#E1-MJMAIN-22C5" x="15643" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="15921" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="16366" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="16811" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="17257" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="17760" y="0"></use>
<g transform="translate(18150,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-54" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="19320" y="0"></use>
<g transform="translate(19599,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="20625" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="21070" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="21515" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="21961" y="0"></use>
<g transform="translate(22406,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-54" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="704" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1483" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="24481" y="0"></use>
</g>
</svg></p>
<p>对条件建模（对见过的数据建模，也称自回归模型：对见过的数据建模）</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="39.39ex" height="2.843ex" style="vertical-align: -0.838ex; margin-left: -0.089ex;" viewBox="-38.5 -863.1 16959.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">p(x_t|x_1,...x_{t-1}) = p(x_t|f(x_1,...x_{t-1}))</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="503" y="0"></use>
<g transform="translate(893,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="1821" y="0"></use>
<g transform="translate(2099,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="3126" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="3571" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="4016" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="4461" y="0"></use>
<g transform="translate(4906,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="6739" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="7406" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="8462" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="8966" y="0"></use>
<g transform="translate(9355,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="10283" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="10562" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="11112" y="0"></use>
<g transform="translate(11502,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="12528" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="12973" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="13419" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="13864" y="0"></use>
<g transform="translate(14309,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="16141" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="16531" y="0"></use>
</g>
</svg></p>
<h3 id="方案A-马尔可夫假设"><a href="#方案A-马尔可夫假设" class="headerlink" title="方案A - 马尔可夫假设"></a>方案A - 马尔可夫假设</h3><p>假设当前数据只跟过去<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.202ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 517.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\tau</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3C4" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3C4" x="0" y="0"></use>
</g>
</svg>个数据点相关（例如在过去数据上训练一个MLP模型）</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="62.846ex" height="2.843ex" style="vertical-align: -0.838ex; margin-left: -0.089ex;" viewBox="-38.5 -863.1 27058.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">p(x_t|x_1,...x_{t-1}) = p(x_t|x_{t-\tau},...x_{t-1}) = p(x_t|f(x_{t-\tau},...x_{t-1}))</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C4" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="503" y="0"></use>
<g transform="translate(893,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="1821" y="0"></use>
<g transform="translate(2099,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="3126" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="3571" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="4016" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="4461" y="0"></use>
<g transform="translate(4906,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="6739" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="7406" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="8462" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="8966" y="0"></use>
<g transform="translate(9355,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="10283" y="0"></use>
<g transform="translate(10562,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-3C4" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="12406" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="12852" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="13297" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="13742" y="0"></use>
<g transform="translate(14187,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="16020" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="16687" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="17743" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="18247" y="0"></use>
<g transform="translate(18636,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="19564" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="19843" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="20393" y="0"></use>
<g transform="translate(20783,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-3C4" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="22627" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="23072" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="23518" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="23963" y="0"></use>
<g transform="translate(24408,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="26240" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="26630" y="0"></use>
</g>
</svg></p>
<h3 id="方案B-潜变量模型"><a href="#方案B-潜变量模型" class="headerlink" title="方案B - 潜变量模型"></a>方案B - 潜变量模型</h3><p>引入潜变量<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.165ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 932.1 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">h_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="815" y="-213"></use>
</g>
</svg>来表示过去信息<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.127ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 8235.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">h_t = f(x_1,...x_{t-1})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="815" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1209" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="2266" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="2816" y="0"></use>
<g transform="translate(3206,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="4232" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="4677" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="5122" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="5568" y="0"></use>
<g transform="translate(6013,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="7845" y="0"></use>
</g>
</svg>，这样<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.49ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 7961.1 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x_t = p(x_t|h_t,x_{t-1})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1205" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="2262" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="2765" y="0"></use>
<g transform="translate(3155,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-7C" x="4083" y="0"></use>
<g transform="translate(4361,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="815" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5293" y="0"></use>
<g transform="translate(5739,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="7571" y="0"></use>
</g>
</svg></p>
<h2 id="HMM（隐马尔可夫模型）"><a href="#HMM（隐马尔可夫模型）" class="headerlink" title="HMM（隐马尔可夫模型）"></a>HMM（隐马尔可夫模型）</h2><p><a href="https://www.cnblogs.com/skyme/p/4651331.html">一文搞懂HMM（隐马尔可夫模型） - skyme - 博客园 (cnblogs.com)</a></p>
<p><a href="https://www.zhihu.com/question/20962240/answer/33561657">如何用简单易懂的例子解释隐马尔可夫模型？ - 知乎用户的回答 - 知乎</a></p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（23）自注意力机制（self attention）</title>
    <url>/2023/02/13/DL_23/</url>
    <content><![CDATA[<p> 在深度学习中，经常使用CNN或RNN对序列进行编码。使用注意力机制之后，每个查询都会关注所有键值对并生成一个注意力输出。由于查询、键、值来自同一组输入，因此被称为自注意力。自注意力适合处理长文本，但是复杂度相对会更高。</p>
<ul>
<li>给定序列<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.168ex" height="3.009ex" style="vertical-align: -0.671ex;" viewBox="0 -1006.6 8683.6 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x_1,...,x_n, \forall x_i \in \mathbb{R}^d</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2200" d="M0 673Q0 684 7 689T20 694Q32 694 38 680T82 567L126 451H430L473 566Q483 593 494 622T512 668T519 685Q524 694 538 694Q556 692 556 674Q556 670 426 329T293 -15Q288 -22 278 -22T263 -15Q260 -11 131 328T0 673ZM414 410Q414 411 278 411T142 410L278 55L414 410Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJAMS-52" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1026" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1471" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1916" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="2361" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="2807" y="0"></use>
<g transform="translate(3252,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="4349" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2200" x="4794" y="0"></use>
<g transform="translate(5351,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2208" x="6545" y="0"></use>
<g transform="translate(7490,0)">
 <use xlink:href="#E1-MJAMS-52" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1021" y="583"></use>
</g>
</g>
</svg></li>
<li>自注意力池化层将<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.129ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 916.8 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
</svg>当作key，value，query来对序列抽取特征得到<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.721ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 4185.4 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">y_1,...,y_n</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="693" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="944" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1834" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="2279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="2725" y="0"></use>
<g transform="translate(3170,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="693" y="-213"></use>
</g>
</g>
</svg>，这里<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="37.62ex" height="3.176ex" style="vertical-align: -0.838ex;" viewBox="0 -1006.6 16197.3 1367.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">y_i=f(x_i,(x_1,x_1),...,(x_n,x_n)) \in \mathbb{R}^d</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJAMS-52" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1112" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="2168" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="2719" y="0"></use>
<g transform="translate(3108,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="4025" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="4470" y="0"></use>
<g transform="translate(4860,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5886" y="0"></use>
<g transform="translate(6331,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="7358" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="7747" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="8192" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="8638" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="9083" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="9528" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="9973" y="0"></use>
<g transform="translate(10363,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="11460" y="0"></use>
<g transform="translate(11905,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="13002" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="13392" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2208" x="14059" y="0"></use>
<g transform="translate(15004,0)">
 <use xlink:href="#E1-MJAMS-52" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1021" y="583"></use>
</g>
</g>
</svg></li>
</ul>
<h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><ul>
<li><p>跟CNN&#x2F;RNN不同，自注意力并没有记录位置信息。</p>
</li>
<li><p>位置编码讲位置信息注入到输入里，使得自注意力能够记忆位置信息。假设长度为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.395ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 600.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">n</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
</g>
</svg>的序列是<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.856ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 4243.3 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">X\in \mathbb{R}^{n \times d}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJAMS-52" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-58" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2208" x="1130" y="0"></use>
<g transform="translate(2075,0)">
 <use xlink:href="#E1-MJAMS-52" x="0" y="0"></use>
<g transform="translate(722,412)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-D7" x="600" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1379" y="0"></use>
</g>
</g>
</g>
</svg>，那么使用位置编码矩阵<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.621ex" height="2.676ex" style="vertical-align: -0.338ex;" viewBox="0 -1006.6 4142.3 1152.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">P\in \mathbb{R}^{n \times d}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJAMS-52" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-50" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2208" x="1029" y="0"></use>
<g transform="translate(1974,0)">
 <use xlink:href="#E1-MJAMS-52" x="0" y="0"></use>
<g transform="translate(722,412)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-D7" x="600" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1379" y="0"></use>
</g>
</g>
</g>
</svg>来输出<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.566ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2826.9 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">X + P</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-58" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2B" x="1074" y="0"></use>
 <use xlink:href="#E1-MJMATHI-50" x="2075" y="0"></use>
</g>
</svg>作为自编码输入。</p>
</li>
<li><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.745ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 751.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">P</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-50" x="0" y="0"></use>
</g>
</svg>的元素如下计算：</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="47.527ex" height="5.843ex" style="vertical-align: -2.505ex; margin-left: -0.089ex;" viewBox="-38.5 -1437.2 20463.1 2515.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">p_{i,2j} = sin(\frac{i}{10000^{2j/d}}), p_{i,2j+1} = cos(\frac{i}{10000^{2j/d}})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
<g transform="translate(503,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="624" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="1124" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="1968" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="3024" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="3493" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="3839" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="4439" y="0"></use>
<g transform="translate(4829,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="4092" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMATHI-69" x="1873" y="676"></use>
<g transform="translate(60,-945)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-30" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1501" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="2002" y="0"></use>
<g transform="translate(2502,393)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2F" x="913" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1413" y="0"></use>
</g>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9161" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="9551" y="0"></use>
<g transform="translate(9996,0)">
 <use xlink:href="#E1-MJMATHI-70" x="0" y="0"></use>
<g transform="translate(503,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="624" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="1124" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2B" x="1537" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="2315" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="12868" y="0"></use>
 <use xlink:href="#E1-MJMATHI-63" x="13924" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="14358" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="14843" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="15313" y="0"></use>
<g transform="translate(15702,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="4092" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMATHI-69" x="1873" y="676"></use>
<g transform="translate(60,-945)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-30" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1501" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="2002" y="0"></use>
<g transform="translate(2502,393)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2F" x="913" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="1413" y="0"></use>
</g>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="20035" y="0"></use>
</g>
</svg></p>
</li>
</ul>
<h2 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h2><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/1.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/2.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/3.png?raw=true"
                     
                ></p>
<p>计算过程如下：需要学习的参数为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.698ex" height="3.009ex" style="vertical-align: -0.671ex;" viewBox="0 -1006.6 5467.3 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">W^q,W^k,W^v</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-57" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-71" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-57" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-71" x="1526" y="583"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1505" y="0"></use>
<g transform="translate(1950,0)">
 <use xlink:href="#E1-MJMATHI-57" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6B" x="1526" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="3499" y="0"></use>
<g transform="translate(3944,0)">
 <use xlink:href="#E1-MJMATHI-57" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-76" x="1526" y="583"></use>
</g>
</g>
</svg></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/4.png?raw=true"
                     
                ></p>
<p>A矩阵中存储的即为attention的分数，A‘为attention matrix</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/5.png?raw=true"
                     
                ></p>
<p>计算输出O</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/6.png?raw=true"
                     
                ></p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（24）transformer</title>
    <url>/2023/02/13/DL_24/</url>
    <content><![CDATA[<p>Transformer作为编码器－解码器架构的一个实例。Transformer是由编码器和解码器组成的。Transformer的编码器和解码器是基于自注意力的模块叠加而成的，源（输入）序列和目标（输出）序列的<em>嵌入</em>（embedding）表示将加上<em>位置编码</em>（positional encoding），再分别输入到编码器和解码器中。</p>
<h2 id="transformer架构"><a href="#transformer架构" class="headerlink" title="transformer架构"></a>transformer架构</h2><ul>
<li>基于编码器-解码器架构来处理序列对</li>
<li>跟使用注意力的seq2seq不同，Transformer是纯基于注意力</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/9.png?raw=true"
                     
                ></p>
<h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><p>编码器使用layer normalization</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/10.png?raw=true"
                     
                ><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/11.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/12.png?raw=true"
                     
                ></p>
<h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><p>使用Autoregressive，解码器每次的输入为上次解码器的输出和编码器的输出。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/13.png?raw=true"
                     
                ></p>
<h2 id="多头注意力（multi-head-attention）"><a href="#多头注意力（multi-head-attention）" class="headerlink" title="多头注意力（multi-head attention）"></a>多头注意力（multi-head attention）</h2><ul>
<li>对同一key，value，query，希望抽取不同的信息。例如短距离关系和长距离关系。</li>
<li>多头注意力使用<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.339ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 576.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">h</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
</g>
</svg>个独立的注意力池化。合并各个头（head）输出得到最终输出。</li>
</ul>
<p>以两头注意力为例：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/7.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/8.png?raw=true"
                     
                ></p>
<h2 id="有掩码的多头注意力（masked-multi-head-attention）"><a href="#有掩码的多头注意力（masked-multi-head-attention）" class="headerlink" title="有掩码的多头注意力（masked multi-head attention）"></a>有掩码的多头注意力（masked multi-head attention）</h2><ul>
<li>解码器对序列中一个元素输出时，不应该考虑该元素之后的元素</li>
<li>可以通过掩码来实现。也就是计算<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.129ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 916.8 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
</svg>输出时，假装当前序列长度为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.802ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 345.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
</g>
</svg></li>
</ul>
<p>以计算第二个位置为例：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/14.png?raw=true"
                     
                ></p>
<h2 id="基于位置的前馈网络（相当于全连接）（Positionwise-FFN）"><a href="#基于位置的前馈网络（相当于全连接）（Positionwise-FFN）" class="headerlink" title="基于位置的前馈网络（相当于全连接）（Positionwise FFN）"></a>基于位置的前馈网络（相当于全连接）（Positionwise FFN）</h2><ul>
<li>将输入形状由<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.485ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3222.8 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(b,n,d)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="819" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="1264" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1864" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="2309" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2833" y="0"></use>
</g>
</svg>变换成<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.451ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 2777.7 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(bn,d)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="389" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="819" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1419" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="1864" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2388" y="0"></use>
</g>
</svg></li>
<li>作用两个全连接层</li>
<li>输出形状由<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.451ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 2777.7 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(bn,d)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="389" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="819" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1419" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="1864" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2388" y="0"></use>
</g>
</svg>变化回<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.485ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 3222.8 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(b,n,d)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="819" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="1264" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="1864" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="2309" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="2833" y="0"></use>
</g>
</svg></li>
<li>等价于两层核窗口为1的一位卷积层</li>
</ul>
<h2 id="层归一化（add-amp-norm）"><a href="#层归一化（add-amp-norm）" class="headerlink" title="层归一化（add &amp; norm）"></a>层归一化（add &amp; norm）</h2><ul>
<li>批量归一化（Batch Norm）对每个特征&#x2F;通道里元素进行归一化。不适合序列长度会变的NLP应用。</li>
<li>transformer使用层归一化（Layer Norm）对每个样本里的元素进行归一化。</li>
</ul>
<h2 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h2><ul>
<li>假设编码器中的输出<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.721ex" height="2.009ex" style="vertical-align: -0.671ex;" viewBox="0 -576.1 4185.4 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">y_1,...,y_n</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="693" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="944" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="1834" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="2279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="2725" y="0"></use>
<g transform="translate(3170,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="693" y="-213"></use>
</g>
</g>
</svg></li>
<li>将其作为编码中第<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.802ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 345.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
</g>
</svg>个Transformer块中多头注意力的key和value。它的query来自目标序列。</li>
<li>意味着编码器和解码器中的块的个数和输出维度都是一样的。</li>
</ul>
<h3 id="cross-attention"><a href="#cross-attention" class="headerlink" title="cross attention"></a>cross attention</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_3/15.png?raw=true"
                     
                ></p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><ul>
<li>预测第<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.842ex" height="2.343ex" style="vertical-align: -0.505ex;" viewBox="0 -791.3 2084.9 1008.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">t+1</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2B" x="583" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="1584" y="0"></use>
</g>
</svg>个输出时。</li>
<li>解码器中输入前<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
</g>
</svg>个预测值。在自注意力中，前<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
</g>
</svg>个预测值作为key和value，第<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.84ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 361.5 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
</g>
</svg>个预测值还作为query</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（22）注意力机制（attention pooling）</title>
    <url>/2022/12/15/DL_22/</url>
    <content><![CDATA[<p>卷积、全连接、池化层都只考虑不随意线索</p>
<p>注意力机制则显示的考虑随意线索</p>
<ul>
<li>随意线索被称之为查询（query）</li>
<li>每个输入是一个值（value）和不随意线索（key）的对</li>
<li>通过注意力池化层来有偏向性的选择某些输入</li>
</ul>
<h2 id="非参注意力池化层-非参数注意力汇聚"><a href="#非参注意力池化层-非参数注意力汇聚" class="headerlink" title="非参注意力池化层(非参数注意力汇聚)"></a>非参注意力池化层(非参数注意力汇聚)</h2><ul>
<li><p>给定数据<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="19.573ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 8427.3 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">(x_i,y_i), i = 1,...,n</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1306" y="0"></use>
<g transform="translate(1751,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="2586" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="2975" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="3420" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="4044" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="5100" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="5600" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="6046" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="6491" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="6936" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="7381" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="7826" y="0"></use>
</g>
</svg></p>
</li>
<li><p>平均池化是最简单的方案：<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.815ex" height="6.343ex" style="vertical-align: -3.005ex;" viewBox="0 -1437.2 6809.2 2730.8" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">f(x) = \frac{1}{n} \sum_iy_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="940" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1512" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2179" y="0"></use>
<g transform="translate(2958,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="720" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="110" y="676"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="60" y="-686"></use>
</g>
</g>
<g transform="translate(4363,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="848" y="-1536"></use>
</g>
<g transform="translate(5974,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
</g>
</svg></p>
</li>
<li><p>更好的方案是60年代提出来的Nadaraya-Watson核回归</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.169ex" height="7.009ex" style="vertical-align: -3.171ex;" viewBox="0 -1652.5 12989.4 3017.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">f(x) = \sum_{i=1}^{n} \frac{K(x-x_i)}{\sum_{j=1}^{n}K(x-x_j)}y_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="940" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1512" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2179" y="0"></use>
<g transform="translate(3236,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
<g transform="translate(4680,0)">
<g transform="translate(286,0)">
<rect stroke="none" width="7067" height="60" x="0" y="220"></rect>
<g transform="translate(1343,770)">
 <use xlink:href="#E1-MJMATHI-4B" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="889" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="1279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="2073" y="0"></use>
<g transform="translate(3074,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3991" y="0"></use>
</g>
<g transform="translate(60,-812)">
 <use xlink:href="#E1-MJSZ1-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="1494" y="675"></use>
<g transform="translate(1056,-287)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="412" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1191" y="0"></use>
</g>
 <use xlink:href="#E1-MJMATHI-4B" x="2519" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="3408" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="3798" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="4592" y="0"></use>
<g transform="translate(5593,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="6557" y="0"></use>
</g>
</g>
</g>
<g transform="translate(12154,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
</g>
</svg></p>
</li>
</ul>
<h3 id="Nadaraya-Watson核回归"><a href="#Nadaraya-Watson核回归" class="headerlink" title="Nadaraya-Watson核回归"></a>Nadaraya-Watson核回归</h3><p>使用高斯核<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.99ex" height="6.676ex" style="vertical-align: -2.838ex;" viewBox="0 -1652.5 10329 2874.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">K(u) = \frac{1}{\sqrt{2\pi}}exp(-\frac{u^2}{2})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-4B" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C0" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path>
<path stroke-width="1" id="E1-MJMAIN-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-4B" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="889" y="0"></use>
 <use xlink:href="#E1-MJMATHI-75" x="1279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1851" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2518" y="0"></use>
<g transform="translate(3297,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2027" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="763" y="676"></use>
<g transform="translate(60,-915)">
 <use xlink:href="#E1-MJMAIN-221A" x="0" y="33"></use>
<rect stroke="none" width="1074" height="60" x="833" y="774"></rect>
<g transform="translate(833,0)">
 <use xlink:href="#E1-MJMAIN-32" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3C0" x="500" y="0"></use>
</g>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMATHI-65" x="5842" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="6309" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="6881" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="7385" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="7774" y="0"></use>
<g transform="translate(8553,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="1146" height="60" x="0" y="220"></rect>
<g transform="translate(60,676)">
 <use xlink:href="#E1-MJMATHI-75" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="809" y="513"></use>
</g>
 <use xlink:href="#E1-MJMAIN-32" x="322" y="-687"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9939" y="0"></use>
</g>
</svg></p>
<p>那么有</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.015ex" height="8.009ex" style="vertical-align: -3.505ex;" viewBox="0 -1939.5 16367.7 3448.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">f(x) = \sum_{i=1}^{n}\frac{exp(-\frac{1}{2}(x-x_i)^2)}{\sum_{j=1}^{n}exp(-\frac{1}{2}(x-x_j)^2)}y_i </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJSZ1-2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="940" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1512" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2179" y="0"></use>
<g transform="translate(3236,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
<g transform="translate(4680,0)">
<g transform="translate(286,0)">
<rect stroke="none" width="10445" height="60" x="0" y="220"></rect>
<g transform="translate(1343,936)">
 <use xlink:href="#E1-MJMATHI-65" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="466" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="1039" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="1542" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1932" y="0"></use>
<g transform="translate(2710,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="473" height="60" x="0" y="220"></rect>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="84" y="629"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="84" y="-589"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="3424" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="3813" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="4608" y="0"></use>
<g transform="translate(5609,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
<g transform="translate(6526,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="513"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="7369" y="0"></use>
</g>
<g transform="translate(60,-937)">
 <use xlink:href="#E1-MJSZ1-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="1494" y="675"></use>
<g transform="translate(1056,-287)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="412" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1191" y="0"></use>
</g>
 <use xlink:href="#E1-MJMATHI-65" x="2519" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="2985" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="3558" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="4061" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="4451" y="0"></use>
<g transform="translate(5229,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="473" height="60" x="0" y="220"></rect>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="84" y="629"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="84" y="-589"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="5943" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="6333" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="7127" y="0"></use>
<g transform="translate(8128,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="809" y="-213"></use>
</g>
<g transform="translate(9092,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="408"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9936" y="0"></use>
</g>
</g>
</g>
<g transform="translate(15532,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
</g>
</svg></p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="31.849ex" height="6.843ex" style="vertical-align: -3.005ex;" viewBox="0 -1652.5 13712.9 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title"> = \sum_{i=1}^{n}softmax(-\frac{1}{2}(x-x_i)^2)y_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-3D" x="0" y="0"></use>
<g transform="translate(1056,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
 <use xlink:href="#E1-MJMATHI-73" x="2667" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="3136" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="3622" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="4172" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="4534" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="5412" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="5942" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="6514" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="6904" y="0"></use>
<g transform="translate(7682,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="8543" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="8932" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="9727" y="0"></use>
<g transform="translate(10728,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
<g transform="translate(11645,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="12488" y="0"></use>
<g transform="translate(12878,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
</g>
</svg></p>
<h2 id="参数化的注意力机制"><a href="#参数化的注意力机制" class="headerlink" title="参数化的注意力机制"></a>参数化的注意力机制</h2><ul>
<li>在之前的基础上引入可以学习的<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.664ex" height="1.676ex" style="vertical-align: -0.338ex;" viewBox="0 -576.1 716.5 721.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">w</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-77" x="0" y="0"></use>
</g>
</svg></li>
</ul>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="40.386ex" height="6.843ex" style="vertical-align: -3.005ex;" viewBox="0 -1652.5 17388.2 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">f(x) = \sum_{i=1}^{n}softmax(-\frac{1}{2}((x-x_i)w)^2)y_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="940" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1512" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2179" y="0"></use>
<g transform="translate(3236,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6E" x="721" y="1627"></use>
</g>
 <use xlink:href="#E1-MJMATHI-73" x="4847" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="5316" y="0"></use>
 <use xlink:href="#E1-MJMATHI-66" x="5802" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="6352" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="6714" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="7592" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="8122" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="8694" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="9084" y="0"></use>
<g transform="translate(9862,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="10723" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="11112" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="11502" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="12296" y="0"></use>
<g transform="translate(13297,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="809" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="14214" y="0"></use>
 <use xlink:href="#E1-MJMATHI-77" x="14603" y="0"></use>
<g transform="translate(15320,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="16163" y="0"></use>
<g transform="translate(16553,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-213"></use>
</g>
</g>
</svg></p>
<h2 id="注意力评分函数"><a href="#注意力评分函数" class="headerlink" title="注意力评分函数"></a>注意力评分函数</h2><ul>
<li>高斯核函数部分可以视为注意力评分函数，简称评分函数（scoring function），然后把这个函数的输出结果输入到softmax函数中运算。</li>
<li>通过上述步骤。将得到与key对应的value的概率分布（即注意力权重）</li>
</ul>
<h3 id="两种常见的分数计算：（重要）"><a href="#两种常见的分数计算：（重要）" class="headerlink" title="两种常见的分数计算：（重要）"></a>两种常见的分数计算：（重要）</h3><ul>
<li>将query和key合并起来进入一个单输出隐藏层的MLP（加性）</li>
<li>直接将query和key做内积（点积）</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（25）BERT</title>
    <url>/2023/02/13/DL_25/</url>
    <content><![CDATA[<p>创建BERT的动机：预训练的模型抽取了足够多的信息，新的任务只需要增加一个简单的输出层。</p>
<h2 id="BERT架构"><a href="#BERT架构" class="headerlink" title="BERT架构"></a>BERT架构</h2><ul>
<li><p>只有编码器的Transformer</p>
</li>
<li><p>两个版本：</p>
<ul>
<li><p>Base:</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="70.435ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 30326.2 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\#blocks=12,hidden size=768,\#heads=12,\#parameters=110M</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-23" d="M56 347Q56 360 70 367H313L355 524Q394 676 401 686Q406 694 416 694Q434 694 436 676Q436 672 396 522Q355 374 355 369L354 367H543L585 524Q626 679 630 685Q636 694 646 694Q653 694 659 689T665 678Q665 668 626 522Q585 374 585 369L584 367H762Q777 359 777 347Q777 334 767 331T722 327H667H572L552 251L531 174Q531 173 647 173H720Q756 173 766 170T777 153T762 133H519L477 -24Q436 -179 432 -185Q426 -194 416 -194Q409 -194 403 -189T397 -177Q397 -167 436 -21Q477 125 477 131L478 133H289L247 -24Q206 -179 202 -185Q196 -194 186 -194Q179 -194 173 -189T167 -177Q167 -167 206 -21Q247 125 247 131L248 133H70Q56 140 56 153Q56 168 72 173H260L280 249L301 326Q301 327 186 327H72Q56 332 56 347ZM531 326Q531 327 437 327H342L322 251L301 174Q301 173 395 173H490L510 249L531 326Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path>
<path stroke-width="1" id="E1-MJMAIN-37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path>
<path stroke-width="1" id="E1-MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path>
<path stroke-width="1" id="E1-MJMAIN-38" d="M70 417T70 494T124 618T248 666Q319 666 374 624T429 515Q429 485 418 459T392 417T361 389T335 371T324 363L338 354Q352 344 366 334T382 323Q457 264 457 174Q457 95 399 37T249 -22Q159 -22 101 29T43 155Q43 263 172 335L154 348Q133 361 127 368Q70 417 70 494ZM286 386L292 390Q298 394 301 396T311 403T323 413T334 425T345 438T355 454T364 471T369 491T371 513Q371 556 342 586T275 624Q268 625 242 625Q201 625 165 599T128 534Q128 511 141 492T167 463T217 431Q224 426 228 424L286 386ZM250 21Q308 21 350 55T392 137Q392 154 387 169T375 194T353 216T330 234T301 253T274 270Q260 279 244 289T218 306L210 311Q204 311 181 294T133 239T107 157Q107 98 150 60T250 21Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMATHI-4D" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-23" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="833" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6C" x="1263" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="1561" y="0"></use>
 <use xlink:href="#E1-MJMATHI-63" x="2047" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6B" x="2480" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="3002" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3749" y="0"></use>
<g transform="translate(4805,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-32" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5806" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="6251" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="6828" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="7173" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="7697" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="8220" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="8687" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="9287" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="9757" y="0"></use>
 <use xlink:href="#E1-MJMATHI-7A" x="10102" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="10571" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="11315" y="0"></use>
<g transform="translate(12371,0)">
 <use xlink:href="#E1-MJMAIN-37"></use>
 <use xlink:href="#E1-MJMAIN-36" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-38" x="1001" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="13873" y="0"></use>
 <use xlink:href="#E1-MJMAIN-23" x="14318" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="15151" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="15728" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="16194" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="16724" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="17247" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="17995" y="0"></use>
<g transform="translate(19051,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-32" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="20052" y="0"></use>
 <use xlink:href="#E1-MJMAIN-23" x="20497" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="21331" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="21834" y="0"></use>
 <use xlink:href="#E1-MJMATHI-72" x="22364" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="22815" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="23345" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="24223" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="24690" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="25051" y="0"></use>
 <use xlink:href="#E1-MJMATHI-72" x="25518" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="25969" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="26716" y="0"></use>
<g transform="translate(27773,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-31" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"></use>
</g>
 <use xlink:href="#E1-MJMATHI-4D" x="29274" y="0"></use>
</g>
</svg></p>
</li>
<li><p>Large:</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="71.598ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 30826.7 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\#blocks=24,hidden size=1024,\#heads=16,\#parameters=340M</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-23" d="M56 347Q56 360 70 367H313L355 524Q394 676 401 686Q406 694 416 694Q434 694 436 676Q436 672 396 522Q355 374 355 369L354 367H543L585 524Q626 679 630 685Q636 694 646 694Q653 694 659 689T665 678Q665 668 626 522Q585 374 585 369L584 367H762Q777 359 777 347Q777 334 767 331T722 327H667H572L552 251L531 174Q531 173 647 173H720Q756 173 766 170T777 153T762 133H519L477 -24Q436 -179 432 -185Q426 -194 416 -194Q409 -194 403 -189T397 -177Q397 -167 436 -21Q477 125 477 131L478 133H289L247 -24Q206 -179 202 -185Q196 -194 186 -194Q179 -194 173 -189T167 -177Q167 -167 206 -21Q247 125 247 131L248 133H70Q56 140 56 153Q56 168 72 173H260L280 249L301 326Q301 327 186 327H72Q56 332 56 347ZM531 326Q531 327 437 327H342L322 251L301 174Q301 173 395 173H490L510 249L531 326Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path>
<path stroke-width="1" id="E1-MJMATHI-70" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path>
<path stroke-width="1" id="E1-MJMATHI-72" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path>
<path stroke-width="1" id="E1-MJMATHI-4D" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-23" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="833" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6C" x="1263" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="1561" y="0"></use>
 <use xlink:href="#E1-MJMATHI-63" x="2047" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6B" x="2480" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="3002" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3749" y="0"></use>
<g transform="translate(4805,0)">
 <use xlink:href="#E1-MJMAIN-32"></use>
 <use xlink:href="#E1-MJMAIN-34" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5806" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="6251" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="6828" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="7173" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="7697" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="8220" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="8687" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="9287" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="9757" y="0"></use>
 <use xlink:href="#E1-MJMATHI-7A" x="10102" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="10571" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="11315" y="0"></use>
<g transform="translate(12371,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-30" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-32" x="1001" y="0"></use>
 <use xlink:href="#E1-MJMAIN-34" x="1501" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="14373" y="0"></use>
 <use xlink:href="#E1-MJMAIN-23" x="14818" y="0"></use>
 <use xlink:href="#E1-MJMATHI-68" x="15652" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="16228" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="16695" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="17224" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="17748" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="18495" y="0"></use>
<g transform="translate(19552,0)">
 <use xlink:href="#E1-MJMAIN-31"></use>
 <use xlink:href="#E1-MJMAIN-36" x="500" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="20553" y="0"></use>
 <use xlink:href="#E1-MJMAIN-23" x="20998" y="0"></use>
 <use xlink:href="#E1-MJMATHI-70" x="21831" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="22335" y="0"></use>
 <use xlink:href="#E1-MJMATHI-72" x="22864" y="0"></use>
 <use xlink:href="#E1-MJMATHI-61" x="23316" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="23845" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="24724" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="25190" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="25552" y="0"></use>
 <use xlink:href="#E1-MJMATHI-72" x="26018" y="0"></use>
 <use xlink:href="#E1-MJMATHI-73" x="26470" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="27217" y="0"></use>
<g transform="translate(28273,0)">
 <use xlink:href="#E1-MJMAIN-33"></use>
 <use xlink:href="#E1-MJMAIN-34" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="1001" y="0"></use>
</g>
 <use xlink:href="#E1-MJMATHI-4D" x="29775" y="0"></use>
</g>
</svg></p>
</li>
</ul>
</li>
<li><p>在大规模数据上训练 &gt; 3B 词</p>
</li>
</ul>
<h2 id="对输入的修改"><a href="#对输入的修改" class="headerlink" title="对输入的修改"></a>对输入的修改</h2><ul>
<li>每个样本是一个句子对</li>
<li>加入额外的片段嵌入</li>
<li>位置编码可学习</li>
</ul>
<h2 id="预训练任务1：带掩码的语言模型"><a href="#预训练任务1：带掩码的语言模型" class="headerlink" title="预训练任务1：带掩码的语言模型"></a>预训练任务1：带掩码的语言模型</h2><ul>
<li><p>Transformer的编码器是双向的，标准语言模型要求单向</p>
</li>
<li><p>带掩码的语言模型每次随机（15%概率）将一些词元换成&lt;mask&gt;</p>
</li>
<li><p>因为微调任务中不出现&lt;mask&gt;</p>
<p>80%概率下，将选中的词元变成&lt;mask&gt;</p>
<p>10%概率下换成一个随机词元</p>
<p>10%概率下保持原有的词元</p>
</li>
</ul>
<h2 id="预训练任务2：下一句子预测"><a href="#预训练任务2：下一句子预测" class="headerlink" title="预训练任务2：下一句子预测"></a>预训练任务2：下一句子预测</h2><ul>
<li><p>预测一个句子对中两个句子是不是相邻</p>
</li>
<li><p>训练样本中：</p>
<p>50%概率选择相邻句子对：&lt;cls&gt;this movie is great &lt;sep&gt; i like it &lt;sep&gt;</p>
<p>50%概率选择随机句子对：&lt;cls&gt;this movie is great &lt;sep&gt; hello world&lt;sep&gt;</p>
</li>
<li><p>将&lt;cls&gt;对应的输出放到一个全连接层来预测</p>
</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>动手学习深度学习（26）优化算法</title>
    <url>/2023/02/14/DL_26/</url>
    <content><![CDATA[<p> 优化算法使我们能够继续更新模型参数，并使损失函数的值最小化。优化算法对于深度学习非常重要。一方面，训练复杂的深度学习模型可能需要数小时、几天甚至数周。优化算法的性能直接影响模型的训练效率。另一方面，了解不同优化算法的原则及其超参数的作用将使我们能够以有针对性的方式调整超参数，以提高深度学习模型的性能。</p>
<h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><ul>
<li><p>一般形式<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.054ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 4329 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">minimize</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-6D" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="878" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="1224" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="1824" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6D" x="2170" y="0"></use>
 <use xlink:href="#E1-MJMATHI-69" x="3048" y="0"></use>
 <use xlink:href="#E1-MJMATHI-7A" x="3394" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="3862" y="0"></use>
</g>
</svg>   <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.418ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 1902 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">f(x)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-66" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="550" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="940" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1512" y="0"></use>
</g>
</svg>          <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.306ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 3145.5 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">subject</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-75" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-63" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-75" x="469" y="0"></use>
 <use xlink:href="#E1-MJMATHI-62" x="1042" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6A" x="1471" y="0"></use>
 <use xlink:href="#E1-MJMATHI-65" x="1884" y="0"></use>
 <use xlink:href="#E1-MJMATHI-63" x="2350" y="0"></use>
 <use xlink:href="#E1-MJMATHI-74" x="2784" y="0"></use>
</g>
</svg> <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.967ex" height="2.009ex" style="vertical-align: -0.338ex;" viewBox="0 -719.6 847 865.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">to</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6F" x="361" y="0"></use>
</g>
</svg> <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.937ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 2556.1 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">x \in C</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-43" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2208" x="850" y="0"></use>
 <use xlink:href="#E1-MJMATHI-43" x="1795" y="0"></use>
</g>
</svg></p>
</li>
<li><p>局部最优与全局最优。凸优化问题局部最小一定是全局最小。</p>
<ul>
<li>凸：线性回归、softmax回归</li>
<li>非凸：其他、MLP，CNN，RNN，attention，…</li>
</ul>
</li>
<li><p>梯度下降、随机梯度下降（求导很贵的时候）、小批量随机梯度下降</p>
</li>
</ul>
<h3 id="冲量法-moment"><a href="#冲量法-moment" class="headerlink" title="冲量法(moment)"></a>冲量法(moment)</h3><ul>
<li><p>冲量法使用平滑过的梯度对权重更新</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="20.656ex" height="6.676ex" style="vertical-align: -3.338ex;" viewBox="0 -1437.2 8893.3 2874.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">g_t = \frac{1}{b}\sum_{i\in I_t}\nabla l_i(x_{t-1})</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-62" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-49" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2207" d="M46 676Q46 679 51 683H781Q786 679 786 676Q786 674 617 326T444 -26Q439 -33 416 -33T388 -26Q385 -22 216 326T46 676ZM697 596Q697 597 445 597T193 596Q195 591 319 336T445 80L697 596Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1110" y="0"></use>
<g transform="translate(1889,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMATHI-62" x="95" y="-715"></use>
</g>
</g>
<g transform="translate(3194,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(69,-1102)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2208" x="345" y="0"></use>
<g transform="translate(716,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-49" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMATHI-74" x="542" y="-203"></use>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2207" x="4805" y="0"></use>
<g transform="translate(5639,0)">
 <use xlink:href="#E1-MJMATHI-6C" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="422" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="6281" y="0"></use>
<g transform="translate(6671,0)">
 <use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use>
<g transform="translate(572,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="8503" y="0"></use>
</g>
</svg></p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.214ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 6550.2 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v_t = \beta v_{t-1} + g_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1118" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3B2" x="2175" y="0"></use>
<g transform="translate(2748,0)">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
<g transform="translate(485,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="4716" y="0"></use>
<g transform="translate(5717,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-213"></use>
</g>
</g>
</svg>            <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.375ex" height="2.509ex" style="vertical-align: -0.838ex;" viewBox="0 -719.6 7050.2 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">w_t = w_{t-1} - \mu v_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3BC" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path>
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-77" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1013" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1349" y="0"></use>
<g transform="translate(2406,0)">
 <use xlink:href="#E1-MJMATHI-77" x="0" y="0"></use>
<g transform="translate(716,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="4604" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3BC" x="5605" y="0"></use>
<g transform="translate(6209,0)">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
</g>
</g>
</svg></p>
<p>梯度平滑：<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.252ex" height="3.009ex" style="vertical-align: -0.671ex;" viewBox="0 -1006.6 16469.6 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v_t = g_t + \beta g_{t-1} + \beta^2g_{t-2}+\beta^3g_{t-3}+...</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1118" y="0"></use>
<g transform="translate(2175,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="3230" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3B2" x="4231" y="0"></use>
<g transform="translate(4804,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="6764" y="0"></use>
<g transform="translate(7765,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="814" y="583"></use>
</g>
<g transform="translate(8794,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="10754" y="0"></use>
<g transform="translate(11755,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="814" y="583"></use>
</g>
<g transform="translate(12784,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="14522" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="15300" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="15745" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="16191" y="0"></use>
</g>
</svg></p>
</li>
<li><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.332ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 573.5 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\beta</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
</g>
</svg>常见取值<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.607ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 8011.5 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">[0.5,0.9,0.95,0.99]</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-5B" x="0" y="0"></use>
<g transform="translate(278,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-35" x="779" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1558" y="0"></use>
<g transform="translate(2003,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="779" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="3282" y="0"></use>
<g transform="translate(3727,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#E1-MJMAIN-35" x="1279" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5507" y="0"></use>
<g transform="translate(5953,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="1279" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-5D" x="7733" y="0"></use>
</g>
</svg></p>
</li>
</ul>
<h3 id="Adam（比冲量法更平滑）"><a href="#Adam（比冲量法更平滑）" class="headerlink" title="Adam（比冲量法更平滑）"></a>Adam（比冲量法更平滑）</h3><ul>
<li><p>记录<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.434ex" height="2.843ex" style="vertical-align: -0.838ex;" viewBox="0 -863.1 10520 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v_t = \beta_1v_{t-1}+(1-\beta_1)g_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1118" y="0"></use>
<g transform="translate(2175,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
</g>
<g transform="translate(3195,0)">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
<g transform="translate(485,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="5163" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="6164" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="6553" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="7276" y="0"></use>
<g transform="translate(8276,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9297" y="0"></use>
<g transform="translate(9686,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-213"></use>
</g>
</g>
</svg>，通常<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.44ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 3634 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\beta_1=0.9</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1298" y="0"></use>
<g transform="translate(2354,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="779" y="0"></use>
</g>
</g>
</svg></p>
</li>
<li><p>展开<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="48.631ex" height="3.176ex" style="vertical-align: -0.838ex;" viewBox="0 -1006.6 20938.1 1367.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v_t = (1-\beta_1)(g_t + \beta g_{t-1} + \beta^2g_{t-2}+\beta^3g_{t-3}+...)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1118" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="2175" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="2564" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="3287" y="0"></use>
<g transform="translate(4288,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5308" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="5698" y="0"></use>
<g transform="translate(6087,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="7142" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3B2" x="8143" y="0"></use>
<g transform="translate(8717,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="10676" y="0"></use>
<g transform="translate(11677,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="814" y="583"></use>
</g>
<g transform="translate(12707,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="14666" y="0"></use>
<g transform="translate(15667,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="814" y="583"></use>
</g>
<g transform="translate(16697,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
<g transform="translate(477,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-33" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="18434" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="19213" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="19658" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="20103" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="20548" y="0"></use>
</g>
</svg></p>
</li>
<li><p>因为<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.419ex" height="6.843ex" style="vertical-align: -3.005ex;" viewBox="0 -1652.5 7069.5 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\sum_{i=0}^{\infty}\beta_{1}^{i}=\frac{1}{1-\beta_1}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-221E" d="M55 217Q55 305 111 373T254 442Q342 442 419 381Q457 350 493 303L507 284L514 294Q618 442 747 442Q833 442 888 374T944 214Q944 128 889 59T743 -11Q657 -11 580 50Q542 81 506 128L492 147L485 137Q381 -11 252 -11Q166 -11 111 57T55 217ZM907 217Q907 285 869 341T761 397Q740 397 720 392T682 378T648 359T619 335T594 310T574 285T559 263T548 246L543 238L574 198Q605 158 622 138T664 94T714 61T765 51Q827 51 867 100T907 217ZM92 214Q92 145 131 89T239 33Q357 33 456 193L425 233Q364 312 334 337Q285 380 233 380Q171 380 132 331T92 214Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-30" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-221E" x="521" y="1627"></use>
<g transform="translate(1611,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="814" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-435"></use>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="2909" y="0"></use>
<g transform="translate(3687,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2863" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="1181" y="676"></use>
<g transform="translate(60,-726)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
</g>
</g>
</g>
</g>
</g>
</svg>，所以权重和为1</p>
</li>
<li><p>由于<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.443ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 2774 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">v_0=0</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-30" x="686" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1217" y="0"></use>
 <use xlink:href="#E1-MJMAIN-30" x="2273" y="0"></use>
</g>
</svg>，且<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.419ex" height="7.176ex" style="vertical-align: -3.005ex;" viewBox="0 -1796 7069.5 3089.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\sum_{i=0}^{t}\beta_1^i=\frac{1-\beta_1^t}{1-\beta_1}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-30" x="1124" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="840" y="1627"></use>
<g transform="translate(1611,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="814" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-435"></use>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="2909" y="0"></use>
<g transform="translate(3687,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2863" height="60" x="0" y="220"></rect>
<g transform="translate(60,827)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="814" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-435"></use>
</g>
</g>
<g transform="translate(60,-726)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-213"></use>
</g>
</g>
</g>
</g>
</g>
</svg>，修正<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.36ex" height="5.676ex" style="vertical-align: -2.838ex;" viewBox="0 -1221.9 5321.8 2443.8" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\hat{v}_t=\frac{v_t}{1-\beta_1^t}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-76" x="7" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="27" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="747" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1161" y="0"></use>
<g transform="translate(1940,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2863" height="60" x="0" y="220"></rect>
<g transform="translate(1011,677)">
 <use xlink:href="#E1-MJMATHI-76" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="686" y="-213"></use>
</g>
<g transform="translate(60,-816)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="814" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="801" y="-435"></use>
</g>
</g>
</g>
</g>
</g>
</svg>(修正针对t较小的情况)</p>
</li>
<li><p>类似记录<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="24.597ex" height="3.176ex" style="vertical-align: -1.005ex;" viewBox="0 -934.9 10590.2 1367.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">s_t = \beta_2s_{t-1}+(1-\beta_2)g_t^2</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="663" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1102" y="0"></use>
<g transform="translate(2159,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="801" y="-213"></use>
</g>
<g transform="translate(3179,0)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
<g transform="translate(469,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="5131" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="6132" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="6521" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="7244" y="0"></use>
<g transform="translate(8244,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="801" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="9265" y="0"></use>
<g transform="translate(9654,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="680" y="488"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-395"></use>
</g>
</g>
</svg>，通常<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.765ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 4635 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\beta_2=0.999</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
<path stroke-width="1" id="E1-MJMAIN-39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="801" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1298" y="0"></use>
<g transform="translate(2354,0)">
 <use xlink:href="#E1-MJMAIN-30"></use>
 <use xlink:href="#E1-MJMAIN-2E" x="500" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="779" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="1279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-39" x="1780" y="0"></use>
</g>
</g>
</svg>，且修正<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.425ex" height="5.676ex" style="vertical-align: -2.838ex;" viewBox="0 -1221.9 5349.6 2443.8" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\hat{s}_t=\frac{s_t}{1-\beta_2^t}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-73" x="15" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="55" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="786" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1189" y="0"></use>
<g transform="translate(1967,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="2863" height="60" x="0" y="220"></rect>
<g transform="translate(1019,677)">
 <use xlink:href="#E1-MJMATHI-73" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="663" y="-213"></use>
</g>
<g transform="translate(60,-816)">
 <use xlink:href="#E1-MJMAIN-31" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="722" y="0"></use>
<g transform="translate(1723,0)">
 <use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="814" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="801" y="-435"></use>
</g>
</g>
</g>
</g>
</g>
</svg></p>
</li>
<li><p>计算重新调整后的梯度<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.095ex" height="6.676ex" style="vertical-align: -3.171ex;" viewBox="0 -1508.9 6068.8 2874.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">g'_t=\frac{\hat{v}_t}{\sqrt{\hat{s}_t}+\epsilon}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMATHI-76" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path>
<path stroke-width="1" id="E1-MJSZ1-221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3F5" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="680" y="445"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-395"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1110" y="0"></use>
<g transform="translate(1889,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="3661" height="60" x="0" y="220"></rect>
<g transform="translate(1388,677)">
 <use xlink:href="#E1-MJMATHI-76" x="7" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="27" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="747" y="-213"></use>
</g>
<g transform="translate(60,-966)">
 <use xlink:href="#E1-MJSZ1-221A" x="0" y="35"></use>
<rect stroke="none" width="911" height="60" x="1000" y="826"></rect>
<g transform="translate(1000,0)">
 <use xlink:href="#E1-MJMATHI-73" x="15" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="55" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="786" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2B" x="2134" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3F5" x="3135" y="0"></use>
</g>
</g>
</g>
</g>
</svg></p>
</li>
<li><p>最后更新<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.124ex" height="2.843ex" style="vertical-align: -1.005ex;" viewBox="0 -791.3 6942.2 1223.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">w_t=w_{t-1}-\eta g'_t</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-77" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B7" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-77" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1013" y="-213"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1349" y="0"></use>
<g transform="translate(2406,0)">
 <use xlink:href="#E1-MJMATHI-77" x="0" y="0"></use>
<g transform="translate(716,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2212" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="4604" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3B7" x="5605" y="0"></use>
<g transform="translate(6109,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="680" y="445"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="675" y="-395"></use>
</g>
</g>
</svg></p>
</li>
</ul>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>Python学习之路（16）总结各种文件的读取和写入方法</title>
    <url>/2023/02/14/Python_16/</url>
    <content><![CDATA[<p> 每次需要读取csv，json或者txt等类型文件时，总是要去google一下，所以在这里整理一下常用文件的读写，方便后续使用。</p>
<h2 id="csv文件"><a href="#csv文件" class="headerlink" title="csv文件"></a>csv文件</h2><p>python官方文档中有csv库的详细解析，具体参考：<a class="link"   href="https://docs.python.org/zh-cn/3/library/csv.html" >csv — CSV 文件读写 — Python 3.11.2 文档 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="使用Python-I-x2F-O"><a href="#使用Python-I-x2F-O" class="headerlink" title="使用Python I&#x2F;O"></a>使用Python I&#x2F;O</h3><p>使用python I&#x2F;O方法进行读取时即是新建一个List 列表然后按照先行后列的顺序(类似C语言中的二维数组)将数据存进空的List对象中，如果需要将其转化为<code>numpy</code>数组也可以使用<code>np.array</code>(List name)进行对象之间的转化。</p>
<h4 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> csv<br><br>birth_data = []<br>birth_header = []<br>birth_weight_file = <span class="hljs-string">&#x27;c:/file.csv&#x27;</span> <span class="hljs-comment"># 文件地址</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(birth_weight_file) <span class="hljs-keyword">as</span> csvfile:<br>    csv_reader = csv.reader(csvfile)  <span class="hljs-comment"># 使用csv.reader读取csvfile中的文件</span><br>    birth_header = <span class="hljs-built_in">next</span>(csv_reader)  <span class="hljs-comment"># 读取第一行每一列的标题</span><br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> csv_reader:  <span class="hljs-comment"># 将csv 文件中的数据保存到birth_data中</span><br>        birth_data.append(row)<br><br>birth_data = [[<span class="hljs-built_in">float</span>(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> row] <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> birth_data]  <span class="hljs-comment"># 将数据从string形式转换为float形式</span><br><br>birth_data = np.array(birth_data)  <span class="hljs-comment"># 将list数组转化成array数组便于查看数据结构</span><br>birth_header = np.array(birth_header)<br><span class="hljs-built_in">print</span>(birth_data.shape)  <br><span class="hljs-built_in">print</span>(birth_header.shape)<br><span class="hljs-comment"># 打印数据和数据头的形状</span><br><span class="hljs-comment"># (189, 9)</span><br><span class="hljs-comment"># (9,)</span><br>data = torch.FloatTensor(birth_data) <span class="hljs-comment"># 将numpy格式转换为tensor，使其可以使用pytorch相关运算</span><br></code></pre></td></tr></table></figure></div>

<h4 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;test.csv&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> csvfile: <br>    writer = csv.writer(csvfile)<br>    writer.writerow([<span class="hljs-string">&quot;index&quot;</span>,<span class="hljs-string">&quot;a_name&quot;</span>,<span class="hljs-string">&quot;b_name&quot;</span>]) <span class="hljs-comment"># 先写入columns_name</span><br>    writer.writerows([[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]]) <span class="hljs-comment"># 写入多行用writerows</span><br></code></pre></td></tr></table></figure></div>

<h3 id="使用Pandas"><a href="#使用Pandas" class="headerlink" title="使用Pandas"></a>使用Pandas</h3><h4 id="读取文件-1"><a href="#读取文件-1" class="headerlink" title="读取文件"></a>读取文件</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br>csv_data = pd.read_csv(<span class="hljs-string">&#x27;birth_weight.csv&#x27;</span>)  <span class="hljs-comment"># 读取训练数据</span><br><span class="hljs-built_in">print</span>(csv_data.shape)  <span class="hljs-comment"># (189, 9)</span><br>N = <span class="hljs-number">5</span><br>csv_batch_data = csv_data.tail(N)  <span class="hljs-comment"># 取后5条数据</span><br><span class="hljs-built_in">print</span>(csv_batch_data.shape)  <span class="hljs-comment"># (5, 9)</span><br>train_batch_data = csv_batch_data[<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">3</span>, <span class="hljs-number">6</span>))]  <span class="hljs-comment"># 取这20条数据的3到5列值(索引从0开始)</span><br><span class="hljs-built_in">print</span>(train_batch_data)<br><span class="hljs-comment">#      RACE  SMOKE  PTL</span><br><span class="hljs-comment"># 184   0.0    0.0  0.0</span><br><span class="hljs-comment"># 185   0.0    0.0  1.0</span><br><span class="hljs-comment"># 186   0.0    1.0  0.0</span><br><span class="hljs-comment"># 187   0.0    0.0  0.0</span><br><span class="hljs-comment"># 188   0.0    0.0  1.0</span><br></code></pre></td></tr></table></figure></div>

<h4 id="写入文件-1"><a href="#写入文件-1" class="headerlink" title="写入文件"></a>写入文件</h4><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 任意的多组列表</span><br>a = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]<br>b = [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]    <br><span class="hljs-comment"># 字典中的key值即为csv中列名</span><br>dataframe = pd.DataFrame(&#123;<span class="hljs-string">&#x27;a_name&#x27;</span>:a,<span class="hljs-string">&#x27;b_name&#x27;</span>:b&#125;)<br><br><span class="hljs-comment">#将DataFrame存储为csv,index表示是否显示行名，default=True</span><br>dataframe.to_csv(<span class="hljs-string">&quot;test.csv&quot;</span>,index=<span class="hljs-literal">False</span>,sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br></code></pre></td></tr></table></figure></div>

<h2 id="JSON文件"><a href="#JSON文件" class="headerlink" title="JSON文件"></a>JSON文件</h2><p>JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。JSON在python中分别由list和dict组成。JSON模块提供了四个功能：dumps、dump、loads、load。</p>
<h3 id="dumps"><a href="#dumps" class="headerlink" title="dumps"></a>dumps</h3><p>dumps将python中的<strong>字典</strong>转换为<strong>字符串</strong>。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json<br><br>test_dict = &#123;<span class="hljs-string">&#x27;bigberg&#x27;</span>: [<span class="hljs-number">7600</span>, &#123;<span class="hljs-number">1</span>: [[<span class="hljs-string">&#x27;iPhone&#x27;</span>, <span class="hljs-number">6300</span>], [<span class="hljs-string">&#x27;Bike&#x27;</span>, <span class="hljs-number">800</span>], [<span class="hljs-string">&#x27;shirt&#x27;</span>, <span class="hljs-number">300</span>]]&#125;]&#125;<br><span class="hljs-built_in">print</span>(test_dict)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(test_dict)) <span class="hljs-comment"># dict</span><br><span class="hljs-comment">#dumps 将数据转换成字符串</span><br>json_str = json.dumps(test_dict)<br><span class="hljs-built_in">print</span>(json_str)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(json_str)) <span class="hljs-comment"># str</span><br></code></pre></td></tr></table></figure></div>

<h3 id="loads"><a href="#loads" class="headerlink" title="loads"></a>loads</h3><p>loads将<strong>字符串</strong>转换为<strong>字典</strong>。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">new_dict = json.loads(json_str)<br><span class="hljs-built_in">print</span>(new_dict)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(new_dict)) <span class="hljs-comment"># dict</span><br></code></pre></td></tr></table></figure></div>

<h3 id="dump"><a href="#dump" class="headerlink" title="dump"></a>dump</h3><p>dump将数据写入json文件中。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;record.json&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> f:<br>    json.dump(new_dict,f)<br></code></pre></td></tr></table></figure></div>

<h3 id="load"><a href="#load" class="headerlink" title="load"></a>load</h3><p>load把文件打开，并把字符串变换为数据类型。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;record.json&quot;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> load_f:<br>    load_dict = json.load(load_f)<br>    <span class="hljs-built_in">print</span>(load_dict)<br>load_dict[<span class="hljs-string">&#x27;smallberg&#x27;</span>] = [<span class="hljs-number">8200</span>,&#123;<span class="hljs-number">1</span>:[[<span class="hljs-string">&#x27;Python&#x27;</span>,<span class="hljs-number">81</span>],[<span class="hljs-string">&#x27;shirt&#x27;</span>,<span class="hljs-number">300</span>]]&#125;]<br><span class="hljs-built_in">print</span>(load_dict)<br><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;record.json&quot;</span>,<span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> dump_f:<br>    json.dump(load_dict,dump_f)<br></code></pre></td></tr></table></figure></div>

<h2 id="TXT文件"><a href="#TXT文件" class="headerlink" title="TXT文件"></a>TXT文件</h2><p><a href="https://hxiangdou.github.io/2022/10/02/Python_10/">Python学习之路（10）文件和异常 - 顺利毕业企划 (hxiangdou.github.io)</a></p>
]]></content>
      <categories>
        <category>Python学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅机器学习课程（1）Pytorch Tutorial</title>
    <url>/2023/02/15/ML-LHY-1/</url>
    <content><![CDATA[<p> Pytorch作为深度学习常用模块库，里面包含了很多深度学习相关的操作和模块，底层由C++实现，使用张量进行计算，可使用GPU加速。</p>
<h2 id="Pytorch-Documentation"><a href="#Pytorch-Documentation" class="headerlink" title="Pytorch Documentation"></a>Pytorch Documentation</h2><p>参考网址：<a class="link"   href="https://pytorch.org/docs/stable/" >https://pytorch.org/docs/stable/ <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p>常用的模块有：</p>
<ul>
<li>torch.nn -&gt; neural nework</li>
<li>torch.optim -&gt; optimization algorithms</li>
<li>torch.utils.data -&gt; dataset, dataloader</li>
</ul>
<h2 id="Pytorch-Documentation-Example"><a href="#Pytorch-Documentation-Example" class="headerlink" title="Pytorch Documentation Example"></a>Pytorch Documentation Example</h2><p><strong>Function inputs and outputs</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_1/1.png?raw=true"
                      alt="inputs and outputs"
                ></p>
<p><strong>Data type and explanation of each input</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_1/2.png?raw=true"
                     
                ></p>
<p><strong>Some functions behave differently with different inputs</strong></p>
<p>在PyTorch中，参数(parameters)和关键字参数(keyword arguments)是两种不同的概念。</p>
<p>参数是模型中的可学习参数，例如线性层中的权重。它们通常被定义为模型的<code>nn.Module</code>的成员变量，并且可以通过调用<code>nn.Module</code>的成员函数<code>parameters()</code>返回。</p>
<p>关键字参数是函数的额外参数，它们是可选的。它们可以通过向函数提供以参数名称为关键字的额外参数的形式来提供，例如：<code>nn.Linear(in_features, out_features, bias=True)</code>。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_1/3.png?raw=true"
                     
                ></p>
<p><strong>三种不同输入对应的torch.max</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_1/4.png?raw=true"
                     
                ></p>
<h2 id="Common-Errors"><a href="#Common-Errors" class="headerlink" title="Common Errors"></a>Common Errors</h2><div class="note-large notel-red"><div class="notel-title"><p>Tensor on Different Device to Model</p>
</div><div class="notel-content"><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">model = torch.nn.Linear(<span class="hljs-number">5</span>,<span class="hljs-number">1</span>).to(<span class="hljs-string">&quot;cuda:0&quot;</span>) <br>x = torch.randn(<span class="hljs-number">5</span>).to(<span class="hljs-string">&quot;cpu&quot;</span>) <br>y = model(x) <br></code></pre></td></tr></table></figure></div>

<p><strong>Tensor for * is on CPU, but expected them to be on GPU</strong> </p>
<p>&#x3D;&gt; send the tensor to GPU </p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">x = torch.randn(<span class="hljs-number">5</span>).to(<span class="hljs-string">&quot;cuda:0&quot;</span>) <br>y = model(x) <br><span class="hljs-built_in">print</span>(y.shape)<br></code></pre></td></tr></table></figure></div>
 </div></div>

<div class="note-large notel-red"><div class="notel-title"><p>Mismatched Dimensions</p>
</div><div class="notel-content"><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">x = torch.randn(<span class="hljs-number">4</span>,<span class="hljs-number">5</span>)<br>y = torch.randn(<span class="hljs-number">5</span>,<span class="hljs-number">4</span>)<br>z = x + y<br></code></pre></td></tr></table></figure></div>

<p><strong>The size of tensor a (5) must match the size of tensor b (4) at non-singleton  dimension 1</strong> </p>
<p>&#x3D;&gt;  the shape of a tensor is incorrect, use <em>transpose</em>, <em>squeeze</em>, <em>unsqueeze</em> to align  the dimensions</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">y = y.transpose(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>z = x + y<br><span class="hljs-built_in">print</span>(z.shape)<br></code></pre></td></tr></table></figure></div>
 </div></div>

<div class="note-large notel-red"><div class="notel-title"><p>Cuda Out of Memory</p>
</div><div class="notel-content"><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br>resnet18 = models.resnet18().to( <span class="hljs-string">&quot;cuda:0&quot;</span>) <span class="hljs-comment"># Neural Networks for Image Recognition</span><br>data = torch.randn( <span class="hljs-number">512</span>,<span class="hljs-number">3</span>,<span class="hljs-number">244</span>,<span class="hljs-number">244</span>) <span class="hljs-comment"># Create fake data (512 images)</span><br>out = resnet18(data.to( <span class="hljs-string">&quot;cuda:0&quot;</span>)) <span class="hljs-comment"># Use Data as Input and Feed to Model</span><br><span class="hljs-built_in">print</span>(out.shape)<br></code></pre></td></tr></table></figure></div>

<p><strong>CUDA out of memory. Tried to allocate 350.00 MiB (GPU 0; 14.76 GiB total  capacity; 11.94 GiB already allocated; 123.75 MiB free; 13.71 GiB reserved in  total by PyTorch)</strong> </p>
<p>&#x3D;&gt;  The batch size of data is too large to fit in the GPU. Reduce the batch size. </p>
 </div></div>

<div class="note-large notel-red"><div class="notel-title"><p>Mismatched Tensor Type</p>
</div><div class="notel-content"><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br>L = nn.CrossEntropyLoss()<br>outs = torch.randn(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>)<br>labels = torch.Tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0</span>])<br>lossval = L(outs,labels) <span class="hljs-comment"># Calculate CrossEntropyLoss between outs and labels</span><br></code></pre></td></tr></table></figure></div>

<p><strong>expected scalar type Long but found Float</strong> </p>
<p>&#x3D;&gt; labels must be long tensors, cast it to type “Long” to fix this issue</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="code"><pre><code class="hljs python">labels = labels.long()<br>lossval = L(outs,labels)<br><span class="hljs-built_in">print</span>(lossval)<br></code></pre></td></tr></table></figure></div>
 </div></div>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅机器学习课程（2）机器学习任务攻略</title>
    <url>/2023/02/15/ML-LHY-2/</url>
    <content><![CDATA[<p> 对于模型训练的初期，一般遵循下图的调整方向。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/1.png?raw=true"
                      alt="攻略"
                ></p>
<p>optimization fails（优化失败）:（critical point: training loss不再下降）</p>
<ul>
<li>local minima（局部最小值）：无路可走</li>
<li>saddle point（鞍点）：有路可走</li>
</ul>
<h2 id="Batch-and-Momentum（批量和动量）：解决梯度下降停止的问题"><a href="#Batch-and-Momentum（批量和动量）：解决梯度下降停止的问题" class="headerlink" title="Batch and Momentum（批量和动量）：解决梯度下降停止的问题"></a>Batch and Momentum（批量和动量）：解决梯度下降停止的问题</h2><p><strong>batch中的小批量和大批量问题</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/2.png?raw=true"
                      alt="batch"
                ></p>
<h3 id="Momentum-将前一步的update的方向加上当前梯度下降的反方向"><a href="#Momentum-将前一步的update的方向加上当前梯度下降的反方向" class="headerlink" title="Momentum: 将前一步的update的方向加上当前梯度下降的反方向"></a>Momentum: 将前一步的update的方向加上当前梯度下降的反方向</h3><h2 id="自动调整学习率"><a href="#自动调整学习率" class="headerlink" title="自动调整学习率"></a>自动调整学习率</h2><p>一般的梯度下降算法很少会走到critical point，往往会遇到的问题是</p>
<ul>
<li>学习率过大时，模型不断在最低点附近震荡而无法靠近最低点。</li>
<li>学习率过小时，模型需要很大很大的计算量才能缓慢的靠近最低点。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/3.png?raw=true"
                      alt="learning rate"
                ></p>
<p>所以我们要使学习率自动随着梯度的大小进行变化。我们可以通过下面这个式子来设置学习率的更新(parameter dependent learning rate)</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.325ex" height="5.843ex" style="vertical-align: -2.838ex;" viewBox="0 -1293.7 7459.2 2515.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\theta^{t+1}_i \gets \theta^t_i - \frac{\eta}{\sigma^t_i} g^t_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B7" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
<g transform="translate(469,403)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2B" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="663" y="-430"></use>
 <use xlink:href="#E1-MJMAIN-2190" x="2007" y="0"></use>
<g transform="translate(3285,0)">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="663" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="663" y="-430"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="4332" y="0"></use>
<g transform="translate(5111,0)">
<g transform="translate(342,0)">
<rect stroke="none" width="1048" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMATHI-3B7" x="272" y="736"></use>
<g transform="translate(60,-816)">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="810" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="808" y="-430"></use>
</g>
</g>
</g>
<g transform="translate(6622,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="680" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="675" y="-430"></use>
</g>
</g>
</svg>           <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.433ex" height="5.843ex" style="vertical-align: -2.338ex;" viewBox="0 -1508.9 5783.6 2515.6" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">g^t_i = \frac{\partial L}{\partial \theta_i}|_{\theta=\theta^t}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2202" d="M202 508Q179 508 169 520T158 547Q158 557 164 577T185 624T230 675T301 710L333 715H345Q378 715 384 714Q447 703 489 661T549 568T566 457Q566 362 519 240T402 53Q321 -22 223 -22Q123 -22 73 56Q42 102 42 148V159Q42 276 129 370T322 465Q383 465 414 434T455 367L458 378Q478 461 478 515Q478 603 437 639T344 676Q266 676 223 612Q264 606 264 572Q264 547 246 528T202 508ZM430 306Q430 372 401 400T333 428Q270 428 222 382Q197 354 183 323T150 221Q132 149 132 116Q132 21 232 21Q244 21 250 22Q327 35 374 112Q389 137 409 196T430 306Z"></path>
<path stroke-width="1" id="E1-MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="680" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="675" y="-430"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="1114" y="0"></use>
<g transform="translate(1893,0)">
<g transform="translate(397,0)">
<rect stroke="none" width="1501" height="60" x="0" y="220"></rect>
<g transform="translate(126,676)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-4C" x="567" y="0"></use>
</g>
<g transform="translate(60,-736)">
 <use xlink:href="#E1-MJMAIN-2202" x="0" y="0"></use>
<g transform="translate(567,0)">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="663" y="-213"></use>
</g>
</g>
</g>
</g>
<g transform="translate(3912,0)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
<g transform="translate(278,-294)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="469" y="0"></use>
<g transform="translate(882,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMATHI-74" x="578" y="483"></use>
</g>
</g>
</g>
</g>
</svg></p>
<h3 id="Root-Mean-Square-更新方法"><a href="#Root-Mean-Square-更新方法" class="headerlink" title="Root Mean Square 更新方法"></a>Root Mean Square 更新方法</h3><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/4.png?raw=true"
                      alt="square"
                ></p>
<h3 id="RMSProp-更新方法"><a href="#RMSProp-更新方法" class="headerlink" title="RMSProp 更新方法"></a>RMSProp 更新方法</h3><p>最近的梯度有较大的影响，而过去的梯度影响会较小。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/5.png?raw=true"
                      alt="RMSProp"
                ></p>
<p>Adam使用的即为RMSProp+Momentum</p>
<h3 id="Learning-Rate-Scheduling（随时间变化的学习率）"><a href="#Learning-Rate-Scheduling（随时间变化的学习率）" class="headerlink" title="Learning Rate Scheduling（随时间变化的学习率）"></a>Learning Rate Scheduling（随时间变化的学习率）</h3><p>使学习率跟随时间发生变化，以满足模型的要求。</p>
<p><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.731ex" height="6.843ex" style="vertical-align: -2.838ex;" viewBox="0 -1724.2 7634.2 2946.1" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">\theta^{t+1}_i \gets \theta^t_i - \frac{\eta^T}{\sigma^t_i}g^t_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-3B8" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3B7" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q156 442 175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336V326Q503 302 439 53Q381 -182 377 -189Q364 -216 332 -216Q319 -216 310 -208T299 -186Q299 -177 358 57L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-54" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path>
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
<g transform="translate(469,403)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2B" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1140" y="0"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="663" y="-430"></use>
 <use xlink:href="#E1-MJMAIN-2190" x="2007" y="0"></use>
<g transform="translate(3285,0)">
 <use xlink:href="#E1-MJMATHI-3B8" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="663" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="663" y="-430"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="4332" y="0"></use>
<g transform="translate(5111,0)">
<g transform="translate(342,0)">
<rect stroke="none" width="1223" height="60" x="0" y="220"></rect>
<g transform="translate(60,736)">
 <use xlink:href="#E1-MJMATHI-3B7" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-54" x="714" y="513"></use>
</g>
<g transform="translate(147,-816)">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="810" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="808" y="-430"></use>
</g>
</g>
</g>
<g transform="translate(6797,0)">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="680" y="499"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="675" y="-430"></use>
</g>
</g>
</svg></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/ML_LHY_2/6.png?raw=true"
                      alt="scheduling"
                ></p>
<h2 id="classification（分类问题）"><a href="#classification（分类问题）" class="headerlink" title="classification（分类问题）"></a>classification（分类问题）</h2><p>详细版本：<a class="link"   href="https://youtu.be/fZAZUYEelMg" >https://youtu.be/fZAZUYEelMg <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>   <a class="link"   href="https://youtu.be/hSXFuypLukA" >https://youtu.be/hSXFuypLukA <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="Loss-of-Classification"><a href="#Loss-of-Classification" class="headerlink" title="Loss of Classification"></a>Loss of Classification</h3><p>Mean Square Error(MSE)                                    <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="17.282ex" height="5.509ex" style="vertical-align: -3.005ex;" viewBox="0 -1078.4 7440.7 2372" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">e = \sum_i(\hat{y}_i-y'_i)^2</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-65" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="744" y="0"></use>
<g transform="translate(1800,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="848" y="-1536"></use>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="3245" y="0"></use>
<g transform="translate(3634,0)">
 <use xlink:href="#E1-MJMATHI-79" x="1" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="60" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="792" y="-342"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="4761" y="0"></use>
<g transform="translate(5762,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="445"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-430"></use>
</g>
<g transform="translate(6597,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="583"></use>
</g>
</g>
</svg></p>
<p>Cross-entropy(更适合用在分类上)                      <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.248ex" height="5.509ex" style="vertical-align: -3.005ex;" viewBox="0 -1078.4 6995.7 2372" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">e = -\sum_i \hat{y}_i lny'_i</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-65" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="744" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1800" y="0"></use>
<g transform="translate(2745,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="848" y="-1536"></use>
</g>
<g transform="translate(4356,0)">
 <use xlink:href="#E1-MJMATHI-79" x="1" y="0"></use>
 <use xlink:href="#E1-MJMAIN-5E" x="60" y="21"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="792" y="-342"></use>
</g>
 <use xlink:href="#E1-MJMATHI-6C" x="5261" y="0"></use>
 <use xlink:href="#E1-MJMATHI-6E" x="5560" y="0"></use>
<g transform="translate(6160,0)">
 <use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2032" x="706" y="445"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="693" y="-430"></use>
</g>
</g>
</svg></p>
<p><em>minimizing cross-entropy</em> is equivalent to <em>maximizing likelihood</em>.</p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅机器学习课程（3）Self-attention</title>
    <url>/2023/02/15/ML-LHY-3/</url>
    <content><![CDATA[<p> 基本的运算讲解参考：</p>
<p><a href="https://hxiangdou.github.io/2023/02/13/DL_23/">动手学习深度学习（23）自注意力机制（self attention） - 顺利毕业企划 (hxiangdou.github.io)</a></p>
<p><a href="https://hxiangdou.github.io/2023/02/13/DL_24/">动手学习深度学习（24）transformer - 顺利毕业企划 (hxiangdou.github.io)</a></p>
]]></content>
      <categories>
        <category>DeepLearning学习</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DeepLearning</tag>
      </tags>
  </entry>
  <entry>
    <title>南开学术规范与论文写作（第1讲）Writing &amp; Academic Norms</title>
    <url>/2023/02/19/paper-write-method-1/</url>
    <content><![CDATA[<p> 讲解学术规范，以免有意或无意构成学术不端行为。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-1/1.png?raw=true"
                     
                ></p>
<p>自我取证：对工作的开展和执行过程进行记录以便做自证，类似于github时间戳，小组讨论记录等。</p>
<p>需要完成：<a class="link"   href="https://plagiarism.iu.edu/IUcriteria.html" >https://plagiarism.iu.edu/IUcriteria.html <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a> 主页上的考核内容。</p>
]]></content>
      <categories>
        <category>papers-writing</category>
      </categories>
      <tags>
        <tag>papers-writing</tag>
      </tags>
  </entry>
  <entry>
    <title>南开学术规范与论文写作（第3讲）论文写作的准备工作</title>
    <url>/2023/02/24/paper-write-method-3/</url>
    <content><![CDATA[<p> 主要讲解论文开始写作前的准备工作。</p>
<h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><p>对于论文的发表，内容和形式都是必要条件。</p>
<p>论文的内容应当以创新点为核心。</p>
<p>创新点的主要形式分为三种（创新性递减）：</p>
<ul>
<li>发现新的问题去解决（同时提出一种可行的解决方案）</li>
<li>对已有问题提出新的方法</li>
<li>将已有问题的一些方法组合起来进行组合式创新</li>
</ul>
<p>论文的方法应当在某些领域有一定的提高：</p>
<ul>
<li>更少时间花销</li>
<li>更准确的结果</li>
<li>更少内存花销</li>
<li>……</li>
</ul>
<p><strong>不要在论文中写两个以上的贡献</strong>（保持贡献为1个或者2个）</p>
<h2 id="发现新的问题去解决"><a href="#发现新的问题去解决" class="headerlink" title="发现新的问题去解决"></a>发现新的问题去解决</h2><p>这个新问题应当是：</p>
<ul>
<li>具有一定难度和挑战性</li>
<li>对于潜在读者来说有使用价值，或者值得其感兴趣</li>
</ul>
<p>发现新的问题是很困难的。</p>
<h2 id="对已有问题提出新的方法"><a href="#对已有问题提出新的方法" class="headerlink" title="对已有问题提出新的方法"></a>对已有问题提出新的方法</h2><p>新的方法的几个可能来源：</p>
<ul>
<li>从问题本身出发发现新的方法</li>
<li>从其他领域寻找可能的方法</li>
<li>从与作者不同的角度分析问题</li>
</ul>
<h2 id="组合创新"><a href="#组合创新" class="headerlink" title="组合创新"></a>组合创新</h2><p>原创性体现在：</p>
<ul>
<li>为什么选择这些模块进行组合</li>
<li>怎么把不同模块组合起来</li>
</ul>
<h1 id="会议-x2F-期刊"><a href="#会议-x2F-期刊" class="headerlink" title="会议&#x2F;期刊"></a>会议&#x2F;期刊</h1><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-3/1.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-3/2.png?raw=true"
                     
                ></p>
<h1 id="写作规划"><a href="#写作规划" class="headerlink" title="写作规划"></a>写作规划</h1><ul>
<li>快速撰写第一版草稿然后进行修改</li>
<li>了解论文中已经被解释过的内容</li>
<li>了解哪些内容仍然需要被解释</li>
<li>避免书写过多细节，然后发现没有足够的空间</li>
<li>写作会迫使作者重新思考实验：重新实验或者是修改算法</li>
<li>在修改过程中，覆盖需要说的所有内容，并以足够的细节进行说明，然后对其进行润色和缩短</li>
</ul>
]]></content>
      <categories>
        <category>papers-writing</category>
      </categories>
      <tags>
        <tag>papers-writing</tag>
      </tags>
  </entry>
  <entry>
    <title>南开学术规范与论文写作（第2讲）Writing Tips</title>
    <url>/2023/02/24/paper-write-method-2/</url>
    <content><![CDATA[<p> 讲解一些论文写作工作，提高工作效率。</p>
<h1 id="Overleaf"><a href="#Overleaf" class="headerlink" title="Overleaf"></a>Overleaf</h1><p>提供所见即所得的latex文档编写。</p>
<p>可以使用git进行overleaf的版本控制。</p>
<ul>
<li>建议尽量多的换行，减少产生版本冲突的可能</li>
<li>提高对overleaf中warning的注意，尽量避免产生warning</li>
<li>确认本领域的特殊词汇，然后将其添加到词典中</li>
</ul>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p>优秀的版本控制软件。使用<a class="link"   href="https://tortoisegit.org/" >TortoiseGit – Windows Shell Interface to Git <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>可以优化git使用体验。</p>
<ul>
<li>尽可能频繁的进行更新同步</li>
<li>应该参照commit，pull，push的命令顺序</li>
</ul>
<h1 id="Grammarly"><a href="#Grammarly" class="headerlink" title="Grammarly"></a>Grammarly</h1><p>英文语法分析插件，帮助排除word文件的语法错误，并且给出更好的语法。</p>
<h1 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h1><p>可以在以下网站找到视觉论文的Latex源码：</p>
<ul>
<li><a class="link"   href="https://www.overleaf.com/read/nkyrytybmzcm" >https://www.overleaf.com/read/nkyrytybmzcm <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li>
</ul>
<p><strong>使用<code>\newcommand</code>命令来保证文件格式的一致性</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/1.png?raw=true"
                     
                ></p>
<p>添加图片：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/2.png?raw=true"
                     
                ></p>
<p>添加表格</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/3.png?raw=true"
                     
                ></p>
<p><strong>使用<code>Strings</code>规范期刊&#x2F;会议名称</strong></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/4.png?raw=true"
                     
                ></p>
<p>CVPR</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/5.png?raw=true"
                     
                ></p>
<p><strong>Reference</strong></p>
<p>从Google Scholar上复制过来之后，要再检查一遍。</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/6.png?raw=true"
                     
                ></p>
<p><strong>避免很无聊的图</strong></p>
<ul>
<li>使图片内容紧凑、有意义。避免重复的内容。</li>
<li>确保图内文字的大小舒适可读。</li>
</ul>
<p><strong>保留论文的所有中间文件</strong></p>
<p><strong>避免无效的内容</strong></p>
<p>简单的例子：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-2/7.png?raw=true"
                     
                ></p>
<h1 id="常见的Checklist"><a href="#常见的Checklist" class="headerlink" title="常见的Checklist"></a>常见的Checklist</h1><ul>
<li>避免一些会让审稿人误认为无创新性的表达。</li>
<li>使用更好的方式表达结果，以突显论文方法的效果。</li>
<li>用足够的实验确认效果提升是由论文的创新点得到的。</li>
</ul>
<p><strong>一些好的习惯</strong></p>
<ul>
<li>开源代码，并且说明代码已经开源</li>
<li>分析算法尚存的一些问题</li>
<li>提供足够的理论证明</li>
<li>分析算法的计算开销、时间开销、内存开销等内容</li>
<li>使自己的idea保持sharp，可以采用与原有方法的对比</li>
<li>尽量使用少量的符号进行表达</li>
<li>尽量使用公平的环境和条件来与现有方法效果进行对比</li>
</ul>
<h1 id="分析审稿人回复"><a href="#分析审稿人回复" class="headerlink" title="分析审稿人回复"></a>分析审稿人回复</h1><p>参照：<a class="link"   href="https://zhuanlan.zhihu.com/p/104298923" >https://zhuanlan.zhihu.com/p/104298923 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
]]></content>
      <categories>
        <category>papers-writing</category>
      </categories>
      <tags>
        <tag>papers-writing</tag>
      </tags>
  </entry>
  <entry>
    <title>南开学术规范与论文写作（第4讲）论文写作（上）</title>
    <url>/2023/02/25/paper-write-method-4/</url>
    <content><![CDATA[<p> 介绍论文的摘要（abstract）、前言（introduction）、相关工作（related work）、总体介绍（overview）等。<strong>论文书写应当是面向该领域的入门人员。</strong></p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p><strong>摘要在逻辑上是一个单独文档：</strong></p>
<ul>
<li>作为一个总结，应当在完成论文后再书写。</li>
<li>应当复述论文或者前言中的一些部分。但是要<strong>避免</strong>重复使用相同的描述。</li>
<li>当论文有任何关键变化时，都需要对摘要进行重写。</li>
</ul>
<p><strong>摘要的内容：</strong></p>
<ul>
<li>说明文章关注的是什么问题，以及为什么值得关注</li>
<li>解释主要思想、方法、理论和发现</li>
<li>总结实验证据和理论证明</li>
<li>论文的结论是什么</li>
</ul>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>引言的主要功能是解释问题。</p>
<p><strong>引言内容主要包括：</strong></p>
<ul>
<li>将问题对非本专业的人员进行通俗化的解释。</li>
<li>解释问题存在的背景：<ul>
<li>潜在用户是谁</li>
<li>论文的工作如何扩展当前的思考</li>
<li>为什么简单&#x2F;现有的方案不足以解决问题</li>
<li>为什么当前问题很重要</li>
<li>解决问题的挑战是什么</li>
</ul>
</li>
<li>简要总结在论文的工作之前，SOTA技术的发展与不足。</li>
<li>总结论文所做出的<strong>假设</strong>。</li>
</ul>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>相关工作需要比引言有更多的细节。确保引用的是正确的论文（Google Scholar）。</p>
<p><strong>相关工作讨论的目的：</strong></p>
<ul>
<li><p>展示您对该领域的熟悉程度：</p>
<ul>
<li>先前已经完成了哪些工作。</li>
<li>现在的最新技术是什么。</li>
</ul>
</li>
<li><p>让审稿人对您声称的新颖性有信心。</p>
</li>
<li><p>仔细选择要引用的工作。例如，引用：</p>
<ul>
<li><p>开始某个研究方向的论文；</p>
</li>
<li><p>取得重大进展的论文；</p>
</li>
<li><p>以当前最佳思路&#x2F;结果结束的论文。</p>
</li>
</ul>
</li>
<li><p>未讨论密切相关的工作可能会导致被拒绝。</p>
</li>
</ul>
<p><strong>确保声明你的工作在该领域的优势：</strong></p>
<ul>
<li>你可能是第一个研究一个新问题的人</li>
<li>仅仅有不同还不够，你的工作必须在某些方面更好。 </li>
<li>对关键的先前结果进行批判性分析和解释 <ul>
<li>指出其优点。 </li>
<li>讨论其弱点或限制。 </li>
<li>你的工作是一种改进或解决了一个不同但相关的问题。 </li>
<li>你<strong>不必</strong>在所有方面都进行改进。</li>
</ul>
</li>
</ul>
<p><strong>不要只是进行简单的描述：</strong></p>
<ul>
<li><p>关键分析应该展示您的工作如何是在该问题上所有先前工作的进步。 </p>
</li>
<li><p>未引用重要论文可能会导致审稿人得出您的工作较差的结论。 </p>
</li>
<li><p>工具： </p>
<ul>
<li>您的工作可能依赖于现有方法作为其中一步。 </li>
<li>可能存在选择替代工具的选择。简要分析它们并证明您的选择的合理性。</li>
</ul>
</li>
<li><p>引用最近的调查基准论文。（评测论文、综述论文） </p>
</li>
<li><p>将相关工作进行分组叙述。</p>
</li>
</ul>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>在描述细节之前，提供一个<strong>概述</strong>通常是有帮助的。</p>
<ul>
<li>你的想法可能有很多组成部分。</li>
<li>这些组成部分之间往往存在复杂的关系。</li>
<li>可以将其作为单独的章节，或包含在论文的Introduction部分。</li>
</ul>
<p><strong>overview的作用：</strong></p>
<ul>
<li>解释论文的关键环节</li>
<li>解释关键环节是如何结合在一起</li>
<li>给读者提供一个思维导图</li>
<li>帮助读者了解论文的其余部分。 </li>
<li>了解每个步骤的目的以及它们如何结合在一起。 </li>
<li>对于复杂的关系，图表可能非常有用。 </li>
<li>在概述后，应在后面的章节中详细解释新颖的想法，并为非原创的想法提供引用。 </li>
<li>概述还可以提供其他背景材料（例如，定义技术术语或符号），这些材料对于理解您的方法是必要的。</li>
</ul>
<h1 id="Detail-Section"><a href="#Detail-Section" class="headerlink" title="Detail Section"></a>Detail Section</h1><p>细节部分是整篇论文的核心，分为几个部分，每个部分描述一种的一个环节，或者给出导致最终结果的理论，或者给出工作的主要方面。</p>
<p><strong>Detail Section是否具有足够reproducibility：</strong></p>
<ul>
<li>应该能够根据论文进行再现。 </li>
<li>能够实现所描述的内容</li>
<li>或按照证明中的步骤进行验证</li>
<li>或收集相似类型的数据并以相同的方式进行分析。</li>
</ul>
<p><strong>常见的问题：</strong></p>
<ul>
<li><p>忘记读者可能没有与您相同的背景知识。</p>
</li>
<li><p>过于注重细节而忽略主要思想。</p>
</li>
<li><p>忘记解释思想如何组合在一起。</p>
</li>
<li><p>仅仅说出您做了什么，以及您的方法如何工作，并没有解释为什么要以这种方式进行。</p>
</li>
<li><p>没有解释每个细节如何适应整个解决方案。</p>
</li>
<li><p>用平实的语言概括方程或算法传达的思想。</p>
</li>
</ul>
<p><strong>不要对读者对背景知识的了解有过高的期望。</strong></p>
]]></content>
      <categories>
        <category>papers-writing</category>
      </categories>
      <tags>
        <tag>papers-writing</tag>
      </tags>
  </entry>
  <entry>
    <title>南开学术规范与论文写作（第4讲）论文写作（下）</title>
    <url>/2023/02/25/paper-write-method-5/</url>
    <content><![CDATA[<p> 介绍论文主题写作的后半部分，理论（theory），算法（algorithms），实验（experiments），结论（conclusions）等。</p>
<h1 id="Theory"><a href="#Theory" class="headerlink" title="Theory"></a>Theory</h1><p>除了有精确的公式表达，还要有平实语言描述，<strong>即使去除公式依旧是可读的。</strong></p>
<p><strong>使用例子进行理论解释：</strong></p>
<p>一些人可能更善于从理论论证中学习，但是有些人更适合从示例中学习。</p>
<ul>
<li>提供一些简单的示例有助于展示理论在实践中的运作方式。</li>
<li>这样可以让读者更有信心地理解你的想法，并确认该方法确实有效。</li>
</ul>
<p>不仅要呈现公式，还要解释你的方法是什么，公式的含义，以及公式采取这种形式的原因。</p>
<h1 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h1><p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/1.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/2.png?raw=true"
                     
                ></p>
<p>反例：</p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/3.png?raw=true"
                     
                ></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/4.png?raw=true"
                     
                ></p>
<p><strong>对算法的解释不是简单的对伪代码的描述。</strong></p>
<h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>报告你做了什么，你发现了什么，因此应该用过去时写。 论文的主要部分应该用现在时来写。</p>
<p>每个实验应该有单独、明确的<strong>目的</strong>。 </p>
<ul>
<li>实验可以验证某个理论的某些方面。 </li>
<li>实验可以提供一种衡量方法的结果质量的方式。 </li>
<li>在可能的情况下，重要的是进行能够与现有方法或理论进行比较的测试。 </li>
<li>为了发表论文，该想法在某种程度上需要有所改进。</li>
</ul>
<p><strong>书写步骤：</strong></p>
<ul>
<li>明确阐述实验目的，然后解释实验是如何进行的。 </li>
<li>给出实验结果。 </li>
<li>提供对结果的解释，明确从中推断出了什么。 </li>
<li>解释测试数据的来源和获取方式，以及为什么选择了这个特定的数据集。 </li>
<li>如果可能，使用带有真实数据（GT）的标准基准测试。 </li>
<li>在实验描述中保持诚实。 </li>
<li>所有方法都有局限性。 </li>
<li><strong>确保你得出的任何结论都有实验结果的支持</strong>，并且不要过度概括。</li>
</ul>
<h1 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h1><ul>
<li>简单描述你的contributions并且声明自己的novelty。</li>
<li>解释为什么你的结果是重要和有用的，并概括实验证据或理论证明，说明你的想法如何改进了早期工作。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/5.png?raw=true"
                     
                ></p>
<ul>
<li>清晰地陈述你的研究存在的局限性。</li>
</ul>
<h1 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h1><p>简短感谢基金会、工业或其他伙伴，他们提供给您设备、反馈或其他支持。您还应感谢提供数据集、代码、标本等资源的其他研究人员。</p>
<p><strong>提供数据来源：</strong></p>
<ul>
<li>提供引用文献和代码&#x2F;数据链接（如果可能）。 </li>
<li>如果您希望在论文中复制他人的受版权保护的作品，仅在致谢中提到是不够的。</li>
<li>您必须获得版权持有人的书面许可，尽管书面材料的简短摘录可能不需要这样做。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/6.png?raw=true"
                     
                ></p>
<p><strong>表达对版权的尊重：</strong></p>
<ul>
<li>版权法律可能很复杂，并且因国家而异。</li>
<li>即使获得了许可，您在使用版权材料时也应始终说明其来源。</li>
<li>有时您可能需要支付使用版权材料的许可费用。</li>
</ul>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="https://github.com/Hxiangdou/hxiangdou.github.io/blob/master/images/paper-write-method-5/7.png?raw=true"
                     
                ></p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><strong>概述参考文献</strong>（Bibliography）是一份特定于论文中所讨论的文献列表，而<strong>文献引用</strong>（References）则是你在论文中具体讨论并互相引用的项。学术论文中应只包含引用，而不是一份普通的参考文献列表。</p>
<p>参考文献应该展示以下几个关键点，并帮助读者了解更多关于该主题的信息。</p>
<ul>
<li><p>它可以展示你对领域和其最新进展的了解程度。只有在这方面做足功夫，你的创新主张才有可能被认为是可信的。</p>
</li>
<li><p>参考文献也可以展示你的工作是对之前研究的一个重要补充或提升。</p>
</li>
<li><p>参考文献也能告诉读者如何找到你所使用的工具和其他研究者的工作细节</p>
</li>
<li><p>也可以为你的问题提供背景。</p>
</li>
</ul>
<p>按照期望在会议或期刊中发表论文的引用风格来编写参考文献。有些会议或期刊要求参考文献使用特定的引用格式：</p>
<ul>
<li>可能使用字母续排列、出现次序排列等</li>
<li>使用数字引用，e.g. [1].</li>
<li>作者和日期引用，e.g. [Jones1999].</li>
</ul>
<h2 id="Appendices"><a href="#Appendices" class="headerlink" title="Appendices"></a>Appendices</h2><p>有时<strong>附录</strong>太长了，会打断读者的理解，所以会放到文献的末尾进行补充。</p>
<p>使用附录的主要目的是提供补充材料。 </p>
]]></content>
      <categories>
        <category>papers-writing</category>
      </categories>
      <tags>
        <tag>papers-writing</tag>
      </tags>
  </entry>
  <entry>
    <title>about</title>
    <url>/about/index.html</url>
    <content><![CDATA[<h1 id="ME"><a href="#ME" class="headerlink" title="ME"></a>ME</h1><p><strong>茴香豆</strong><br><del>计科专业大数据方向憨憨，以后该干什么呢？迷茫ヾ(•ω•&#96;)o</del></p>
<p>现在是计算机视觉方向的憨憨了，以后估计就是做这个了。</p>
<h1 id="WORK"><a href="#WORK" class="headerlink" title="WORK"></a>WORK</h1><p><del>谁能给我个工作哇</del> 2022工作真的不好找！</p>
]]></content>
  </entry>
  <entry>
    <title>categories</title>
    <url>/categories/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>colorful</title>
    <url>/galleries/colorful/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>相册</title>
    <url>/galleries/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>tags</title>
    <url>/tags/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>漫画</title>
    <url>/galleries/%E6%BC%AB%E7%94%BB/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>游戏</title>
    <url>/galleries/%E6%B8%B8%E6%88%8F/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>随手拍</title>
    <url>/galleries/%E9%9A%8F%E6%89%8B%E6%8B%8D/index.html</url>
    <content><![CDATA[]]></content>
  </entry>
</search>
